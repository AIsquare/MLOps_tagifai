{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9240275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hhome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import nltk\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "sns.set_theme()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0b7ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-20 06:43:18</td>\n",
       "      <td>Comparison between YOLO and RCNN on real world...</td>\n",
       "      <td>Bringing theory to experiment is cool. We can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-02-20 06:47:21</td>\n",
       "      <td>Show, Infer &amp; Tell: Contextual Inference for C...</td>\n",
       "      <td>The beauty of the work lies in the way it arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2020-02-24 16:24:45</td>\n",
       "      <td>Awesome Graph Classification</td>\n",
       "      <td>A collection of important graph embedding, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2020-03-03 13:54:31</td>\n",
       "      <td>Diffusion to Vector</td>\n",
       "      <td>Reference implementation of Diffusion2Vec (Com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           created_on                                              title  \\\n",
       "0   6  2020-02-20 06:43:18  Comparison between YOLO and RCNN on real world...   \n",
       "1   7  2020-02-20 06:47:21  Show, Infer & Tell: Contextual Inference for C...   \n",
       "2   9  2020-02-24 16:24:45                       Awesome Graph Classification   \n",
       "3  15  2020-02-28 23:55:26                    Awesome Monte Carlo Tree Search   \n",
       "4  19  2020-03-03 13:54:31                                Diffusion to Vector   \n",
       "\n",
       "                                         description  \n",
       "0  Bringing theory to experiment is cool. We can ...  \n",
       "1  The beauty of the work lies in the way it arch...  \n",
       "2  A collection of important graph embedding, cla...  \n",
       "3  A curated list of Monte Carlo tree search pape...  \n",
       "4  Reference implementation of Diffusion2Vec (Com...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract projects\n",
    "PROJECTS_URL = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/projects.csv\"\n",
    "projects = pd.read_csv(PROJECTS_URL)\n",
    "projects.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2009f419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     tag\n",
       "0   6         computer-vision\n",
       "1   7         computer-vision\n",
       "2   9          graph-learning\n",
       "3  15  reinforcement-learning\n",
       "4  19          graph-learning"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tags\n",
    "TAGS_URL = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/tags.csv\"\n",
    "tags = pd.read_csv(TAGS_URL)\n",
    "tags.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c274dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(projects,tags,on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a7cb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-20 06:43:18</td>\n",
       "      <td>Comparison between YOLO and RCNN on real world...</td>\n",
       "      <td>Bringing theory to experiment is cool. We can ...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-02-20 06:47:21</td>\n",
       "      <td>Show, Infer &amp; Tell: Contextual Inference for C...</td>\n",
       "      <td>The beauty of the work lies in the way it arch...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2020-02-24 16:24:45</td>\n",
       "      <td>Awesome Graph Classification</td>\n",
       "      <td>A collection of important graph embedding, cla...</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2020-03-03 13:54:31</td>\n",
       "      <td>Diffusion to Vector</td>\n",
       "      <td>Reference implementation of Diffusion2Vec (Com...</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           created_on                                              title  \\\n",
       "0   6  2020-02-20 06:43:18  Comparison between YOLO and RCNN on real world...   \n",
       "1   7  2020-02-20 06:47:21  Show, Infer & Tell: Contextual Inference for C...   \n",
       "2   9  2020-02-24 16:24:45                       Awesome Graph Classification   \n",
       "3  15  2020-02-28 23:55:26                    Awesome Monte Carlo Tree Search   \n",
       "4  19  2020-03-03 13:54:31                                Diffusion to Vector   \n",
       "\n",
       "                                         description                     tag  \n",
       "0  Bringing theory to experiment is cool. We can ...         computer-vision  \n",
       "1  The beauty of the work lies in the way it arch...         computer-vision  \n",
       "2  A collection of important graph embedding, cla...          graph-learning  \n",
       "3  A curated list of Monte Carlo tree search pape...  reinforcement-learning  \n",
       "4  Reference implementation of Diffusion2Vec (Com...          graph-learning  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f8dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.tag.notnull()]  # remove projects with no tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0f273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally\n",
    "df.to_csv(\"labeled_projects.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c916bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "822808f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contains_tensorflow(text):\n",
    "    condition = any(tag in text.lower() for tag in (\"tensorlfow\",\"tf\"))\n",
    "    return \"tensorflow\" if condition else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b88fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of tags\n",
    "tags, tag_counts = zip(*Counter(df.tag.values).most_common())\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = sns.barplot(x= list(tags), y=list(tag_counts))\n",
    "plt.title(\"Tag distribution\", fontsize=20)\n",
    "plt.xlabel(\"Tag\", fontsize=16)\n",
    "ax.set_xticklabels(tags, rotation=90, fontsize=14)\n",
    "plt.ylabel(\"Number of projects\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0932aaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural-language-processing', 388),\n",
       " ('computer-vision', 356),\n",
       " ('mlops', 79),\n",
       " ('reinforcement-learning', 56),\n",
       " ('graph-learning', 45),\n",
       " ('time-series', 31)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common tags\n",
    "tags = Counter(df.tag.values)\n",
    "tags.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c47932bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='tag', index=3, options=('computer-vision', 'graph-learning', 'rein…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(tag=list(tags))\n",
    "def display_word_cloud(tag=\"natural-language-processing\"):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    subset = df[df.tag==tag]\n",
    "    text = subset.title.values\n",
    "    cloud = WordCloud(stopwords=STOPWORDS,background_color='black').generate(\" \".join(text))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71a0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.title + \" \" + df.description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201e654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, lower=True, stem=False,stopwords=STOPWORDS):\n",
    "    '''clean raw text'''\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "        \n",
    "    if len(stopwords):\n",
    "        pattern = re.compile(r'\\b(' + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "        text = pattern.sub('',text)\n",
    "    # Spacing and filters\n",
    "    text = re.sub(\n",
    "        r\"([!\\\"'#$%&()*\\+,-./:;<=>?@\\\\\\[\\]^_`{|}~])\", r\" \\1 \", text\n",
    "    )  # add spacing between objects to be filtered\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()  # strip white space at the ends\n",
    "\n",
    "    # Remove links\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Stemming\n",
    "    if stem:\n",
    "        text = \" \".join([stemmer.stem(word, to_lowercase=lower) for word in text.split(\" \")])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc64a7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between YOLO and RCNN on real world videos Bringing theory to experiment is cool. We can easily train models in colab and find the results in minutes.\n",
      "comparison yolo rcnn real world videos bringing theory experiment cool easily train models colab find results minutes\n"
     ]
    }
   ],
   "source": [
    "original_df = df.copy()\n",
    "df.text = df.text.apply(clean_text, lower=True, stem=False)\n",
    "print(f\"{original_df.text.values[0]}\\n{df.text.values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03d7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc275b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepted tags (external constraint)\n",
    "ACCEPTED_TAGS = [\"natural-language-processing\", \"computer-vision\", \"mlops\", \"graph-learning\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf9b2712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-20 06:43:18</td>\n",
       "      <td>Comparison between YOLO and RCNN on real world...</td>\n",
       "      <td>Bringing theory to experiment is cool. We can ...</td>\n",
       "      <td>computer-vision</td>\n",
       "      <td>comparison yolo rcnn real world videos bringin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-02-20 06:47:21</td>\n",
       "      <td>Show, Infer &amp; Tell: Contextual Inference for C...</td>\n",
       "      <td>The beauty of the work lies in the way it arch...</td>\n",
       "      <td>computer-vision</td>\n",
       "      <td>show infer tell contextual inference creative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2020-02-24 16:24:45</td>\n",
       "      <td>Awesome Graph Classification</td>\n",
       "      <td>A collection of important graph embedding, cla...</td>\n",
       "      <td>graph-learning</td>\n",
       "      <td>awesome graph classification collection import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>awesome monte carlo tree search curated list m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2020-03-03 13:54:31</td>\n",
       "      <td>Diffusion to Vector</td>\n",
       "      <td>Reference implementation of Diffusion2Vec (Com...</td>\n",
       "      <td>graph-learning</td>\n",
       "      <td>diffusion vector reference implementation diff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           created_on                                              title  \\\n",
       "0   6  2020-02-20 06:43:18  Comparison between YOLO and RCNN on real world...   \n",
       "1   7  2020-02-20 06:47:21  Show, Infer & Tell: Contextual Inference for C...   \n",
       "2   9  2020-02-24 16:24:45                       Awesome Graph Classification   \n",
       "3  15  2020-02-28 23:55:26                    Awesome Monte Carlo Tree Search   \n",
       "4  19  2020-03-03 13:54:31                                Diffusion to Vector   \n",
       "\n",
       "                                         description                     tag  \\\n",
       "0  Bringing theory to experiment is cool. We can ...         computer-vision   \n",
       "1  The beauty of the work lies in the way it arch...         computer-vision   \n",
       "2  A collection of important graph embedding, cla...          graph-learning   \n",
       "3  A curated list of Monte Carlo tree search pape...  reinforcement-learning   \n",
       "4  Reference implementation of Diffusion2Vec (Com...          graph-learning   \n",
       "\n",
       "                                                text  \n",
       "0  comparison yolo rcnn real world videos bringin...  \n",
       "1  show infer tell contextual inference creative ...  \n",
       "2  awesome graph classification collection import...  \n",
       "3  awesome monte carlo tree search curated list m...  \n",
       "4  diffusion vector reference implementation diff...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d097ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reinforcement-learning', 'time-series']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of scope tags\n",
    "oos_tags = [item for item in df.tag.unique() if item not in ACCEPTED_TAGS]\n",
    "oos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f446ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             87\n",
       "created_on     87\n",
       "title          87\n",
       "description    87\n",
       "tag            87\n",
       "text           87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_indices = df[df.tag.isin(oos_tags)].index\n",
    "df[df.tag.isin(oos_tags)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45385350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "      <td>other</td>\n",
       "      <td>awesome monte carlo tree search curated list m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>121</td>\n",
       "      <td>2020-03-24 04:56:38</td>\n",
       "      <td>Deep Reinforcement Learning in TensorFlow2</td>\n",
       "      <td>deep-rl-tf2 is a repository that implements a ...</td>\n",
       "      <td>other</td>\n",
       "      <td>deep reinforcement learning tensorflow2 deep r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>218</td>\n",
       "      <td>2020-04-06 11:29:57</td>\n",
       "      <td>Distributional RL using TensorFlow2</td>\n",
       "      <td>🐳 Implementation of various Distributional Rei...</td>\n",
       "      <td>other</td>\n",
       "      <td>distributional rl using tensorflow2 implementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>239</td>\n",
       "      <td>2020-04-06 18:39:48</td>\n",
       "      <td>Prophet: Forecasting At Scale</td>\n",
       "      <td>Tool for producing high quality forecasts for ...</td>\n",
       "      <td>other</td>\n",
       "      <td>prophet forecasting scale tool producing high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>277</td>\n",
       "      <td>2020-04-07 00:30:33</td>\n",
       "      <td>Curriculum for Reinforcement Learning</td>\n",
       "      <td>Curriculum learning applied to reinforcement l...</td>\n",
       "      <td>other</td>\n",
       "      <td>curriculum reinforcement learning curriculum l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           created_on                                       title  \\\n",
       "3    15  2020-02-28 23:55:26             Awesome Monte Carlo Tree Search   \n",
       "37  121  2020-03-24 04:56:38  Deep Reinforcement Learning in TensorFlow2   \n",
       "67  218  2020-04-06 11:29:57         Distributional RL using TensorFlow2   \n",
       "74  239  2020-04-06 18:39:48               Prophet: Forecasting At Scale   \n",
       "95  277  2020-04-07 00:30:33       Curriculum for Reinforcement Learning   \n",
       "\n",
       "                                          description    tag  \\\n",
       "3   A curated list of Monte Carlo tree search pape...  other   \n",
       "37  deep-rl-tf2 is a repository that implements a ...  other   \n",
       "67  🐳 Implementation of various Distributional Rei...  other   \n",
       "74  Tool for producing high quality forecasts for ...  other   \n",
       "95  Curriculum learning applied to reinforcement l...  other   \n",
       "\n",
       "                                                 text  \n",
       "3   awesome monte carlo tree search curated list m...  \n",
       "37  deep reinforcement learning tensorflow2 deep r...  \n",
       "67  distributional rl using tensorflow2 implementa...  \n",
       "74  prophet forecasting scale tool producing high ...  \n",
       "95  curriculum reinforcement learning curriculum l...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace tag with other tag\n",
    "df.tag = df.tag.apply(lambda x: \"other\" if x in oos_tags else x)\n",
    "df.iloc[oos_indices].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e4adc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum frequency required for a tag\n",
    "min_freq = 75\n",
    "tags = Counter(df.tag.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02f8e0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x1a11f168b88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4abad670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=75, description='min_freq', max=388), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(min_freq=(0,tags.most_common()[0][1]))\n",
    "def separate_tags_by_freq(min_freq=min_freq):\n",
    "    tags_above_freq = Counter(tag for tag in tags.elements() if tags[tag]>=min_freq)\n",
    "    tags_below_freq = Counter(tag for tag in tags.elements()\n",
    "                                    if tags[tag] < min_freq)\n",
    "    print (\"Most popular tags:\\n\", tags_above_freq.most_common(3))\n",
    "    print (\"\\nTags that just made the cut:\\n\", tags_above_freq.most_common()[-3:])\n",
    "    print (\"\\nTags that just missed the cut:\\n\", tags_below_freq.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "549e96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(tag, include=[]):\n",
    "    \"\"\"Determine if a given tag is to be included.\"\"\"\n",
    "    if tag not in include:\n",
    "        tag = None\n",
    "    return tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d19feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tags that have fewer than <min_freq> occurrences\n",
    "tags_above_freq = Counter(tag for tag in tags.elements()\n",
    "                          if (tags[tag] >= min_freq))\n",
    "df.tag = df.tag.apply(filter, include=list(tags_above_freq.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e8a6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill None with other\n",
    "df.tag = df.tag.fillna(\"other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac7b4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f6faa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "X = df.text.to_numpy()\n",
    "y = df.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ecd2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    def __init__(self,class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}\n",
    "        self.index_to_class = {v:k for k,v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "    \n",
    "    def fit(self,y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v:k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "    \n",
    "    def encode(self,y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        #print(encoded)\n",
    "        for i, item in enumerate(y):\n",
    "#             print(i)\n",
    "#             print(item)\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "    \n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "    \n",
    "    def save(self, fp):\n",
    "        with open(fp,\"w\") as fp:\n",
    "            contents = {\"class_to_index\": self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls,fp):\n",
    "        with open(fp, 'r') as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02480a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "num_classes = len(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24d99032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer-vision': 0,\n",
       " 'mlops': 1,\n",
       " 'natural-language-processing': 2,\n",
       " 'other': 3}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.class_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5ad2dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'computer-vision',\n",
       " 1: 'mlops',\n",
       " 2: 'natural-language-processing',\n",
       " 3: 'other'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.index_to_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05019be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.encode([\"computer-vision\", \"mlops\", \"mlops\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3a3f27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer-vision', 'mlops', 'mlops']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode\n",
    "label_encoder.decode(np.array([0, 1, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6be5fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955,)\n"
     ]
    }
   ],
   "source": [
    "# Encode all our labels\n",
    "y = label_encoder.encode(y)\n",
    "print (y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f19a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92260e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sizes\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "092d24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (train)\n",
    "X_train, X_, y_train, y_ = train_test_split(\n",
    "    X, y, train_size=train_size, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceafe519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 668 (0.70)\n",
      "remaining: 287 (0.30)\n"
     ]
    }
   ],
   "source": [
    "print (f\"train: {len(X_train)} ({(len(X_train) / len(X)):.2f})\\n\"\n",
    "       f\"remaining: {len(X_)} ({(len(X_) / len(X)):.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3418b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_, y_, train_size=0.5, stratify=y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06199648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 668 (0.70)\n",
      "val: 143 (0.15)\n",
      "test: 144 (0.15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: {len(X_train)} ({len(X_train)/len(X):.2f})\\n\"\n",
    "      f\"val: {len(X_val)} ({len(X_val)/len(X):.2f})\\n\"\n",
    "      f\"test: {len(X_test)} ({len(X_test)/len(X):.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69d89ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for each class\n",
    "counts = {}\n",
    "counts[\"train_counts\"] = {tag: label_encoder.decode(y_train).count(tag) for tag in label_encoder.classes}\n",
    "counts[\"val_counts\"] = {tag: label_encoder.decode(y_val).count(tag) for tag in label_encoder.classes}\n",
    "counts[\"test_counts\"] = {tag: label_encoder.decode(y_test).count(tag) for tag in label_encoder.classes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c75d7405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>computer-vision</th>\n",
       "      <th>mlops</th>\n",
       "      <th>natural-language-processing</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>249</td>\n",
       "      <td>55</td>\n",
       "      <td>272</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       computer-vision  mlops  natural-language-processing  other\n",
       "train              249     55                          272     92\n",
       "val                 53     12                           58     20\n",
       "test                54     12                           58     20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"train\": counts[\"train_counts\"],\n",
    "    \"val\": counts[\"val_counts\"],\n",
    "    \"test\": counts[\"test_counts\"]\n",
    "}).T.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fa5e2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[\"val_counts\"][\"mlops\"] * (train_size/val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00ae1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust counts across splits\n",
    "for k in counts[\"val_counts\"].keys():\n",
    "    counts[\"val_counts\"][k] = int(counts[\"val_counts\"][k] *(train_size/val_size))\n",
    "for k in counts[\"test_counts\"].keys():\n",
    "    counts[\"test_counts\"][k] = int(counts[\"test_counts\"][k] *(train_size/test_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e3765ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>computer-vision</th>\n",
       "      <th>mlops</th>\n",
       "      <th>natural-language-processing</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>249</td>\n",
       "      <td>55</td>\n",
       "      <td>272</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>247</td>\n",
       "      <td>56</td>\n",
       "      <td>270</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>252</td>\n",
       "      <td>56</td>\n",
       "      <td>270</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       computer-vision  mlops  natural-language-processing  other\n",
       "train              249     55                          272     92\n",
       "val                247     56                          270     93\n",
       "test               252     56                          270     93"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_df = pd.DataFrame({\n",
    "    \"train\": counts[\"train_counts\"],\n",
    "    \"val\": counts[\"val_counts\"],\n",
    "    \"test\": counts[\"test_counts\"]\n",
    "}).T.fillna(0)\n",
    "dist_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ede2fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851056877051131"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard deviation\n",
    "np.mean(np.std(dist_df.to_numpy(), axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d4c77cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huggingtweets tweet generation huggingface</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selfie2anime tflite end end tutorial tensorflo...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>introduction q learning reinforcement learning...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>holopix50k large scale wild stereo image datas...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlops machine learning operations mlops best p...</td>\n",
       "      <td>mlops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0         huggingtweets tweet generation huggingface   \n",
       "1  selfie2anime tflite end end tutorial tensorflo...   \n",
       "2  introduction q learning reinforcement learning...   \n",
       "3  holopix50k large scale wild stereo image datas...   \n",
       "4  mlops machine learning operations mlops best p...   \n",
       "\n",
       "                           tag  \n",
       "0  natural-language-processing  \n",
       "1              computer-vision  \n",
       "2                        other  \n",
       "3              computer-vision  \n",
       "4                        mlops  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split DataFrames\n",
    "train_df = pd.DataFrame({\"text\": X_train, \"tag\": label_encoder.decode(y_train)})\n",
    "val_df = pd.DataFrame({\"text\": X_val, \"tag\": label_encoder.decode(y_val)})\n",
    "test_df = pd.DataFrame({\"text\": X_test, \"tag\": label_encoder.decode(y_test)})\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6a94ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec6d544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers and transformers\n",
    "substitution = naw.ContextualWordEmbsAug(model_path=\"distilbert-base-uncased\", action=\"substitute\")\n",
    "insertion = naw.ContextualWordEmbsAug(model_path=\"distilbert-base-uncased\", action=\"insert\")\n",
    "text = \"Conditional image generation using Variational Autoencoders and GANs.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e636542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conditional complexity generation processes variational data and strings.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitution.augment(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "081bfd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conditional image image generation using binary variational linear autoencoders filters and gans.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insertions\n",
    "insertion.augment(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbc376d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dashes from tags & aliases\n",
    "def replace_dash(x):\n",
    "    return x.replace(\"-\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "101125d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer vision'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_dash('computer-vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6c01cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliases\n",
    "aliases_by_tag = {\n",
    "    \"computer-vision\": [\"cv\", \"vision\"],\n",
    "    \"mlops\": [\"production\"],\n",
    "    \"natural-language-processing\": [\"nlp\", \"nlproc\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa2ba6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cv', 'vision', 'COmputer']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['cv','vision']+['COmputer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b2f7597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv\n",
      "vision\n",
      "production\n",
      "nlp\n",
      "nlproc\n"
     ]
    }
   ],
   "source": [
    "# Flatten dict\n",
    "#let's try simply swapping machine learning related keywords with their aliases\n",
    "flattened_aliases = {}\n",
    "for tag, aliases in aliases_by_tag.items():\n",
    "    tag = replace_dash(x=tag)\n",
    "    if len(aliases):\n",
    "        flattened_aliases[tag] = aliases\n",
    "    for alias in aliases:\n",
    "        print(alias)\n",
    "        _aliases = aliases + [tag]\n",
    "        _aliases.remove(alias)\n",
    "        flattened_aliases[alias] = _aliases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "999bc418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer vision': ['cv', 'vision'],\n",
       " 'cv': ['vision', 'computer vision'],\n",
       " 'vision': ['cv', 'computer vision'],\n",
       " 'mlops': ['production'],\n",
       " 'production': ['mlops'],\n",
       " 'natural language processing': ['nlp', 'nlproc'],\n",
       " 'nlp': ['nlproc', 'natural language processing'],\n",
       " 'nlproc': ['nlp', 'natural language processing']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a28aed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', 'nlproc']\n",
      "['nlproc', 'natural language processing']\n"
     ]
    }
   ],
   "source": [
    "print (flattened_aliases[\"natural language processing\"])\n",
    "print (flattened_aliases[\"nlp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b9be6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# We want to match with the whole word only\n",
    "print (\"gan\" in \"This is a gan.\")\n",
    "print (\"gan\" in \"This is gandalf.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b09bd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\b matches spaces\n",
    "def find_word(word, text):\n",
    "    word = word.replace(\"+\", \"\\+\")\n",
    "    pattern = re.compile(fr\"\\b({word})\\b\", flags=re.IGNORECASE)\n",
    "    return pattern.search(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93e67ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(10, 13), match='gan'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Correct behavior (single instance)\n",
    "print (find_word(\"gan\", \"This is a gan.\"))\n",
    "print (find_word(\"gan\", \"This is gandalf.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce3b1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import transformation_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ce8c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformation_function()\n",
    "def swap_aliases(x):\n",
    "    \"\"\"Swap ML keywords with their aliases.\"\"\"\n",
    "    # Find all matches\n",
    "    matches = []\n",
    "    for i, tag in enumerate(flattened_aliases):\n",
    "        match = find_word(tag, x.text)\n",
    "        if match:\n",
    "            matches.append(match)\n",
    "    # Swap a random match with a random alias\n",
    "    if len(matches):\n",
    "        match = random.choice(matches)\n",
    "        print(match)\n",
    "        tag = x.text[match.start():match.end()]\n",
    "        x.text = f\"{x.text[:match.start()]}{random.choice(flattened_aliases[tag])}{x.text[match.end():]}\"\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5683d8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "survey reinforcement learning natural language processing tasks\n",
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "survey reinforcement learning natural language processing tasks\n",
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "survey reinforcement learning nlproc tasks\n"
     ]
    }
   ],
   "source": [
    "# Swap\n",
    "for i in range(3):\n",
    "    sample_df = pd.DataFrame([{\"text\": \"a survey of reinforcement learning for nlp tasks.\"}])\n",
    "    sample_df.text = sample_df.text.apply(clean_text, lower=True, stem=False)\n",
    "    print (swap_aliases(sample_df.iloc[0]).text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2da2e374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(33, 36), match='nlp'>\n",
      "autogenerate cv apply jobs using nlproc\n",
      "<re.Match object; span=(33, 36), match='nlp'>\n",
      "autogenerate cv apply jobs using natural language processing\n",
      "<re.Match object; span=(33, 36), match='nlp'>\n",
      "autogenerate cv apply jobs using natural language processing\n"
     ]
    }
   ],
   "source": [
    "# Undesired behavior (needs contextual insight)\n",
    "for i in range(3):\n",
    "    sample_df = pd.DataFrame([{\"text\": \"Autogenerate your CV to apply for jobs using NLP.\"}])\n",
    "    sample_df.text = sample_df.text.apply(clean_text, lower=True, stem=False)\n",
    "    print (swap_aliases(sample_df.iloc[0]).text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "887ae39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7e278d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/668 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match='mlops'>\n",
      "<re.Match object; span=(0, 5), match='mlops'>\n",
      "<re.Match object; span=(0, 5), match='mlops'>\n",
      "<re.Match object; span=(0, 5), match='mlops'>\n",
      "<re.Match object; span=(0, 5), match='mlops'>\n",
      "<re.Match object; span=(23, 38), match='computer vision'>\n",
      "<re.Match object; span=(32, 38), match='vision'>\n",
      "<re.Match object; span=(23, 38), match='computer vision'>\n",
      "<re.Match object; span=(32, 38), match='vision'>\n",
      "<re.Match object; span=(32, 38), match='vision'>\n",
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "<re.Match object; span=(30, 33), match='nlp'>\n",
      "<re.Match object; span=(133, 136), match='nlp'>\n",
      "<re.Match object; span=(133, 136), match='nlp'>\n",
      "<re.Match object; span=(19, 46), match='natural language processing'>\n",
      "<re.Match object; span=(133, 136), match='nlp'>\n",
      "<re.Match object; span=(133, 136), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                             | 21/668 [00:00<00:03, 203.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(17, 32), match='computer vision'>\n",
      "<re.Match object; span=(26, 32), match='vision'>\n",
      "<re.Match object; span=(17, 32), match='computer vision'>\n",
      "<re.Match object; span=(17, 32), match='computer vision'>\n",
      "<re.Match object; span=(26, 32), match='vision'>\n",
      "<re.Match object; span=(87, 90), match='nlp'>\n",
      "<re.Match object; span=(87, 90), match='nlp'>\n",
      "<re.Match object; span=(87, 90), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▏                                                                          | 43/668 [00:00<00:02, 209.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(87, 90), match='nlp'>\n",
      "<re.Match object; span=(87, 90), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(26, 31), match='mlops'>\n",
      "<re.Match object; span=(26, 31), match='mlops'>\n",
      "<re.Match object; span=(26, 31), match='mlops'>\n",
      "<re.Match object; span=(26, 31), match='mlops'>\n",
      "<re.Match object; span=(26, 31), match='mlops'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(56, 83), match='natural language processing'>\n",
      "<re.Match object; span=(56, 83), match='natural language processing'>\n",
      "<re.Match object; span=(56, 83), match='natural language processing'>\n",
      "<re.Match object; span=(56, 83), match='natural language processing'>\n",
      "<re.Match object; span=(56, 83), match='natural language processing'>\n",
      "<re.Match object; span=(93, 99), match='vision'>\n",
      "<re.Match object; span=(84, 99), match='computer vision'>\n",
      "<re.Match object; span=(84, 99), match='computer vision'>\n",
      "<re.Match object; span=(93, 99), match='vision'>\n",
      "<re.Match object; span=(84, 99), match='computer vision'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████                                                                  | 110/668 [00:00<00:03, 185.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(44, 47), match='nlp'>\n",
      "<re.Match object; span=(44, 47), match='nlp'>\n",
      "<re.Match object; span=(90, 117), match='natural language processing'>\n",
      "<re.Match object; span=(44, 47), match='nlp'>\n",
      "<re.Match object; span=(44, 47), match='nlp'>\n",
      "<re.Match object; span=(51, 54), match='nlp'>\n",
      "<re.Match object; span=(51, 54), match='nlp'>\n",
      "<re.Match object; span=(51, 54), match='nlp'>\n",
      "<re.Match object; span=(51, 54), match='nlp'>\n",
      "<re.Match object; span=(51, 54), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(9, 14), match='mlops'>\n",
      "<re.Match object; span=(9, 14), match='mlops'>\n",
      "<re.Match object; span=(9, 14), match='mlops'>\n",
      "<re.Match object; span=(9, 14), match='mlops'>\n",
      "<re.Match object; span=(9, 14), match='mlops'>\n",
      "<re.Match object; span=(105, 108), match='nlp'>\n",
      "<re.Match object; span=(105, 108), match='nlp'>\n",
      "<re.Match object; span=(105, 108), match='nlp'>\n",
      "<re.Match object; span=(105, 108), match='nlp'>\n",
      "<re.Match object; span=(105, 108), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▉                                                               | 135/668 [00:00<00:02, 205.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(109, 115), match='vision'>\n",
      "<re.Match object; span=(100, 115), match='computer vision'>\n",
      "<re.Match object; span=(100, 115), match='computer vision'>\n",
      "<re.Match object; span=(100, 115), match='computer vision'>\n",
      "<re.Match object; span=(100, 115), match='computer vision'>\n",
      "<re.Match object; span=(36, 51), match='computer vision'>\n",
      "<re.Match object; span=(45, 51), match='vision'>\n",
      "<re.Match object; span=(36, 51), match='computer vision'>\n",
      "<re.Match object; span=(45, 51), match='vision'>\n",
      "<re.Match object; span=(36, 51), match='computer vision'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(93, 103), match='production'>\n",
      "<re.Match object; span=(93, 103), match='production'>\n",
      "<re.Match object; span=(93, 103), match='production'>\n",
      "<re.Match object; span=(93, 103), match='production'>\n",
      "<re.Match object; span=(93, 103), match='production'>\n",
      "<re.Match object; span=(89, 116), match='natural language processing'>\n",
      "<re.Match object; span=(89, 116), match='natural language processing'>\n",
      "<re.Match object; span=(32, 35), match='nlp'>\n",
      "<re.Match object; span=(32, 35), match='nlp'>\n",
      "<re.Match object; span=(32, 35), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████████████▊                                                            | 159/668 [00:00<00:02, 214.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(71, 98), match='natural language processing'>\n",
      "<re.Match object; span=(71, 98), match='natural language processing'>\n",
      "<re.Match object; span=(71, 98), match='natural language processing'>\n",
      "<re.Match object; span=(71, 98), match='natural language processing'>\n",
      "<re.Match object; span=(71, 98), match='natural language processing'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(55, 70), match='computer vision'>\n",
      "<re.Match object; span=(53, 56), match='nlp'>\n",
      "<re.Match object; span=(53, 56), match='nlp'>\n",
      "<re.Match object; span=(53, 56), match='nlp'>\n",
      "<re.Match object; span=(53, 56), match='nlp'>\n",
      "<re.Match object; span=(53, 56), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 26), match='nlp'>\n",
      "<re.Match object; span=(23, 26), match='nlp'>\n",
      "<re.Match object; span=(23, 26), match='nlp'>\n",
      "<re.Match object; span=(23, 26), match='nlp'>\n",
      "<re.Match object; span=(23, 26), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▏                                                      | 205/668 [00:01<00:02, 210.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(19, 25), match='vision'>\n",
      "<re.Match object; span=(46, 48), match='cv'>\n",
      "<re.Match object; span=(10, 25), match='computer vision'>\n",
      "<re.Match object; span=(19, 25), match='vision'>\n",
      "<re.Match object; span=(19, 25), match='vision'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(25, 52), match='natural language processing'>\n",
      "<re.Match object; span=(99, 102), match='nlp'>\n",
      "<re.Match object; span=(99, 102), match='nlp'>\n",
      "<re.Match object; span=(25, 52), match='natural language processing'>\n",
      "<re.Match object; span=(99, 102), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████████████▊                                                    | 227/668 [00:01<00:02, 193.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(133, 139), match='vision'>\n",
      "<re.Match object; span=(124, 139), match='computer vision'>\n",
      "<re.Match object; span=(124, 139), match='computer vision'>\n",
      "<re.Match object; span=(124, 139), match='computer vision'>\n",
      "<re.Match object; span=(124, 139), match='computer vision'>\n",
      "<re.Match object; span=(26, 32), match='vision'>\n",
      "<re.Match object; span=(26, 32), match='vision'>\n",
      "<re.Match object; span=(26, 32), match='vision'>\n",
      "<re.Match object; span=(26, 32), match='vision'>\n",
      "<re.Match object; span=(26, 32), match='vision'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(94, 100), match='vision'>\n",
      "<re.Match object; span=(94, 100), match='vision'>\n",
      "<re.Match object; span=(85, 100), match='computer vision'>\n",
      "<re.Match object; span=(85, 100), match='computer vision'>\n",
      "<re.Match object; span=(85, 100), match='computer vision'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▍                                               | 266/668 [00:01<00:02, 177.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(12, 15), match='nlp'>\n",
      "<re.Match object; span=(12, 15), match='nlp'>\n",
      "<re.Match object; span=(12, 15), match='nlp'>\n",
      "<re.Match object; span=(12, 15), match='nlp'>\n",
      "<re.Match object; span=(12, 15), match='nlp'>\n",
      "<re.Match object; span=(22, 28), match='vision'>\n",
      "<re.Match object; span=(22, 28), match='vision'>\n",
      "<re.Match object; span=(22, 28), match='vision'>\n",
      "<re.Match object; span=(22, 28), match='vision'>\n",
      "<re.Match object; span=(22, 28), match='vision'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▎                                            | 290/668 [00:01<00:01, 193.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(104, 114), match='production'>\n",
      "<re.Match object; span=(104, 114), match='production'>\n",
      "<re.Match object; span=(104, 114), match='production'>\n",
      "<re.Match object; span=(104, 114), match='production'>\n",
      "<re.Match object; span=(104, 114), match='production'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n",
      "<re.Match object; span=(28, 31), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████▉                                       | 338/668 [00:01<00:01, 214.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(16, 19), match='nlp'>\n",
      "<re.Match object; span=(16, 19), match='nlp'>\n",
      "<re.Match object; span=(16, 19), match='nlp'>\n",
      "<re.Match object; span=(16, 19), match='nlp'>\n",
      "<re.Match object; span=(16, 19), match='nlp'>\n",
      "<re.Match object; span=(18, 21), match='nlp'>\n",
      "<re.Match object; span=(18, 21), match='nlp'>\n",
      "<re.Match object; span=(18, 21), match='nlp'>\n",
      "<re.Match object; span=(18, 21), match='nlp'>\n",
      "<re.Match object; span=(18, 21), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(25, 28), match='nlp'>\n",
      "<re.Match object; span=(113, 128), match='computer vision'>\n",
      "<re.Match object; span=(122, 128), match='vision'>\n",
      "<re.Match object; span=(122, 128), match='vision'>\n",
      "<re.Match object; span=(122, 128), match='vision'>\n",
      "<re.Match object; span=(122, 128), match='vision'>\n",
      "<re.Match object; span=(15, 21), match='vision'>\n",
      "<re.Match object; span=(15, 21), match='vision'>\n",
      "<re.Match object; span=(15, 21), match='vision'>\n",
      "<re.Match object; span=(15, 21), match='vision'>\n",
      "<re.Match object; span=(15, 21), match='vision'>\n",
      "<re.Match object; span=(7, 10), match='nlp'>\n",
      "<re.Match object; span=(7, 10), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████▍                                 | 384/668 [00:01<00:01, 220.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 10), match='nlp'>\n",
      "<re.Match object; span=(7, 10), match='nlp'>\n",
      "<re.Match object; span=(7, 10), match='nlp'>\n",
      "<re.Match object; span=(15, 18), match='nlp'>\n",
      "<re.Match object; span=(15, 18), match='nlp'>\n",
      "<re.Match object; span=(15, 18), match='nlp'>\n",
      "<re.Match object; span=(15, 18), match='nlp'>\n",
      "<re.Match object; span=(15, 18), match='nlp'>\n",
      "<re.Match object; span=(14, 20), match='vision'>\n",
      "<re.Match object; span=(14, 20), match='vision'>\n",
      "<re.Match object; span=(5, 20), match='computer vision'>\n",
      "<re.Match object; span=(14, 20), match='vision'>\n",
      "<re.Match object; span=(5, 20), match='computer vision'>\n",
      "<re.Match object; span=(61, 64), match='nlp'>\n",
      "<re.Match object; span=(61, 64), match='nlp'>\n",
      "<re.Match object; span=(61, 64), match='nlp'>\n",
      "<re.Match object; span=(61, 64), match='nlp'>\n",
      "<re.Match object; span=(61, 64), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▎                              | 408/668 [00:02<00:01, 223.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(24, 27), match='nlp'>\n",
      "<re.Match object; span=(24, 27), match='nlp'>\n",
      "<re.Match object; span=(24, 27), match='nlp'>\n",
      "<re.Match object; span=(24, 27), match='nlp'>\n",
      "<re.Match object; span=(24, 27), match='nlp'>\n",
      "<re.Match object; span=(90, 100), match='production'>\n",
      "<re.Match object; span=(90, 100), match='production'>\n",
      "<re.Match object; span=(90, 100), match='production'>\n",
      "<re.Match object; span=(90, 100), match='production'>\n",
      "<re.Match object; span=(90, 100), match='production'>\n",
      "<re.Match object; span=(41, 51), match='production'>\n",
      "<re.Match object; span=(41, 51), match='production'>\n",
      "<re.Match object; span=(41, 51), match='production'>\n",
      "<re.Match object; span=(41, 51), match='production'>\n",
      "<re.Match object; span=(41, 51), match='production'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████████████████████████████████████████████████▉                            | 431/668 [00:02<00:01, 207.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(56, 71), match='computer vision'>\n",
      "<re.Match object; span=(65, 71), match='vision'>\n",
      "<re.Match object; span=(65, 71), match='vision'>\n",
      "<re.Match object; span=(65, 71), match='vision'>\n",
      "<re.Match object; span=(56, 71), match='computer vision'>\n",
      "<re.Match object; span=(34, 40), match='vision'>\n",
      "<re.Match object; span=(34, 40), match='vision'>\n",
      "<re.Match object; span=(25, 40), match='computer vision'>\n",
      "<re.Match object; span=(25, 40), match='computer vision'>\n",
      "<re.Match object; span=(34, 40), match='vision'>\n",
      "<re.Match object; span=(33, 43), match='production'>\n",
      "<re.Match object; span=(33, 43), match='production'>\n",
      "<re.Match object; span=(33, 43), match='production'>\n",
      "<re.Match object; span=(33, 43), match='production'>\n",
      "<re.Match object; span=(33, 43), match='production'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(90, 117), match='natural language processing'>\n",
      "<re.Match object; span=(90, 117), match='natural language processing'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(8, 14), match='vision'>\n",
      "<re.Match object; span=(72, 87), match='computer vision'>\n",
      "<re.Match object; span=(8, 14), match='vision'>\n",
      "<re.Match object; span=(72, 87), match='computer vision'>\n",
      "<re.Match object; span=(8, 14), match='vision'>\n",
      "<re.Match object; span=(40, 46), match='vision'>\n",
      "<re.Match object; span=(40, 46), match='vision'>\n",
      "<re.Match object; span=(31, 46), match='computer vision'>\n",
      "<re.Match object; span=(40, 46), match='vision'>\n",
      "<re.Match object; span=(40, 46), match='vision'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████████████████████████████████▌                      | 478/668 [00:02<00:00, 215.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(6, 33), match='natural language processing'>\n",
      "<re.Match object; span=(6, 33), match='natural language processing'>\n",
      "<re.Match object; span=(6, 33), match='natural language processing'>\n",
      "<re.Match object; span=(6, 33), match='natural language processing'>\n",
      "<re.Match object; span=(6, 33), match='natural language processing'>\n",
      "<re.Match object; span=(45, 48), match='nlp'>\n",
      "<re.Match object; span=(45, 48), match='nlp'>\n",
      "<re.Match object; span=(45, 48), match='nlp'>\n",
      "<re.Match object; span=(45, 48), match='nlp'>\n",
      "<re.Match object; span=(45, 48), match='nlp'>\n",
      "<re.Match object; span=(55, 65), match='production'>\n",
      "<re.Match object; span=(55, 65), match='production'>\n",
      "<re.Match object; span=(55, 65), match='production'>\n",
      "<re.Match object; span=(55, 65), match='production'>\n",
      "<re.Match object; span=(55, 65), match='production'>\n",
      "<re.Match object; span=(77, 80), match='nlp'>\n",
      "<re.Match object; span=(77, 80), match='nlp'>\n",
      "<re.Match object; span=(77, 80), match='nlp'>\n",
      "<re.Match object; span=(77, 80), match='nlp'>\n",
      "<re.Match object; span=(77, 80), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(59, 62), match='nlp'>\n",
      "<re.Match object; span=(59, 62), match='nlp'>\n",
      "<re.Match object; span=(59, 62), match='nlp'>\n",
      "<re.Match object; span=(59, 62), match='nlp'>\n",
      "<re.Match object; span=(59, 62), match='nlp'>\n",
      "<re.Match object; span=(17, 27), match='production'>\n",
      "<re.Match object; span=(17, 27), match='production'>\n",
      "<re.Match object; span=(17, 27), match='production'>\n",
      "<re.Match object; span=(17, 27), match='production'>\n",
      "<re.Match object; span=(17, 27), match='production'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▊                | 531/668 [00:02<00:00, 235.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(8, 11), match='nlp'>\n",
      "<re.Match object; span=(8, 11), match='nlp'>\n",
      "<re.Match object; span=(8, 11), match='nlp'>\n",
      "<re.Match object; span=(8, 11), match='nlp'>\n",
      "<re.Match object; span=(8, 11), match='nlp'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(23, 33), match='production'>\n",
      "<re.Match object; span=(21, 24), match='nlp'>\n",
      "<re.Match object; span=(21, 24), match='nlp'>\n",
      "<re.Match object; span=(21, 24), match='nlp'>\n",
      "<re.Match object; span=(21, 24), match='nlp'>\n",
      "<re.Match object; span=(21, 24), match='nlp'>\n",
      "<re.Match object; span=(57, 60), match='nlp'>\n",
      "<re.Match object; span=(57, 60), match='nlp'>\n",
      "<re.Match object; span=(57, 60), match='nlp'>\n",
      "<re.Match object; span=(57, 60), match='nlp'>\n",
      "<re.Match object; span=(57, 60), match='nlp'>\n",
      "<re.Match object; span=(0, 15), match='computer vision'>\n",
      "<re.Match object; span=(9, 15), match='vision'>\n",
      "<re.Match object; span=(0, 15), match='computer vision'>\n",
      "<re.Match object; span=(0, 15), match='computer vision'>\n",
      "<re.Match object; span=(0, 15), match='computer vision'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(66, 69), match='nlp'>\n",
      "<re.Match object; span=(122, 125), match='nlp'>\n",
      "<re.Match object; span=(122, 125), match='nlp'>\n",
      "<re.Match object; span=(122, 125), match='nlp'>\n",
      "<re.Match object; span=(122, 125), match='nlp'>\n",
      "<re.Match object; span=(122, 125), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(13, 16), match='nlp'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(53, 56), match='nlp'>\n",
      "<re.Match object; span=(53, 56), match='nlp'>\n",
      "<re.Match object; span=(0, 27), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(69, 72), match='nlp'>\n",
      "<re.Match object; span=(41, 68), match='natural language processing'>\n",
      "<re.Match object; span=(41, 68), match='natural language processing'>\n",
      "<re.Match object; span=(41, 68), match='natural language processing'>\n",
      "<re.Match object; span=(41, 68), match='natural language processing'>\n",
      "<re.Match object; span=(9, 19), match='production'>\n",
      "<re.Match object; span=(9, 19), match='production'>\n",
      "<re.Match object; span=(9, 19), match='production'>\n",
      "<re.Match object; span=(9, 19), match='production'>\n",
      "<re.Match object; span=(9, 19), match='production'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████████▍      | 612/668 [00:02<00:00, 249.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(139, 142), match='nlp'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(139, 142), match='nlp'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(49, 76), match='natural language processing'>\n",
      "<re.Match object; span=(102, 108), match='vision'>\n",
      "<re.Match object; span=(93, 108), match='computer vision'>\n",
      "<re.Match object; span=(93, 108), match='computer vision'>\n",
      "<re.Match object; span=(93, 108), match='computer vision'>\n",
      "<re.Match object; span=(93, 108), match='computer vision'>\n",
      "<re.Match object; span=(19, 34), match='computer vision'>\n",
      "<re.Match object; span=(19, 34), match='computer vision'>\n",
      "<re.Match object; span=(19, 34), match='computer vision'>\n",
      "<re.Match object; span=(28, 34), match='vision'>\n",
      "<re.Match object; span=(19, 34), match='computer vision'>\n",
      "<re.Match object; span=(27, 30), match='nlp'>\n",
      "<re.Match object; span=(27, 30), match='nlp'>\n",
      "<re.Match object; span=(16, 26), match='production'>\n",
      "<re.Match object; span=(16, 26), match='production'>\n",
      "<re.Match object; span=(27, 30), match='nlp'>\n",
      "<re.Match object; span=(7, 34), match='natural language processing'>\n",
      "<re.Match object; span=(128, 131), match='nlp'>\n",
      "<re.Match object; span=(128, 131), match='nlp'>\n",
      "<re.Match object; span=(128, 131), match='nlp'>\n",
      "<re.Match object; span=(7, 34), match='natural language processing'>\n",
      "<re.Match object; span=(14, 41), match='natural language processing'>\n",
      "<re.Match object; span=(14, 41), match='natural language processing'>\n",
      "<re.Match object; span=(14, 41), match='natural language processing'>\n",
      "<re.Match object; span=(14, 41), match='natural language processing'>\n",
      "<re.Match object; span=(14, 41), match='natural language processing'>\n",
      "<re.Match object; span=(34, 40), match='vision'>\n",
      "<re.Match object; span=(34, 40), match='vision'>\n",
      "<re.Match object; span=(25, 40), match='computer vision'>\n",
      "<re.Match object; span=(34, 40), match='vision'>\n",
      "<re.Match object; span=(25, 40), match='computer vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(64, 70), match='vision'>\n",
      "<re.Match object; span=(99, 105), match='vision'>\n",
      "<re.Match object; span=(90, 105), match='computer vision'>\n",
      "<re.Match object; span=(90, 105), match='computer vision'>\n",
      "<re.Match object; span=(99, 105), match='vision'>\n",
      "<re.Match object; span=(99, 105), match='vision'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(70, 97), match='natural language processing'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(74, 77), match='nlp'>\n",
      "<re.Match object; span=(0, 15), match='computer vision'>\n",
      "<re.Match object; span=(9, 15), match='vision'>\n",
      "<re.Match object; span=(9, 15), match='vision'>\n",
      "<re.Match object; span=(0, 15), match='computer vision'>\n",
      "<re.Match object; span=(0, 15), match='computer vision'>\n",
      "<re.Match object; span=(119, 125), match='vision'>\n",
      "<re.Match object; span=(119, 125), match='vision'>\n",
      "<re.Match object; span=(119, 125), match='vision'>\n",
      "<re.Match object; span=(119, 125), match='vision'>\n",
      "<re.Match object; span=(119, 125), match='vision'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 668/668 [00:03<00:00, 214.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(56, 66), match='production'>\n",
      "<re.Match object; span=(56, 66), match='production'>\n",
      "<re.Match object; span=(56, 66), match='production'>\n",
      "<re.Match object; span=(56, 66), match='production'>\n",
      "<re.Match object; span=(56, 66), match='production'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(106, 109), match='nlp'>\n",
      "<re.Match object; span=(51, 56), match='mlops'>\n",
      "<re.Match object; span=(51, 56), match='mlops'>\n",
      "<re.Match object; span=(51, 56), match='mlops'>\n",
      "<re.Match object; span=(51, 56), match='mlops'>\n",
      "<re.Match object; span=(51, 56), match='mlops'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(35, 38), match='nlp'>\n",
      "<re.Match object; span=(35, 38), match='nlp'>\n",
      "<re.Match object; span=(35, 38), match='nlp'>\n",
      "<re.Match object; span=(35, 38), match='nlp'>\n",
      "<re.Match object; span=(35, 38), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(0, 3), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(11, 14), match='nlp'>\n",
      "<re.Match object; span=(54, 64), match='production'>\n",
      "<re.Match object; span=(54, 64), match='production'>\n",
      "<re.Match object; span=(54, 64), match='production'>\n",
      "<re.Match object; span=(54, 64), match='production'>\n",
      "<re.Match object; span=(54, 64), match='production'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n",
      "<re.Match object; span=(29, 39), match='production'>\n",
      "<re.Match object; span=(29, 39), match='production'>\n",
      "<re.Match object; span=(19, 22), match='nlp'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huggingtweets tweet generation huggingface</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selfie2anime tflite end end tutorial tensorflo...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>introduction q learning reinforcement learning...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>holopix50k large scale wild stereo image datas...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlops machine learning operations mlops best p...</td>\n",
       "      <td>mlops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0         huggingtweets tweet generation huggingface   \n",
       "1  selfie2anime tflite end end tutorial tensorflo...   \n",
       "2  introduction q learning reinforcement learning...   \n",
       "3  holopix50k large scale wild stereo image datas...   \n",
       "4  mlops machine learning operations mlops best p...   \n",
       "\n",
       "                           tag  \n",
       "0  natural-language-processing  \n",
       "1              computer-vision  \n",
       "2                        other  \n",
       "3              computer-vision  \n",
       "4                        mlops  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation function (TF) policy\n",
    "policy = ApplyOnePolicy(n_per_original=5, keep_original=True)\n",
    "tf_applier = PandasTFApplier([swap_aliases], policy)\n",
    "train_df_augmented = tf_applier.apply(train_df)\n",
    "train_df_augmented.drop_duplicates(subset=[\"text\"], inplace=True)\n",
    "train_df_augmented.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55d3496d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 903)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(train_df_augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76e60f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f4d7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10c8e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, lower, stem, min_freq):\n",
    "    \"\"\"Preprocess the data.\"\"\"\n",
    "    df[\"text\"] = df.title + \" \" + df.description  # feature engineering\n",
    "    df.text = df.text.apply(clean_text, lower=lower, stem=stem)  # clean text\n",
    "\n",
    "    # Replace OOS tags with `other`\n",
    "    oos_tags = [item for item in df.tag.unique() if item not in ACCEPTED_TAGS]\n",
    "    df.tag = df.tag.apply(lambda x: \"other\" if x in oos_tags else x)\n",
    "\n",
    "    # Replace tags below min_freq with `other`\n",
    "    tags_above_freq = Counter(tag for tag in tags.elements()\n",
    "                            if (tags[tag] >= min_freq))\n",
    "    df.tag = df.tag.apply(lambda tag: tag if tag in tags_above_freq else None)\n",
    "    df.tag = df.tag.fillna(\"other\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2dbda36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(X, y, train_size=0.7):\n",
    "    \"\"\"Generate balanced data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(\n",
    "        X, y, train_size=train_size, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06592aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True)  # shuffle\n",
    "# df = df[: num_samples]  # None = all samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "035c2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "82666507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "set_seeds()\n",
    "df = pd.read_csv(\"labeled_projects.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "label_encoder = LabelEncoder().fit(df.tag)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ec2136d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LabelEncoder(num_classes=4)>\n",
      "['computer-vision', 'mlops', 'natural-language-processing', 'other']\n"
     ]
    }
   ],
   "source": [
    "# Label encoder\n",
    "print (label_encoder)\n",
    "print (label_encoder.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f46577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d588f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n",
      "[2 2 1 3 3]\n",
      "{\n",
      "  \"precision\": 0.2844744487889649,\n",
      "  \"recall\": 0.22916666666666666,\n",
      "  \"f1\": 0.24552884283001275\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate random predictions\n",
    "y_pred = np.random.randint(low=0, high=len(label_encoder), size=len(y_test))\n",
    "print (y_pred.shape)\n",
    "print (y_pred[0:5])\n",
    "\n",
    "# Evaluate\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b532217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b46dfd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.375, 0.08333333333333333, 0.4027777777777778, 0.1388888888888889]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class frequencies\n",
    "p = [Counter(y_test)[index]/len(y_test) for index in range(len(label_encoder))]\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "57fc98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate weighted random predictions\n",
    "y_pred = np.random.choice(a=range(len(label_encoder)), size=len(y_test), p=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d91ca52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.3294211281499417,\n",
      "  \"recall\": 0.3194444444444444,\n",
      "  \"f1\": 0.3239553132352485\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487e246",
   "metadata": {},
   "source": [
    "# Rule Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c45730ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "set_seeds()\n",
    "df = pd.read_csv(\"labeled_projects.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "label_encoder = LabelEncoder().fit(df.tag)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d1e507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(text, aliases_by_tag):\n",
    "    \"\"\"If a token matches an alias,\n",
    "    then add the corresponding tag class.\"\"\"\n",
    "    for tag, aliases in aliases_by_tag.items():\n",
    "        if replace_dash(tag) in text:\n",
    "            return tag\n",
    "        for alias in aliases:\n",
    "            if alias in text:\n",
    "                return tag\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed903b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_dash('nlp') in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "15430d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural-language-processing'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "text = \"A pretrained-model hub for popular nlp models.\"\n",
    "get_tag(text=clean_text(text), aliases_by_tag=aliases_by_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "831adf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "tags = []\n",
    "for text in X_test:\n",
    "    tag = get_tag(text, aliases_by_tag=aliases_by_tag)\n",
    "    tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "00dd6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [label_encoder.class_to_index[tag] if tag is not None else -1 for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e185a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8611111111111112,\n",
      "  \"recall\": 0.1597222222222222,\n",
      "  \"f1\": 0.2600750175139683\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfbe9c",
   "metadata": {},
   "source": [
    "'''Why is recall so low?\n",
    "\n",
    "How come our precision is high but our recall is so low?\n",
    "\n",
    "Only relying on the aliases can prove catastrophic when those particular aliases aren't used in our input signals. To improve this, we can build a bag of words of related terms. For example, mapping terms such as text classification and named entity recognition to the natural-language-processing tag but building this is a non-trivial task. Not to mention, we'll need to keep updating these rules as the data landscape matures.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b34d6749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Pitfalls\n",
    "text = \"Transfer learning with transformers for text classification.\"\n",
    "print (get_tag(text=clean_text(text), aliases_by_tag=aliases_by_tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2dd3a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "democraci\n",
      "democraci\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print (stemmer.stem(\"democracy\"))\n",
    "print (stemmer.stem(\"democracies\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d82f15",
   "metadata": {},
   "source": [
    "Limitations: we failed to generalize or learn any implicit patterns to predict the labels because we treat the tokens in our input as isolated entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1146af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0789ad99",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'elements'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19576\\3433179518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labeled_projects.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19576\\794839814.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(df, lower, stem, min_freq)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Replace tags below min_freq with `other`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     tags_above_freq = Counter(tag for tag in tags.elements()\n\u001b[0m\u001b[0;32m     12\u001b[0m                             if (tags[tag] >= min_freq))\n\u001b[0;32m     13\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtags_above_freq\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'elements'"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "set_seeds()\n",
    "df = pd.read_csv(\"labeled_projects.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "label_encoder = LabelEncoder().fit(df.tag)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e2baad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving raw X_test to compare with later\n",
    "X_test_raw = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2157bea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laplacian pyramid reconstruction refinement semantic seg pytorch implementation multi resolution reconstruction architecture based laplacian pyramid uses skip connections\n",
      "(668, 98496)\n"
     ]
    }
   ],
   "source": [
    "# Tf-idf\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,7))  # char n-grams\n",
    "print (X_train[0])\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "print (X_train.shape)  # scipy.sparse.csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee1b5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: [249  55 272  92],\n",
      "class weights: {0: 0.004016064257028112, 1: 0.01818181818181818, 2: 0.003676470588235294, 3: 0.010869565217391304}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d21d54",
   "metadata": {},
   "source": [
    "### Data imbalance\n",
    "With our datasets, we may often notice a data imbalance problem where a range of continuous values (regression) or certain classes (classification) may have insufficient amounts of data to learn from. This becomes a major issue when training because the model will learn to generalize to the data available and perform poorly on regions where the data is sparse. There are several techniques to mitigate data imbalance, including resampling, incorporating class weights, augmentation, etc. Though the ideal solution is to collect more data for the minority classes!\n",
    "\n",
    "We'll use the imblearn package to ensure that we oversample our minority classes to be equal to the majority class (tag with most samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c26b7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bba9345d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['huggingtweets tweet generation huggingface'\n 'selfie2anime tflite end end tutorial tensorflow lite selfie2anime u gat'\n 'introduction q learning reinforcement learning q learning algorithm along implementation python using numpy'\n 'holopix50k large scale wild stereo image dataset largest dataset wild stereo image pairs 50k crowd sourced holopix lightfield image sharing social network'\n 'mlops machine learning operations mlops best practices businesses run ai successfully help expanding software products cloud services'\n 'github actions machine learning workflows hamel husain talk hamel provide brief tutorial github actions show use new tool automate ml workflows'\n 'bleurt learning robust metrics text generation metric natural language generation based transfer learning'\n 'ai medicine imaging stanford symposium 2020 aimi symposium hope address gaps barriers field catalyze evidence based solutions improve health'\n 'advanced deep learning computer vision adl4cv visual computing group offers variety lectures seminars regular basis covering hot areas computer graphics vision machine learning'\n 'generating soap notes doctor patient conversations evaluate complete pipelines leveraging transcripts train machine learning model generate notes'\n 'automatically generate multiple choice questions mcqs automatically generate multiple choice questions mcqs content bert summarizer wordnet conceptnet'\n 'cognito data wrangling toolkit cognito exclusive python data preprocessing library command line utility helps developer transform raw data machine learning format'\n 'fashionbert text image matching adaptive loss cross modal retrieval'\n 'onnx transformers accelerated nlp pipelines fast inference cpu built transformers onnx runtime'\n 'meta learning shot natural language processing survey clear definitions progress summary common datasets applying meta learning shot nlp'\n 'colbert ai colbert ai deep learning language model generates text style stephen colbert famous monologues'\n 'codebert masked language model source code tutorial use codebert mlm python code model trained scratch using roberta'\n 'learning dexterity end end trained human like robot hand manipulate physical objects unprecedented dexterity'\n 'gutenberg dialog build dialog dataset online books many languages'\n 'txtai ai powered search engine ai powered search engine'\n 'trackable project deals tracking humans narrow hallway different lighting conditions'\n 'first order motion model image animation generating video sequence object source image animated according motion driving video'\n 'favorite recipes computer vision deep learning blog post enlists favorite recipes deep learning context computer vision august 2020'\n 'transformer explained intuitive explanation transformer motivating lens cnns rnns etc'\n 'googletrans googletrans free unlimited google translate api python translates totally free charge'\n 'fruit detection using convolution neural networks tensorflow trained convolutional neural network model predict fruits 100 classes types training accuracy 95 testing accuracy 9'\n 'solaris cosmiq works geospatial machine learning analysis toolkit'\n 'data augmentation recipes tf keras image based models learn different ways data augmentation training image classifier tf keras'\n 'simgnn pytorch implementation simgnn neural network approach fast graph similarity computation wsdm 2019'\n 'battle tested techniques scoping machine learning projects one challenges managing ml project project scoping even small changes data architecture create huge differences model outputs'\n 'annotated transformer post present annotated version paper form line line implementation'\n 'lstm forecast model stock price prediction using keras easy understand lstm forecast model stock price prediction dataset contains daywise details googl stock may 2019 may 2018'\n 'tapas weakly supervised table parsing via pre training using neural networks find answers tables'\n 'scispacy full spacy pipeline models scientific biomedical documents'\n 'mixnmatch multifactor disentanglement encoding conditional image generation'\n 'introduction transfer learning huggingface talk start introducing recent breakthroughs nlp resulted combination transfer learning schemes transformer architect'\n 'illustrated word2vec post go concept embedding mechanics generating embeddings word2vec'\n 'highres net multi frame super resolution satellite imagery pytorch implementation highres net neural network multi frame super resolution trained tested european space agency kelvin competition'\n 'keras notifications slack get slack notifications model training progress training keras tf keras'\n 'rlx modular deep rl library research rlx deep rl library written top pytorch built educational research purpose'\n 'applying modern best practices autoencoders project applies best modern practices found areas image research autoencoders comparing models areas image research'\n 'melanoma detection pytorch video show build deep learning model detect melanoma high accuracy'\n 'illustrated transformer post look transformer model uses attention boost speed models trained'\n 'tokenizers machines read survey different tokenization strategies nlp'\n 'ensemble forecasts time series forecasting using classical methods ets holt winter sarima prophet show discuss advantages ensemble forecast'\n 'zero shot topic classification bart classification head trained mnli'\n 'barebones image retrieval system project presents simple framework retrieve images similar query image'\n 'cs285 deep reinforcement learning course deep reinforcement learning transfer multi task learning'\n 'data science meets devops mlops jupyter git kubernetes end end example deploying machine learning product using jupyter papermill tekton gitops kubeflow'\n 'natural language processing news get highlights natural language processing machine learning research industry straight inbox every month'\n 'search visual datasets task application class label format'\n 'create semantic search arbitrary objects end end example build system search objects semantically hamel husain ho hsiang wu'\n 'emotion recognition tom jerry videos developed application classifies emotion depicted tom jerry frame one following happy angry sad suprised'\n 'switched flask fastapi production ml popular tool always best'\n 'segmentation models segmentation models pretrained backbones keras tensorflow keras'\n 'controlling text generation plug play language models article discusses alternative approach controlled text generation titled plug play language model pplm'\n 'bart version closed book qa bart version sequence sequence model open domain qa closed book setup based pytorch huggingface transformers'\n 'summary transformers models high level summary differences model huggingface transformer library'\n 'attention attention post gonna look attention invented various attention mechanisms models transformer snail'\n 'effects news sentiments stock predictions project based natural language processing technique called sentiment analysis stock market news related subject analysis'\n 'autonomous learning library pytorch library building deep reinforcement learning agents'\n 'curriculum reinforcement learning curriculum learning applied reinforcement learning exceptions supervised learning'\n 'research guide data scientists tips research top data scientists'\n 'workshop scalability autonomous driving andrej karpathy overview autonomous driving computer vision tesla'\n 'sentencepiece unsupervised text tokenizer neural network based text generation'\n 'understanding convolutional neural networks nlp recently also started apply cnns problems natural language processing gotten interesting results'\n 'azure machine learning template azure machine learning template mnist classifier'\n 'visual guide using bert first time tutorial use variant bert classify sentences'\n 'bit exploring large scale pre training compute excited share best bit models pre trained public datasets along code tf2 jax pytorch'\n 'sadedegel extraction based turkish news summarizer sadede gel turkish means cut chase'\n 'implementation contextual chatbot pytorch simple chatbot implementation pytorch'\n 'ner model 40 languages trained new tftrainer model fine tuned xlm roberta base 40 languages proposed xtreme wikiann'\n 'change detection using siamese networks blog primer siamese networks used observing change satellite images time observing facial changes people age'\n 'funnel transformer filtering sequential redundancy funnel transformer self attention model gradually compresses sequence hidden states shorter one hence reduces computation cost'\n 'detext deep neural text understanding framework detext deep neural text understanding framework ranking classification tasks'\n 'look inside workings label smoothing blog post describes trick label smoothing improves model accuracy use'\n 'history language models alec radford quick history language models'\n 'simclr tensorflow 2 minimally implements simclr  arxiv org abs 2002 05709 tensorflow 2'\n 'universal adversarial triggers attacking analyzing nlp create short phrases cause specific model prediction concatenated input dataset'\n 'nlp newsletter democratizing artificial intelligence research education technologies'\n 'model based reinforcement learning survey survey integration fields better known model based reinforcement learning'\n 'u net deep learning colorization greyscale images article describes experiments training neural network generate 3 channel colour images single channel greyscale images using deep learning'\n 'attentionwalk pytorch implementation watch step learning node embeddings via graph attention neurips 2018'\n 'delight deep light weight transformers similar better performance transformer based models significantly fewer parameters'\n 'implementing portrait bokeh mode using opencv numpy python love portrait mode smartphone code help using opencv numpy detects faces asks want blur'\n 'q bert agents build knowledge graphs explore textual worlds asking questions'\n 'single stage semantic segmentation image labels attain competitive results training single network model segmentation self supervised fashion using image level annotations'\n 'deep learning videos 2018 guide action recognition post summarize literature action recognition videos'\n 'anomaly detection keras tensorflow deep learning perform anomaly detection image datasets using deep learning'\n 'comment classification using bert multi language fine tuning going use bert layer model applying keras'\n 'training image classifier pytorch torchvision data loaders common datasets imagenet cifar10 mnist etc data transformers images vizualization data loaders'\n 'text classification using bert tensorflow hub tutorial helps learn bert models classification task tweet dataset'\n 'stumpy powerful scalable python library time series stumpy powerful scalable python library computing matrix profile used variety time series data mining tasks'\n 'azure ml mlops using azure ml'\n 'building level 3 conversational ai assistants presentations panels fireside chats addressing topics related creation level 3 ai assistants'\n 'abstraction reasoning corpus arc computer learn complex abstract tasks examples arc used measure human like form general fluid intelligence'\n 'transfer learning t5 text text transfer transformer paper demonstrate achieve state art results multiple nlp tasks using text text transformer pre trained large text corpus'\n 'introduction adversarial examples deep learning report provides intuitive introduction adversarial examples discusses wide variety different adversarial attacks notably provides ad'\n 'pytorch geometric temporal temporal extension library pytorch geometric'\n 'diverse image generation via self conditioned gans simple effective unsupervised method generating realistic diverse images using class conditional gan model without using manually annotated class'\n 'flashtorch visualization toolkit neural networks pytorch'\n 'machine learning pipelines kubeflow kubeflow pipelines reusable end end ml workflows built using kubeflow pipelines sdk'\n 'part 2 deep representations way towards neural style transfer top approach conceiving neural style transfer'\n 'deepdream video style transfer deepdream video'\n 'parallelizing prophet cross validation dask applied example w code'\n 'nlp beyond english 7000 languages spoken around world nlp research mostly focused english post outlines work languages eng'\n 'face predicting web app interactive deep learning model utilizes computer webcam predict age gender seconds'\n 'simple transformers transformers classification ner qa language modeling language generation t5 multi modal conversational ai'\n 'capsule graph neural network pytorch implementation capsule graph neural network iclr 2019'\n 'need deep graph neural networks depth graph neural network architectures bring advantage'\n 'generate true false questions content automatically generate true false questions like ones see school textbooks using openai gpt2 sentence bert berkley parser'\n 'spaczz fuzzy matching spacy fuzzy matching functionality spacy'\n 'graphein protein graph library'\n 'v2v posenet pytorch pytorch implementation v2v posenet integralpose posefix loss'\n 'deepclas4bio deepclas4bio project aims facilitate interoperability bioimaging tools deep learning frameworks'\n 'unet implementation keras gpu vector map generation aerial imagery using deep learning geospatial unet'\n 'evolution representations transformer evolution representations individual tokens transformers trained different training objectives mt lm mlm bert style'\n 'replicating airbnb amenity detection documentary series airbnb engineering team shared article used computer vision detection amenities photos read like recipe replicated'\n 'unpopular opinion data scientists end end believe data scientists effective end end'\n 'ailight automatic highlighting using bert automatically highlight pdfs using bert embeddings clustering  anishthite github io ailight'\n 'pyimagesearch online platform blogs computer vision deep learning'\n 'tuned albert ensemble model top 6 squad 2 0'\n 'nerf neural radiance fields representing scenes neural radiance fields view synthesis'\n 'explore execute adapting without rewards via factorized meta reinforcement learning'\n 'accelerate nlp pipelines using hugging face onnx onnx runtime team hugging face working together address challenges training deployment transformer models'\n 'data quality key successful ml ops look ml ops highlight data quality key ml ops workflows'\n 'explainable ml monitoring video covers overview risks ai need explainable monitoring exactly mean talk'\n 'self supervised representation learning get labels free unlabelled data train unsupervised dataset supervised manner'\n 'back translation text augmentation google sheets learn augment existing labeled text data free using google sheets'\n 'tensorflow serving flexible high performance serving system machine learning models designed production environments'\n 'omega ml building deploying ml models easy way deploying ml hard omega ml makes breeze'\n 'visual survey data augmentation nlp extensive overview text data augmentation techniques natural language processing'\n 'comprehensive analysis important metrics ml work authors present comprehensive analysis important metrics practical applications'\n 'unsupervised toolbox unsupervised learning tool box micro framework state art methods models unsupervised learning nlu nlg'\n 'gotchas transfer learning image classification discover things care transfer learning image classification'\n 'deep love transfer learning nlp review nlp research'\n 'set python project automation collaboration set python repo unit tests code coverage lint checking type checking makefile wrapper automated build github actions'\n 'gpt 3 model simply knows brief introduction gigantic gpt 3 new leap ai natural language processing'\n 'awesome deep rl project built people learning researching latest deep reinforcement learning methods'\n 'remo python lib remo app annotations images management computer vision'\n 'survey long term context transformers past two years nlp community developed veritable zoo methods combat expensive multi head self attention'\n 'low dimensional hyperbolic knowledge graph embeddings low dimensional knowledge graph embeddings simultaneously capture hierarchical relations logical patterns'\n 'quick draw neural network learn recognize doodling'\n 'deep learning techniques nlp healthcare talk discussing recent advancements deep learning facilitate adaption nlp healthcare domain'\n 'dpod pose estimator pytorch recreation sota 6d pose estimation research paper'\n 'text summarization using tf idf algorithm article explains tf idf algorithm shows implemtnation scratch summarize text'\n 'reinforcement learning tic tac toe value function reinforcement learning algorithm agents learn tic tac toe using value function'\n 'linformer self attention linear complexity demonstrate self attention mechanism approximated low rank matrix'\n 'recipes building open domain chatbot python framework sharing training testing dialogue models open domain chitchat vqa visual question answering'\n 'python implementation reinforcement learning introduction plot replications exercise solutions anki flashcards entire book chapters'\n 'adapterhub framework adapting transformers huggingface transformers adapters'\n 'tempering expectations gpt 3 openai api closer look magic behind gpt 3 caveats aware'\n 'paraphrase question t5 text text transformer given question generate paraphrased versions question t5 transformer pretrained model training script provided'\n 'pruning bert accelerate inference previously discussing various ways accelerating models like bert blog post empirically evaluate pruning approach'\n 'divide hugging face transformers training time 2 reducing training time helps iterate fixed budget time thus achieve better results'\n 'adversarial latent autoencoders introducing adversarial latent autoencoder alae general architecture leverage recent improvements gan training procedures'\n 'biobert pre trained biomedical language representation model code fine tuning biobert biomedical text mining tasks biomedical ner relation extraction qa etc'\n 'reinforcement learning tutorial important reinforcement learning rl algorithms including policy iteration q learning neural fitted q'\n 'face alignment full pose range 3d total solution face alignment full pose range 3d total solution'\n 'cnn see first super clean notebook showcasing tensorflow 2 0 example end end dl interpretability'\n 'learning summarize human feedback human feedback models outperform much larger supervised models reference summaries tl dr'\n 'stylegan encoder encodes real images latent space stylegan model'\n 'u 2 net code newly accepted paper pattern recognition 2020 u 2 net going deeper nested u structure salient object detection'\n 'automatic translation squad dataset spanish machine translation used squad dataset produce equivalent dataset spanish word alignment applied produce synthetic spanisqa corpus'\n 'dark secrets bert much linguistically interpretable self attention patterns presumed strength actually used solve downstream tasks'\n 'gentle introduction text summarization machine learning text summarization technique generating concise precise summary voluminous texts focusing sections convey useful info'\n 'lazynlp library scrape clean web pages create massive datasets'\n 'pytest pytest framework makes easy write small tests yet scales support complex functional testing'\n 'great expectations always know expect data'\n 'building covid 19 project recommendation system create github open source repo recommendation system web app mlflow sagemaker booklet ai'\n 'electra electra pre training text encoders discriminators rather generators'\n 'machine learning tests production best practices testing ml based systems'\n 'interactive analysis sentence embeddings learn interactively explore sentence embedding labels tensorflow embedding projector'\n 'streamalert serverless realtime data analysis framework empowers ingest analyze alert data environment using datasources alerts'\n 'document search engine nlp based search engine single page pdf files'\n 'wikiart stylegan 2 model conditional stylegan 2 model trained images wikiart'\n 'gpt 3 language model technical overview technical details gpt 3 model training inference expect next'\n 'genomic ulmfit ulmfit genomic sequence data'\n 'evolution strategies evolutionary algorithms refer division population based optimization algorithms inspired natural selection'\n 'huggingtweets streamlit app built around huggingtweets project fine tune pre trained gpt2 model tweet like user given twitter handle'\n 'blink better entity linking entity linking python library uses wikipedia target knowledge base'\n 'torchcde differentiable controlled differential equation solvers pytorch gpu support memory efficient adjoint backpropagation'\n 'serverless bert huggingface aws lambda build serverless question answering api bert huggingface serverless framework aws lambda'\n 'coloring greyscale images coloring black white images neural networks'\n 'image smoothing via l0 gradient minimization edge aware image smoothing algorithm algorithm tries smoothen image preserving global structural information image'\n 'openai api api accessing new ai models developed openai'\n 'transformertts transformer tts implementation non autoregressive transformer based neural network text speech'\n 'openmmlab computer vision mmcv python library cv research supports many research projects object detection segmentation pose estimation action classification'\n 'extracting structured data templatic documents automatically extract data structured documents invoices receipts etc potential streamline many business workflows'\n 'structured self attention implementation paper structured self attentive sentence embedding  arxiv org abs 1703 03130 model interpretability explainability'\n 'open compound domain adaptation pytorch implementation open compound domain adaptation'\n 'font recognition using deep learning deepfont adobe deepfont paper technique created adobe inc detect font images using deep learning published work paper public'\n 'nlp developers shrinking transformers rasa video rasa senior developer advocate rachael talk different approaches make transformer models smaller'\n 'future transfer learning natural language processing transfer learning natural language processing nlp open questions current trends limits future directions'\n 'pix2pix tf js implementation web friendly ml models using tensorflow js pix2pix face segmentation fast style transfer many'\n 'almost everything need know time series understand moving average exponential smoothing stationarity autocorrelation sarima'\n 'practical guide building conversational chatbot building chatbot scratch using keras nltk library customer service company'\n 'doc2vec paragraph embeddings text classification text classification model uses gensim doc2vec generating paragraph embeddings scikit learn logistic regression classification'\n 'nlp evolved financial sentiment analysis still need humans read boring financial statements'\n 'sentiment analysis key milestones challenges new directions overview sentiment analysis progress ahead'\n 'image classifier browser using tensorflow js make prediction directly browser'\n 'show tell neural image caption generator tensorflow implementation image text model'\n 'python template projects template gives batteries required package code ci checks auto build deploy docs easy pypi publishing support docker files'\n 'text classification torchtext example shows train supervised learning algorithm classification using one textclassification datasets'\n 'wav2lip accurately lip syncing videos wild lip sync expert need speech lip generation wild'\n 'visual exploration deepcluster deepcluster self supervised method combine clustering representation learning'\n 'attribute2font creating fonts want attributes official pytorch implementation attribute2font creating fonts want attributes'\n 'leafy plant leaf classifier sequential model trained images leafsnap com'\n 'sentiment analysis sentiment analysis combining three dataset amazon yelp imdb reviews train model classify comment negative positive denoted 0 1'\n 'finetuning transformers jax haiku walking port roberta pre trained model jax haiku fine tuning model solve downstream task'\n 'steal modern nlp systems gibberish possible steal bert based models without real training data even using gibberish word sequences'\n 'illustrated guide transformers component component breakdown analysis'\n 'build robust embeddings visual similarity tasks repository package bunch tips tricks efficiently train deep learning models computer vision'\n 'super resolution variational auto encoders vae realnvp prior super resolution vae pytorch'\n 'neural style transfer gatys et al pytorch implementation original neural style transfer paper gatys et al pytorch'\n 'identifying brain tumor mri images using fastai dynamicunet use fastai unet learner identify tumours mri brain logging loss metrics neptune ai logger compare results hyperparameter tuning'\n 'limitations deep learning vision might fix opinion paper strengths weaknesses deep nets vision'\n 'deepkitai open source machine learning devtool training suite'\n 'pytorch faster rcnn fine tune faster rcnn pytorch task'\n 'understanding effectivity ensembles deep learning report explores ideas presented deep ensembles loss landscape perspective stanislav fort huiyi hu balaji lakshminarayanan'\n 'medicalzoo pytorch pytorch based deep learning framework multi modal 2d 3d medical image segmentation'\n 'genrl genrl pytorch first reinforcement learning library centered around reproducible generalizable algorithm implementations'\n 'transformers hugging face transformers state art natural language processing tensorflow 2 0 pytorch'\n 'rxnmapper unsupervised attention guided atom mapping atom mapping information learned albert model trained unsupervised fashion large dataset chemical reactions'\n 'convnet galaxy morphology classifier classify galaxies hubble tuning fork using convnet'\n 'tensorflow js gesture controlled 2048 gesture controlled 2048 built tensorflow js'\n 'building footprint extraction project retrieves satellite imagery google performs building footprint extraction using u net'\n 'autocoder finetuning gpt 2 auto code completion basic simple tool code auto completion built upon gpt 2'\n 'nlp model selection nlp model selection guide make easier select models prescriptive nature used caution'\n 'time series prediction lstm using pytorch time series applied forecasting airplane passengers dataset'\n 'nlp news category objective repository create nlp bot give robot headline news short description return genre'\n 'using jax improve separable image filters optimizing filters improve filtered images computer vision tasks'\n 'quantifying attention flow transformers explain two simple effective methods called attention rollout attention flow'\n 'top2vec top2vec learns jointly embedded topic document word vectors'\n 'bertviz tool visualizing attention transformer model bert gpt 2 albert xlnet roberta ctrl etc'\n 'tensorflow pytorch transformer fastai etc tutorials bert classification question answering seq2seq machine translation contextual topic modeling large scale multilabelclassification etc'\n 'attention mechanism main concepts behind attention including implementation sequence sequence attention model followed application attention transformers'\n 'neural topological slam visual navigation topological representations space effectively leverage semantics afford approximate geometric reasoning'\n 'large scale open domain mixed interface dialogue based korbit large scale open domain mixed interface dialogue based intelligent tutoring system'\n 'message passing query embedding mpqe model answering complex queries knowledge graphs learns embeddings entities knowledge graph embeddings variable types'\n 'intellicode compose code generation using transformer code completion tool capable predicting sequences code tokens arbitrary types generating entire lines syntactically correct code'\n 'set continuous integration machine learning set continuous integration machine learning github actions neptune step step guide'\n 'reverse image search ever wondered google image search works amazon retrieve products similar image upload app site achieve ta'\n 'illustrated gpt 2 visualizing transformer language models visuals explaining inner workings transformers'\n 'beginner guide machine learning model deployment beginner field machine learning wondering bring project live situation started learning ml'\n 'automatic face detection annotation preprocessing automatically detect annotate collect coordinates convert csv tfrecord'\n 'image image translation conditional adversarial networks tensorflow port image image translation conditional adversarial nets'\n 'pix2pix tensorflow 2 0 implementation paper image image translation using conditional gans philip isola jun yan zhu tinghui zhou alexei efros'\n 'landcover ai dataset automatic mapping buildings woodlands water aerial imagery'\n 'fast online object tracking segmentation unifying approach illustrate perform realtime object tracking semi supervised video object segmentation using fully convolutional siamese approach'\n 'intro autoencoders tutorial introduces autoencoders three examples basics image denoising anomaly detection'\n 'dgl deep graph library python package built ease deep learning graph top existing dl frameworks'\n 'cycle gan tensorflow 2 0 custom loops implementation unpaired image image translation using cycle consistent adversarial networks jun yan zhu et al'\n 'short notes model based offline reinforcement learning morel blog article model based offline reinforcement learning morel paper rahul kidambi aravind rajeswaran et al'\n 'huggingface nlp library nlp lightweight extensible library easily share load dataset evaluation metrics already providing access 100 datasets 10 evaluatio'\n 'ml foundations methods precision medicine healthcare tutorial discuss ideas machine learning enable personalization useful applications education retail medicine recsys'\n 'introduction image inpainting deep learning article going learn image inpainting e fill missing parts images precisely using deep learning'\n 'build textual similarity web app tensorflow js wondered search engines understand queries retrieve relevant results chatbots extract intent questions provide'\n 'gru transformer recurrent units self attention related'\n 'act github actions locally run github actions locally'\n 'ai basketball analysis ai web app api analyze basketball shots shooting pose'\n 'bert distillation catalyst distill bert catalyst'\n 'cs231n convolutional neural networks visual recognition deep dive details deep learning architectures focus learning end end models tasks particularly image classification'\n 'codequestion ask coding questions directly terminal'\n 'graph nets pytorch implementation explanation graph representation learning papers involving deepwalk gcn graphsage chebnet gat'\n 'vilbert mt multi task vision language representation learning single vilbert multi task model perform 8 different vision language tasks learnt 12 datasets'\n 'exploratory data analysis ms coco style datasets simple toolkit exploratory data analysis ms coco style formatted datasets'\n 'spinenet novel architecture object detection meta architecture called scale permuted model enables two major improvements backbone architecture design iscovered neural architecture search'\n 'efficient transformers survey characterizes large thoughtful selection recent efficiency flavored x former models'\n 'imagenette imagenette subset 10 easily classified classes imagenet'\n 'unsupervised reinforcement learning lecture unsupervised reinforcement learning sergey levine originally prepared aamas 2020'\n 'literate lamp answering question common sense study problem answering questions require common sense answered using transformer based models conceptnet knowledge base'\n 'bert loses patience fast robust inference early exit patience based early exit inference method used plug play technique simultaneously improve efficiency pretrained lm'\n 'cybert applying bert windows event logs blog shows interpreting cybersecurity logs natural language improving upon standard regex based parsing log data'\n 'fast neural style pytorch implementation algorithm artistic style transfer'\n 'keeping data pipelines healthy w great expectations gh actions show use github actions together open source project great expectations automatically test document profile data pipelines'\n 'fine tuning custom datasets tutorial take several examples using transformers models datasets'\n 'imaginaire nvidia pytorch gan library distributed mixed precision support'\n 'textaugment improving short text classification global augmentation methods'\n 'unsupervised learning probably symmetric deformable 3d objects method learn 3d deformable object categories raw single view images without external supervision'\n 'stackover flow data analysis analysing certain aspects stack overflow data creating tag predictor predicts tag based post posted'\n 'traffic sign recognition using deep learning training dataset contains around 39 000 images test dataset contains around 12 000 images containing 43 different classes using convolutio'\n 'safe space github action github action checks toxicity level comments pr reviews help make repos safe spaces'\n 'synthesizer rethinking self attention transformer models dot product self attention known central indispensable state art transformer models really required'\n 'pdftableextract build parser extract table pdf document retinanet'\n 'roberta meets tpus understanding applying roberta model current challenge'\n 'detectron2 fair next generation platform object detection segmentation'\n 'iyasai book recommendation system recommender system books stories could help loved ones lift mood whenever facing stress unpleasant situations'\n 'entity embedding lstm time series demonstration using lstm forecasting structured time series data containing categorical numerical features'\n 'biosyn biomedical entity representations synonym marginalization'\n 'implementing dcgans using pytorch c api libtorch blog discusses paper review dcgans implementation using pytorch c api detail loading models visualizing batch data c'\n 'object tracking 75 lines code object tracking straightforward conceptually good detector simple methods pretty effective'\n 'harry potter deep learning experiment rnn built tensorflow generate text based harry potter books'\n 'distributional rl using tensorflow2 implementation various distributional reinforcement learning algorithms using tensorflow2'\n 'smart picture editor tool automatically remove unwanted objects photos'\n 'lagrangian neural networks trying learn simulation try lagrangian neural networks explicitly conserve energy may generalize better'\n 'text preprocessing python using spacy library article explored text preprocessing python using spacy library detail fundamental step prepare data applications'\n 'top research papers ecml pkdd 2020 conference ecml pkdd selectionof best reaesch papers'\n 'pytest board continuous pytest runner awesome visualization'\n 'tracking objects points simultaneous object detection tracking using center points'\n 'spacy go spacy go golang interface accessing linguistic annotations provided spacy using google grpc module supports basic functionalities like lo'\n 'image gpt generative pretraining pixels transformers trained pixel sequences generate coherent image completions samples'\n 'neural cdes long time series via log ode method ncdes long time series via log ode method'\n 'learned looking 200 machine learning tools better understand landscape available tools machine learning production decided look every ai ml tool could find'\n 'bachgan high res image synthesis salient object layout propose new task towards practical application image generation high quality image synthesis salient object layout'\n 'arima modeling guide time series forecasting python arima models works train forecast using arima sarima sarimax find optimal model python'\n 'humour ai language model crack jokes language model make laugh humour ai model tries complete sentence humourous way given input words'\n 'graph convolutions dummies article explaining graph convolutional networks simply possible'\n 'guided uncertainty aware policy optimization combining learning model based strategies sample efficient policy learning'\n 'survey state explainable ai nlp overview operations explainability techniques currently available generating explanations nlp model predictions'\n 'table detection information extraction structuring using ml table extraction te task detecting decomposing table information document'\n 'live demo state art mcq generator content demo state art mcq multiple choice questions generator content built using t5 transformer huggingface sense2vec'\n 'movie recommendation system web app recommends movies based plots found imdb'\n 'pose animator takes 2d vector illustration animates containing curves real time based recognition result posenet facemesh'\n 'recurrent neural networks building gru cells vs lstm cells advantages rnn transformers use gru lstm equations gru really mean build gru cell pytorch'\n 'ttt fine tuning transformers tpus gpus acceleration ttt short package fine tuning transformers tpus written tensorflow2 0'\n 'text classification implemented article link given text classification cnn beside tried ml classification algorithm'\n 'temporal convolutional networks time series introduce several novels using tcn including improving traffic prediction sound event localization detection probabilistic forecasting'\n 'tsfresh automatic extraction relevant features time series'\n 'paragraph summarizer uses extractive way summarizing text finding score ranking'\n 'sktime python toolbox machine learning time series'\n 'upside reinforcement learning implementation udrl outlined juergen schmidhuber  arxiv org abs 1912 02875'\n 'neural networks nlp cmu cs 11 747 class start brief overview neural networks spend majority class demonstrating apply neural networks language'\n 'survey deep learning localization mapping towards age spatial machine intelligence'\n 'cvpr 2020 snapshot snapshot conference summarizing papers listing grabbed attention'\n 'bentoml bentoml open source framework high performance ml model serving'\n 'high fidelity generative image compression combine generative adversarial networks learned compression obtain state art generative lossy compression system'\n 'nsfw image classification rest api built tensorflow js ready use open source nsfw image classification rest api built tensorflow js nsfw js effortless content moderation'\n 'short notes batch constrained deep reinforcement learning blog article policy deep reinforcement learning without exploration paper fujimoto et al icml 2019'\n 'deepway autonomous navigation blind tried make something used blind people navigate around streets look video github repo details'\n 'softbot design wanns soft robots robots built highly compliant materials similar found living organisms project explored cppns wanns design'\n 'universal sentence encoder visually explained deep dive universal sentence encoder learns generate fixed length sentence embeddings'\n 'rasa nlu examples experimental components rasa nlu pipelines'\n 'image synthesis cvpr 2020 overview different approaches image synthesis cvpr 2020'\n 'superglue learning feature matching graph neural networks superglue neural network matches two sets local features jointly finding correspondences rejecting non matchable points'\n 'transfer learning fine tuning keras 100 date guide transfer learning fine tuning keras'\n 'snaked classifying snake species using images proof concept possible identify snake species whether poisonous photographs pytorch code model android app'\n 'efficient serverless deployment pytorch models azure tutorial serving models cost effectively scale using azure functions onnx runtime'\n 'exploring knowledge captured probability strings exploration simple knowledge captured language models code examples'\n 'using different decoding methods lm transformers look different decoding methods generate subsequent tokens language modeling'\n 'ccnet pytorch pytorch implementation ccnet criss cross attention semantic segmentation'\n 'neuralcook image2ingredients cooking recommendation deep learning application identify ingredients cooking dishes images recommend dishes cook given set ingredients'\n 'semantic segmentation background removal style transfer running multiple tf lite models perform semantic segmentation remove background apply style transfer'\n 'graph neural networks descriptive guide graph neural networks'\n 'neptune ai lightweight experiment management tool fits workflow'\n 'transfer learning nlp brief history transfer learning nlp'\n 'nlpaug data augmentation nlp'\n 'chakin simple downloader pre trained word vectors'\n 'self driving car project demonstration working model self driving car identifying following lanes using powerful computer vision algorithms'\n 'appnp ppnp pytorch implementation predict propagate graph neural networks meet personalized pagerank iclr 2019'\n 'frimcla framework image classification frimcla open source framework image classification using traditional deep learning techniques supports wide variety deep learning c'\n 'detr end end object detection transformers new method views object detection direct set prediction problem'\n 'autosweep recovering 3d editable objects single photo fully automatic framework extracting editable 3d objects directly single photograph'\n 'next word prediction using transformers predict next word predict mask word'\n 'overview early vision inceptionv1 guided tour first five layers inceptionv1 taxonomized neuron groups'\n 'better nlp project wrapper program library encapsulates couple nlp libraries popular among ai ml communities'\n 'real time text detection east tflite demonstrates conversion process original east model tflite use static images also real time video feeds'\n '2019 guide human pose estimation deep learning basics human pose estimation 2d review literature topic'\n 'shift ctrl f semantic search browser search information available webpage using natural language instead exact string match'\n 'hyperparameter optimization transformers guide basic grid search optimal fact hyperparameters choose significant impact final model performance'\n 'intuitive guide deep network architectures intuition behind base network architectures like mobilenets inception resnet'\n 'data analysis made easy text2code jupyter notebook jupyter notebook extension text2code basic pandas plotly commands'\n 'sparse sinkhorn attention new efficient sparse method learning attend based differentiable sorting internal representations'\n 'onceupon space nlp experiment story telling creates illustrations text sketch content text generation'\n 'high resolution image inpainting high resolution image inpainting iterative confidence feedback guided upsampling'\n 'real time object detection using cnn yolo project done real time object detection using deep learning object detection algorithm e yolo'\n 'machine learning deserves flavor continuous delivery traveling data science world homesick smooth continuous delivery flow thoughts approachable cd4ml'\n 'gans computer vision article review series article series review important research papers gans 2015 today 6 articles 20 papers 20000 words'\n 'graphnorm principled approach accelerating graph neural network training'\n 'building captcha ocr tf2 0 kaggle notebook showcasing use endpoint layer ctc loss function used building captcha reader tensorflow'\n 'gabornet modified network architecture focuses improving convergence reducing training complexity'\n 'biowordvec biosentvec pre trained embeddings biomedical words sentences'\n 'object detection dummies go several basic concepts algorithms popular deep learning models image processing object detection'\n 'token2index lightweight powerful library build token indices nlp tasks compatible major deep learning frameworks like pytorch tensorflow'\n 'paint machine learning web app allows create landscape painting style bob ross using deep learning model served using spell model server'\n 'norfair lightweight python library adding real time 2d object tracking detector'\n 'tensorboard dev easily host track share ml experiments free'\n 'atlass automl using transfer semi supervised learning repository includes code application notebooks work automl using transfer semi supervised learning tools presented'\n 'simplegan tensorflow based framework ease training generative models'\n 'pytorch forecasting time series forecasting pytorch'\n 'convnet playground interactive visualization exploring convolutional neural networks applied task semantic image search'\n 'illustrated guide transformers step step explanation post focus one paper started attention need'\n 'dialogpt toward human quality conversational response generation large scale pre training dialogue'\n 'pifuhd high resolution 3d human digitization repository contains pytorch implementation multi level pixel aligned implicit function high resolution 3d human digitization'\n 'small differences bleu meaningless big differences metric scores meaningful mt'\n 'social distance detection people close red bounding box displayed around indicating maintaining social distance'\n 'important monitor machine learning models importance monitoring monitoring ml different application performance management apm'\n 'semantic graphs generating deep questions deep question generation dqg aims generate complex questions require reasoning multiple pieces information input passage'\n 'docker help become effective data scientist look docker perspective data scientist'\n 'introduction nlp using fastai implementing decoding revolutionary ulmfit approach train language model downstream nlp task'\n 'attentron shot text speech exploiting attention based variable length embedding'\n 'scene classification using pytorch fast ai objective classify multi label images using deep learning used fast ai library implementing model'\n 'practical ai using nlp word embeddings solve localization using nlp word vectors word2vec glove etc novel way solve problem localization edtech'\n 'exploration strategies deep reinforcement learning exploitation versus exploration critical topic reinforcement learning post introduces several common approaches better exploration deep rl'\n 'effective testing machine learning systems testing machine learning systems different discuss strategies writing effective tests machine learning systems'\n 'optimizing mobiledet mobile deployments learn criticalities effectively optimizing mobiledet object detectors mobile deployments'\n 'implementation face net tensorflow 2 0 repository naive unofficial implementation face net paper 2015 implementation opts online mode semi hard triplet mining'\n 'bertology meets biology interpreting attention protein language models'\n 'vott visual object tagging tool electron app building end end object detection models images videos'\n 'goturn pytorch pytorch implementation learning track 100 fps deep regression networks'\n 'yolov4 tensorflow 2 0 implementation yolov4 optimal speed accuracy object detection'\n 'state transfer learning nlp post expands naacl 2019 tutorial transfer learning nlp highlights key insights takeaways provides updates based recent work'\n 'pokezoo deep learning based web app developed using mern stack tensorflow js'\n 'torchio medical image processing deep learning pytorch tools medical image processing deep learning pytorch'\n '15 best tools tracking machine learning experiments feature comparison open source commercial options experiment tracking'\n 'test time data augmentation tutorial properly implement test time image data augmentation production environment limited computational resources'\n 'elastictransformers making bert stretchy semantic elasticsearch sentence transformers'\n '12 factors reproducible machine learning production took experience deduce 12 factors nod 12 factor app build backbone successful ml production'\n 'latest advancements video streaming ai ai developments video streaming using super resolution per title encoding p2p'\n 'overview semantic image segmentation image segmentation computer vision task label specific regions image according shown'\n 'classify photos 600 classes using nine million open images looking build image classifier need training data look google open images'\n 'easy data augmentation eda easy data augmentation techniques boosting performance text classification tasks'\n 'ulmfit airline sentiment analysis transfer learning using pretrained ulmfit model'\n 'drifter ml machine learning testing framework sklearn pandas goal help folks assess whether things changed time'\n 'tensorflowtts real time sota speech synthesis tensorflow 2 0 tensorflowtts provides real time state art speech synthesis architectures tacotron2 melgan fastspeech'\n 'introduction machine learning problem framing course helps frame machine learning ml problems'\n 'ganspace discovering interpretable gan controls paper describes simple technique analyze generative adversarial networks gans create interpretable controls image synthesis'\n 'gnnexplainer generating explanations graph neural networks general tool explaining predictions made graph neural networks gnns'\n 'long form question answering eli5 model open domain long form question answering'\n 'awesome monte carlo tree search curated list monte carlo tree search papers implementations'\n 'self supervised learning computer vision pre trained models domain'\n 'question answering fine tuned bert mean bert achieve human level performance question answering'\n 'semantic cord19 paper explorer semantic research paper explorer search research papers covid coronavirus easily modified research paper database'\n 'eccv 2020 highlights sort snapshot conference summarizing papers listing grabbed attention'\n 'estorch estorch evolution strategy library build around pytorch'\n 'latent graph neural networks manifold learning 2 0 parallels recent works latent graph learning older techniques manifold learning'\n 'gan bert enhancing bert training semi supervised generative adversarial networks'\n 'building intelligent twitter bot volume information going twitter per day makes one best platforms get information subject interest'\n 'deepr training tensorflow models production deepr python library build complex pipelines easily possible top tensorflow'\n 'exploratory data analysis time series exploratory data analysis time series data python uses lot principles concepts discussed prof hyndman book focus understa'\n 'temporal graph networks post describe temporal graph network generic framework deep learning dynamic graphs'\n 'commit history bert forks commit history version controlled research papers could look like'\n 'proteingcn protein model quality assessment using gcns source code paper proteingcn protein model quality assessment using graph convolutional networks'\n 'monai ai toolkit healthcare imaging'\n 'scitldr extreme summarization scientific documents new automatic summarization task high source compression requiring expert background knowledge complex language understanding'\n 'bad passwords nist guidelines example project provided datacamp project write code automatically detects flags bad passwords'\n 'time series classification using deep learning article introduce new package called timeseries fastai2 lately developed'\n 'siamfc towards robust accurate visual tracking implementation series basic algorithms useful video understanding including single object tracking sot video object segmentation vos'\n 'message passing gnns c c implementation using eigen forward pass graph convolutional neural networks'\n 'nlp pandect nlp resources one place nlp pandect created help find almost anything related natural language processing available online'\n 'object goal navigation using goal oriented semantic exploration embodied interactive learning object detection using semantic curiosity learn exploration policy set training environments'\n 'deep learning image super resolution survey article aims provide comprehensive survey recent advances image super resolution using deep learning approaches'\n 'sentiment analysis news article used twitter api extract news related tweets preprocessing calculated tweets polarity'\n 'yolov3 implementation keras tensorflow 2 2 yolov3 real time object detector tensorflow 2 2'\n 'fastai2 vision module detailed guide using fastai2 datablock api common computer vision tasks'\n 'interpretable machine learning computer vision recent progress made visualization interpretation explanation methodologies analyzing data models computer vision'\n 'teachable machine image classifier teachable image classifier runs browser built using tensorflow js'\n 'distilling knowledge neural networks project demonstrates compelling model optimization technique knowledge distillation code walkthroughs tensorflow'\n 'vedaseg vedaseg open source semantic segmentation toolbox based pytorch'\n 'nlp viewer simple website browsing popular nlp datasets'\n 'using data science pipelines disaster response uses etl ml pipeline build nlp system classification messages appropriate disaster categories'\n 'guide natural language processing allennlp basics using allennlp'\n 'create cartoonizer tensorflow lite end end tutorial convert tensorflow lite tflite model deploy android app cartoonizing image captured camera'\n 'nsfw image moderation admin app reactjs fully functional nsfw admin application simplified image classification moderation built node js tensorflow js react'\n '3d ken burns effect single image implementation 3d ken burns effect single image using pytorch'\n 'medical zoo 3d multi modal medical image segmentation articles deep learning medical imaging'\n 'yolov4 optimal speed accuracy object detection minimal implementation yolov4'\n 'coreml model zoo collection unified converted pre trained models'\n 'neural style transfer tutorial uses deep learning compose one image style another image ever wish could paint like picasso van gogh'\n 'tao large scale benchmark tracking object diverse dataset tracking object tao consisting 2 907 high resolution videos captured diverse environments half minute long'\n 'onnx t5 summarization translation q text generation blazing speed using t5 version implemented onnx'\n 'comprehensive survey graph neural networks comprehensive survey graph neural networks'\n 'text feature selection causal inference identifying linguistic features cause people act certain way reading text regardless confounding variables something people'\n 'injecting inductive bias graph neural networks mit talk equivariant mesh neural networks neural augmented factor graph neural networks'\n 'finetune scikit learn style model finetuning nlp finetune library allows users leverage state art pretrained nlp models wide variety downstream tasks'\n 'zero shot neural retrieval via domain targeted synthetic queries zero shot learning ad hoc retrieval models relies synthetic query generation'\n 'machine learning deployment shadow mode test new model production one answer method often employ initially deploying models shadow mode'\n 'real python recommendation engine full stack data science project performs document similarity realpython com content content recommendations implemented via chrome extension'\n 'contextualized topic models python package run contextualized topic modeling'\n 'automated time series forecasting data app uses facebook open source prophet library automatically forecast values future'\n 'stellargraph machine learning graphs state art algorithms graph machine learning making easy discover patterns answer questions graph structured data'\n 'implementing graph neural networks jax talk experience build train graph neural networks gnns jax'\n 'training game agents supervised learning continuing research project trying find ways learn complex tasks games without using reinforcement learning'\n 'face verification implementation siamese neural network model used face verification dataset used task imdb wiki face images dataset'\n 'sized fill blank multi mask filling roberta sized fill blank conditional text filling idea filling missing words sentence probable choice words'\n 'attributed social network embedding sparsity aware memory efficient implementation attributed social network embedding tkde 2018'\n 'indian paper currency prediction trained model takes image indian paper currency input predict class image 10 20 50 100 200 500 2000 denomination'\n 'clinical bert repository publicly available clinical bert embeddings'\n 'hmtl hierarchical multi task learning state art neural network model several nlp tasks based pytorch allennlp'\n 'top 10 deep learning breakthroughs deep reinforcement learning article unravels journey behind reaching point reinforcement learning combined deep learning defeated go player world champion'\n 'discovering symbolic models deep learning w inductive bias general approach distill symbolic representations learned deep model introducing strong inductive biases'\n 'linear attention transformer fully featured transformer mixes qk v local attention q k v global attention scales linearly respect sequence length'\n 'designer gpt2 bot talks ux design twitter profile spits thoughts design development trained hundreds books ux design front end development opinions'\n 'albumentations fast image augmentation library easy use wrapper around libraries'\n 'dash detr detection app user interface detr built dash 100 python'\n 'basic ml algorithms scratch implement basic machine learning algorithms scratch python'\n 'neural machine translation attention notebook trains sequence sequence seq2seq model spanish english translation'\n 'dropout pytorch example example adding dropout pytorch model observe effect dropout model performance tracking models weights biases'\n 'build first data warehouse airflow gcp steps building data warehouse cloud technology use use airflow orchestrate pipeline'\n 'r u stoked nlp sentiment analysis project demonstrate pipeline data first stage data collection ml model deployment'\n 'pattern exploiting training pet repository contains code exploiting cloze questions shot text classification natural language inference'\n 'bingoset cli tool create image dataset cli toolkit quickly create image dataset using bing image search api'\n 'asap pooling graph neural network aaai 2020 asap sparse differentiable pooling method addresses limitations previous graph pooling layers'\n 'stochastic segmentation networks efficient probabilistic method modelling aleatoric uncertainty image segmentation network architecture'\n 'image super resolution project learn train super resolution model espcn div2k dataset upscale images using ai 3x'\n 'models checkpoints hugging face massive growing collection nlp models nearly nlp tasks especially involving use transformers'\n 'optimize ml models learn use optimize custom image classification models built tf keras using tensorflow lite gain 10x reduction model size'\n 'tudatasets collection benchmark datasets graph classification regression'\n 'bert summarization folder contains colab notebooks guide summarization bert gpt 2 play data'\n 'nature scene classification using fastai classifying nature scene images using deep learning fastai library'\n 'ai debate master created deployed bot made debate human given topic employed doc2vec model using gensim library python'\n 'pixellib pixellib library performing segmentation images'\n 'machine learning production pipeline project flow landscape'\n 'practical tips tricks successful transfer learning training models learn knowledge skills related tasks transfer boost performance tasks interest'\n 'tableqa ai tool querying natural language tabular data like csvs dataframes'\n 'wt5 training text text models explain predictions leverage text text framework proposed raffel et al 2019 train language models output natural text explanation alongside prediction'\n 'melanoma classification shubhamai 3 week project working new kaggle competition deploying web application predicting benign malignant based images'\n 'diffusion vector reference implementation diffusion2vec complenet 2018 built gensim networkx'\n 'tensorflow2 object detection tutorial tutorial going step step complete training process tensorflow2 object detection'\n 'mlflow machine learning lifecycle platform open source platform machine learning lifecycle'\n 'build sota conversational ai transfer learning train dialog agent leveraging transfer learning openai gpt gpt 2 transformer language model'\n 'big bad nlp database collection 400 nlp datasets papers included'\n 'author identification using doc2vec web app author identification model trained pan 2012 dataset kaggle spooky authorship dataset'\n 'teacheasy web app text summarization q generation intuitive streamlit based web app text summarization question answer generation reduce work school teachers'\n 'long peek reinforcement learning post gonna briefly go field reinforcement learning rl fundamental concepts classic algorithms'\n 'images radio boxes collected 15 k raw images radio boxes across 500 forms hand picked 200 images used determine radio box checked'\n 'visual guide self labelling images self supervised method generate labels via simultaneous clustering representation learning'\n 'dframcy dframcy light weight utility module integrate pandas dataframe spacy linguistic annotation training tasks'\n 'semixup manifold regularization semixup semi supervised learning method based manifold regularization'\n 'feature stores ml list production ml groups open source feature store architectures'\n 'intro facebook prophet everything need know starting facebook time series forecasting tool'\n 'machine learning methods explained examples common techniques used data science projects get know easy understand examples put practice ml projects'\n 'deep learning based super resolution without using gan techniques training deep learning model image improvement image restoration inpainting super resolution'\n 'topic modeling bert leveraging transformers class based tf idf create dense clusters allowing easily interpretable topics'\n 'axcell automatic extraction results machine learning papers'\n 'two step graph convolutional decoder molecule generation simple auto encoder framework molecule generation'\n 'fast nst videos person segmentation create nst videos pick separate styles person video background'\n 'allennlp open source nlp research library built pytorch'\n 'visual paper summary albert lite bert illustrated summary albert paper improves bert makes resource efficient'\n 'textattack python framework building adversarial attacks nlp models'\n 'stop worrying compositionality review tenets compositionality highlight theory evolved match particular theoretical positions nature language'\n 'shape viewpoint without keypoints recover 3d shape pose texture single image trained image collection without ground truth 3d shape multi view camera viewpoints'\n 'tslearn machine learning toolkit dedicated time series data'\n 'five cool python libraries data science python best friend majority data scientists libraries make life simpler come across five cool python libraries working'\n 'plant disease detection website help detect disease plant based plant leaf image'\n 'face mask detector simple streamlit frontend face mask detection images using pre trained keras cnn model opencv model interpretability'\n '3d face fast accurate stable reconstruction work extends previous work 3ddfa named 3ddfa v2 titled towards fast accurate stable 3d dense face alignment accepted eccv 2020'\n 'nearest celebrity face implementation facenet unified embedding face recognition clustering find celebrity whose face matches closest input face'\n 'make sense reinforcement learning agents log training debug'\n 'course review causal inference types understanding causal inference researchers value'\n 'computer vision pretrained models collection computer vision pre trained models'\n 't5 fine tuning colab notebook showcase fine tune t5 model various nlp tasks especially non text 2 text tasks text 2 text approach'\n 'benchmark models transformers huggingface transformer library allows users benchmark models tensorflow 2 pytorch using pytorchbenchmark tensorflowbenchmark classes'\n 'pytorch transformers tutorials set annotated jupyter notebooks give user template fine tune transformers model downstream nlp tasks classification ner etc'\n 'train albert nlp tensorflow amazon sagemaker train bert 1 hour efficiently scaled 2 048 nvidia v100 gpus improving underlying infrastructure network ml framework'\n 'simple transformers transformers made easy simple transformers removes complexity lets get matters model training experimenting transformer model architectures'\n 'natural language processing roadmap roadmap learning nlp topics'\n 'rules machine learning best practices ml engineering basic knowledge machine learning get benefit best practices machine learning around google'\n 'named entity recognition tagging post go example natural language processing learn load text data perform ner tagging token'\n 'ai economist improving equality productivity ai driven tax policies'\n 'twitter sentiment analysis project based natural language processing nlp sentiment analysis e much positive negative tweets account'\n 'image segmentation 2020 architectures losses datasets frameworks'\n 'research production deep semi supervised learning semi supervised learning ssl blossomed deep learning research community share lessons learned 15 months taking ssl production'\n 'finding similar documents transformers transformers help us distill text documents points n dimensional vector spaces'\n 'shakespeare meets google flax application rnns flax character level language model'\n 'fast api dockerization ml models github repo able know learn build fast api testing ml model test ml model ui dockerize ml'\n 'million ml predictions tip fingers announcement sashido breaking barrier machine learning introducing fully open sourced content moderation service'\n 'nlp developers multilingual nlp rasa video rasa developer advocate rachael talk common approaches handle language input one language'\n 'web mining information theory mining web playing natural language processing implementing information retrieval system tasks going towards nlp performing machine learning algorithms codes problems understood information retrieval process search engine useful problems towards sentiment analysis'\n 'extension block nsfw content using ai nsfw filter extension blocks nsfw content browser uses computer vision model detect nsfw content hides user'\n 'deep learning graph structured representations novel approaches based theme structuring representations computations neural network based models form graph'\n 'dakshina dataset collection text latin native scripts 12 south asian languages'\n 'visualizing neural machine translation model mechanics seq2seq models attention'\n 'jukebox generative model music introducing jukebox neural net generates music including rudimentary singing raw audio variety genres artist styles'\n 'paraphrase generation using t5 model simple application using t5 base model fine tuned quora question pairs generate paraphrased questions'\n 'sudoku game solver computer vision application solves 9x9 sudoku board game using deep learning backtracking algorithm'\n 'ufod unified framework object detection ufod open source framework enables training comparison object detection models custom datasets using different underlying frameworks'\n 'design patterns production nlp systems designs tips designing nlp production systems'\n 'cs224n natural language processing deep learning course students gain thorough introduction cutting edge research deep learning nlp'\n 'med7 clinical natural language processing ehr med7 transferable clinical natural language processing model electronic health records compatible spacy named entity recognition task'\n 'forex prediction using neural networks predict movement forex direction'\n 'solt data augmentation deep learning data augmentation library deep learning supports images segmentation masks labels key points'\n 'wheat detection project detecting creating bounding box wheat heads'\n 'deep learning object detection comprehensive review closer look tensorflow object detection models faster r cnn r fcn ssd'\n 'embedding projector visualization high dimensional data namely embeddings'\n 'practical text classification python keras get grasp current advancements deep neural networks applied text'\n 'layered neural rendering retiming people video manipulating editing time different motions individuals video occur'\n 'semi supervised learning computer vision comprehensive overview recent semi supervised learning methods computer vision'\n 'fairseq tagging fairseq fork sequence tagging labeling tasks'\n 'twitter turing test guess whether tweet written human generated neural network'\n 'learning see learning act visual pre training find pre training vision tasks significantly improves generalization sample efficiency learning manipulate objects'\n 'toward better storylines sentence level language models propose sentence level language model selects next sentence story finite set fluent alternatives'\n 'multimodal meme classification uniter given state art results various image text related problems project aims finetuning uniter solve hateful memes challenge'\n 'detectron 2 demo facebook project contains process getting started facebook fair detectron2 project windows 10 without nvidia gpu'\n 'illustrated self supervised learning visual introduction self supervised learning methods computer vision'\n 'drowsiness detection system using opencv flask python system provides overview system detects whether person drowsy driving alerts using voice messages real time'\n 'multi target albumentations many images many masks bounding boxes key points transform sync'\n 'yolov4 tensorflow yolov4 yolov4 tiny yolov3 yolov3 tiny implemented tensorflow 2 0 android convert yolo v4 weights tensorflow tensorrt tflite'\n 'tf lite semantic segmentation models faster lighter tf lite models perform semantic segmentation'\n 'transmomo invariance driven unsupervised motion retargeting lightweight video motion retargeting approach capable transferring motion person source video realistically another video target'\n 'summarize webapge flask application extracts summarizes webpage using natural language processing powered nlp akash'\n 'electra pre training text encoders discriminators pytorch implementation electra model paper electra pre training text encoders discriminators rather generators'\n 'super bpd fast image segmentation propose direction based super bpd alternative superpixel fast generic image segmentation achieving state art real time result'\n 'electra pytorch electra pytorch fastai huggingface unofficial reimplementation electra pre training text encoders discriminators rather generators'\n 'tf geometric efficient friendly graph neural network library tensorflow 1 x 2 x'\n 'farm framework adapting representation models fast easy transfer learning nlp harvesting language models industry'\n 'top introduction bert huggingface pytorch also provide intuition bert works top approach applications algorithm'\n 'building ai trading systems lessons learned building profitable algorithmic trading system using reinforcement learning techniques'\n 'medcat medical concept annotation tool tool used extract information electronic health records ehrs link biomedical ontologies like snomed ct umls'\n 'efficientdet scalable efficient object detection implementation efficientdet scalable efficient object detection pytorch'\n 'show infer tell contextual inference creative captioning beauty work lies way architects fundamental idea humans look overall image individual pieces'\n 'doccano open source text annotation tool machine learning practitioner'\n 'time series forecasting tensorflow js machine learning becoming increasingly popular days growing number world population see magic crystal ball predicting'\n 'deep q network space invaders pytorch implementation deep q network agent trained play atari 2600 game space invaders'\n 'computer vision recipes repository provides examples best practice guidelines building computer vision systems'\n 'age gender estimation using multi task cnn used multi task cnn predict age group gender person image'\n 'machine learning fastai fastai library based research deep learning best practices undertaken fast ai includes support vision text tabular collab'\n 'machine learning systems design designing machine learning system'\n 'close domain fine tuning table detection project show benefits using models trained close domain using tablebank dataset fine tuning table detection models additio'\n 'hidden technical debt machine learning systems using software engineering framework technical debt find common incur massive ongoing maintenance costs real world ml systems'\n 'pcdet 3d point cloud detection pcdet toolbox pytorch 3d object detection point cloud'\n 'pytorch cnn trainer simple package fine tune cnns torchvision pytorch image models ross wightman'\n 'trained machine learning model three often overlooked parts process occur model actually built model evaluation deployment monitoring'\n 'nsfw image moderation automation engine built tensorflow js open source nsfw image classifier including automation engine fast deletion moderation built node js tensorflow parse server'\n 'deploying ml model torchserve talk brad heintz walks use torchserve deploy trained models scale without writing custom code'\n 'common architectures convolutional neural networks post discuss commonly used architectures convolutional networks'\n 'marge pre training via paraphrasing retrieval model maps document set related documents reconstruction model paraphrases maximize likelihood original'\n 'tokenizers fast state art tokenizers optimized research production'\n 'lyrics based music genre classifier classify genre rock pop hip hop available metal country jazz electronic r b indie folk song lyrics'\n 'unsupervised keyphrase extraction learn unsupervised algorithms automatically extracting representative keyword phrases documents'\n 'understanding text bert building machine reading comprehension system using latest advances deep learning nlp'\n 'digital image processing python play around pixel values python programming language'\n 'driver identification based vehicle telematics data paper proposed deep learning model identify drivers driving behaviors based vehicle telematics data'\n 'rasa open source machine learning framework automate text voice based conversations'\n 'laplacian pyramid reconstruction refinement semantic seg pytorch implementation multi resolution reconstruction architecture based laplacian pyramid uses skip connections'\n 'pytorch3d fair library reusable components deep learning 3d data'\n 'torchvision object detection finetuning tutorial finetuning pre trained mask r cnn model penn fudan database pedestrian detection segmentation'\n 'comparison yolo rcnn real world videos bringing theory experiment cool easily train models colab find results minutes'\n 'easy ocr ready use ocr 40 languages supported including chinese japanese korean thai'\n 'training batch norm batch norm experiments ideas presented  arxiv org abs 2003 00152 frankle et al'\n '2020 guide semantic segmentation concept image segmentation discuss relevant use cases different neural network architectures involved achieving results metrics datasets'\n 'object detection multi template matching python package allows perform object detection using one template images provides simpler alternative deep learning methods'\n 'roberta longformer build long version pretrained models notebook replicates procedure descriped longformer paper train longformer model starting roberta checkpoint'\n 'hugging face achieved 2x performance boost qa question answering distilbert node js'\n 'network fusion content creation conditional inns present method repurpose powerful existing models new tasks even though never designed'\n 'gp gan towards realistic high resolution image blending blending composite images using generative model gaussian poisson equation laplacian pyramid'\n 'coco annotator web based image segmentation tool object detection localization key points'\n 'compressing bert faster prediction blog post discuss ways make huge models like bert smaller faster'\n 'continuous machine learning cml cml helps organize mlops infrastructure top traditional software engineering stack instead creating separate ai platforms'\n 'ecg arrhythmia classification using convolutional neural net implementation paper ecg arrhythmia classification  arxiv org pdf 1804 06812 pdf'\n 'sentiment classification utapass kkbox reviews text classification reviews utapass kkbox using different deep learning models'\n 'using selective attention reinforcement learning agents work establish self attention viewed form indirect encoding enables us construct highly parameter efficient agents'\n 's2igan speech image generation via adversarial learning speech image generation s2ig framework proposed translates speech descriptions photo realistic images without using text information'\n 'mini pokedex end end tutorial gotta classify em build pokemon image classifier classify awesome starters pikachu charmander squirtle bulbasaur'\n 'transformers scratch attempt explain directly modern transformers work without historical baggage'\n 'jepto digital marketing analytics kpi prediction anomaly detection digital marketing data technical non technical marketers business owners'\n 'behavioral testing nlp models checklist overview checklist framework fine grained evaluation nlp models'\n 'machine learning projects repo contains projects done learning basics familiar types regression classification clustering methods used'\n 'stefann scene text editor using font adaptive neural network generalized method realistic modification textual content present scene image accepted cvpr 2020'\n 'ensemble methods object detection repository provide code ensembling output object detection models applying test time augmentation object detection lib'\n 'evaluate longformer triviaqa using nlp evaluate pretrained longformerforquestionanswering model validation dataset triviaqa'\n 'differentiable adaptive computation time visual reasoning dact new algorithm achieving adaptive computation time unlike existing approaches fully differentiable'\n 'epipolar transformers differentiable epipolar transformer enables 2d detector leverage 3d aware features improve 2d pose estimation'\n 'nlp developers word embeddings rasa video rasa developer advocate rachael talk word embeddings work used common errors'\n 'illustrated self attention step step guide self attention illustrations code'\n 'leveraging temporal context object detection object detection architecture leveraging contextual clues across time camera deployment network improving recognition objects'\n 'qsvm quantum svm sentiment analysis'\n 'tensorflow 2 meets object detection api tf object detection api od api officially supports tensorflow 2'\n 'multi task nlp utility toolkit enabling nlp developers easily train infer single model multiple tasks'\n 'artifacts weights biases effortless pipeline tracking production model management'\n 'bridging pytorch tvm taking hugging face transformer bert pytorch running apachetvm inference reasonable timings training'\n 'fast neural style transfer feed forward method repo contains concise pytorch implementation original feed forward nst paper'\n 'jiant software toolkit research general purpose text understanding models'\n 'end end object detection tensorflow lite project shows train custom detection model tfod api optimize tflite perform inference optimized model'\n 'model agnostic meta learning reinforcement learning tf2 reimplementation model agnostic meta learning maml applied reinforcement learning problems tensorflow 2'\n 'optimal transport sinkhorn transformer understand optimal transport sinkhorn knopp algorithm diving sinkhorn transformer'\n 'pictranslate seamless live image text translator given image text app give new image text modified different language'\n 'simplest way serve nlp model production w python scikit learn hugging face pipelines learn simplest way deploy ml models using ray serve'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12368\\3626723321.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Oversample (training set)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moversample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"all\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_over\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_over\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\imblearn\\over_sampling\\_random_over_sampler.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m         )\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    876\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    879\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    696\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['huggingtweets tweet generation huggingface'\n 'selfie2anime tflite end end tutorial tensorflow lite selfie2anime u gat'\n 'introduction q learning reinforcement learning q learning algorithm along implementation python using numpy'\n 'holopix50k large scale wild stereo image dataset largest dataset wild stereo image pairs 50k crowd sourced holopix lightfield image sharing social network'\n 'mlops machine learning operations mlops best practices businesses run ai successfully help expanding software products cloud services'\n 'github actions machine learning workflows hamel husain talk hamel provide brief tutorial github actions show use new tool automate ml workflows'\n 'bleurt learning robust metrics text generation metric natural language generation based transfer learning'\n 'ai medicine imaging stanford symposium 2020 aimi symposium hope address gaps barriers field catalyze evidence based solutions improve health'\n 'advanced deep learning computer vision adl4cv visual computing group offers variety lectures seminars regular basis covering hot areas computer graphics vision machine learning'\n 'generating soap notes doctor patient conversations evaluate complete pipelines leveraging transcripts train machine learning model generate notes'\n 'automatically generate multiple choice questions mcqs automatically generate multiple choice questions mcqs content bert summarizer wordnet conceptnet'\n 'cognito data wrangling toolkit cognito exclusive python data preprocessing library command line utility helps developer transform raw data machine learning format'\n 'fashionbert text image matching adaptive loss cross modal retrieval'\n 'onnx transformers accelerated nlp pipelines fast inference cpu built transformers onnx runtime'\n 'meta learning shot natural language processing survey clear definitions progress summary common datasets applying meta learning shot nlp'\n 'colbert ai colbert ai deep learning language model generates text style stephen colbert famous monologues'\n 'codebert masked language model source code tutorial use codebert mlm python code model trained scratch using roberta'\n 'learning dexterity end end trained human like robot hand manipulate physical objects unprecedented dexterity'\n 'gutenberg dialog build dialog dataset online books many languages'\n 'txtai ai powered search engine ai powered search engine'\n 'trackable project deals tracking humans narrow hallway different lighting conditions'\n 'first order motion model image animation generating video sequence object source image animated according motion driving video'\n 'favorite recipes computer vision deep learning blog post enlists favorite recipes deep learning context computer vision august 2020'\n 'transformer explained intuitive explanation transformer motivating lens cnns rnns etc'\n 'googletrans googletrans free unlimited google translate api python translates totally free charge'\n 'fruit detection using convolution neural networks tensorflow trained convolutional neural network model predict fruits 100 classes types training accuracy 95 testing accuracy 9'\n 'solaris cosmiq works geospatial machine learning analysis toolkit'\n 'data augmentation recipes tf keras image based models learn different ways data augmentation training image classifier tf keras'\n 'simgnn pytorch implementation simgnn neural network approach fast graph similarity computation wsdm 2019'\n 'battle tested techniques scoping machine learning projects one challenges managing ml project project scoping even small changes data architecture create huge differences model outputs'\n 'annotated transformer post present annotated version paper form line line implementation'\n 'lstm forecast model stock price prediction using keras easy understand lstm forecast model stock price prediction dataset contains daywise details googl stock may 2019 may 2018'\n 'tapas weakly supervised table parsing via pre training using neural networks find answers tables'\n 'scispacy full spacy pipeline models scientific biomedical documents'\n 'mixnmatch multifactor disentanglement encoding conditional image generation'\n 'introduction transfer learning huggingface talk start introducing recent breakthroughs nlp resulted combination transfer learning schemes transformer architect'\n 'illustrated word2vec post go concept embedding mechanics generating embeddings word2vec'\n 'highres net multi frame super resolution satellite imagery pytorch implementation highres net neural network multi frame super resolution trained tested european space agency kelvin competition'\n 'keras notifications slack get slack notifications model training progress training keras tf keras'\n 'rlx modular deep rl library research rlx deep rl library written top pytorch built educational research purpose'\n 'applying modern best practices autoencoders project applies best modern practices found areas image research autoencoders comparing models areas image research'\n 'melanoma detection pytorch video show build deep learning model detect melanoma high accuracy'\n 'illustrated transformer post look transformer model uses attention boost speed models trained'\n 'tokenizers machines read survey different tokenization strategies nlp'\n 'ensemble forecasts time series forecasting using classical methods ets holt winter sarima prophet show discuss advantages ensemble forecast'\n 'zero shot topic classification bart classification head trained mnli'\n 'barebones image retrieval system project presents simple framework retrieve images similar query image'\n 'cs285 deep reinforcement learning course deep reinforcement learning transfer multi task learning'\n 'data science meets devops mlops jupyter git kubernetes end end example deploying machine learning product using jupyter papermill tekton gitops kubeflow'\n 'natural language processing news get highlights natural language processing machine learning research industry straight inbox every month'\n 'search visual datasets task application class label format'\n 'create semantic search arbitrary objects end end example build system search objects semantically hamel husain ho hsiang wu'\n 'emotion recognition tom jerry videos developed application classifies emotion depicted tom jerry frame one following happy angry sad suprised'\n 'switched flask fastapi production ml popular tool always best'\n 'segmentation models segmentation models pretrained backbones keras tensorflow keras'\n 'controlling text generation plug play language models article discusses alternative approach controlled text generation titled plug play language model pplm'\n 'bart version closed book qa bart version sequence sequence model open domain qa closed book setup based pytorch huggingface transformers'\n 'summary transformers models high level summary differences model huggingface transformer library'\n 'attention attention post gonna look attention invented various attention mechanisms models transformer snail'\n 'effects news sentiments stock predictions project based natural language processing technique called sentiment analysis stock market news related subject analysis'\n 'autonomous learning library pytorch library building deep reinforcement learning agents'\n 'curriculum reinforcement learning curriculum learning applied reinforcement learning exceptions supervised learning'\n 'research guide data scientists tips research top data scientists'\n 'workshop scalability autonomous driving andrej karpathy overview autonomous driving computer vision tesla'\n 'sentencepiece unsupervised text tokenizer neural network based text generation'\n 'understanding convolutional neural networks nlp recently also started apply cnns problems natural language processing gotten interesting results'\n 'azure machine learning template azure machine learning template mnist classifier'\n 'visual guide using bert first time tutorial use variant bert classify sentences'\n 'bit exploring large scale pre training compute excited share best bit models pre trained public datasets along code tf2 jax pytorch'\n 'sadedegel extraction based turkish news summarizer sadede gel turkish means cut chase'\n 'implementation contextual chatbot pytorch simple chatbot implementation pytorch'\n 'ner model 40 languages trained new tftrainer model fine tuned xlm roberta base 40 languages proposed xtreme wikiann'\n 'change detection using siamese networks blog primer siamese networks used observing change satellite images time observing facial changes people age'\n 'funnel transformer filtering sequential redundancy funnel transformer self attention model gradually compresses sequence hidden states shorter one hence reduces computation cost'\n 'detext deep neural text understanding framework detext deep neural text understanding framework ranking classification tasks'\n 'look inside workings label smoothing blog post describes trick label smoothing improves model accuracy use'\n 'history language models alec radford quick history language models'\n 'simclr tensorflow 2 minimally implements simclr  arxiv org abs 2002 05709 tensorflow 2'\n 'universal adversarial triggers attacking analyzing nlp create short phrases cause specific model prediction concatenated input dataset'\n 'nlp newsletter democratizing artificial intelligence research education technologies'\n 'model based reinforcement learning survey survey integration fields better known model based reinforcement learning'\n 'u net deep learning colorization greyscale images article describes experiments training neural network generate 3 channel colour images single channel greyscale images using deep learning'\n 'attentionwalk pytorch implementation watch step learning node embeddings via graph attention neurips 2018'\n 'delight deep light weight transformers similar better performance transformer based models significantly fewer parameters'\n 'implementing portrait bokeh mode using opencv numpy python love portrait mode smartphone code help using opencv numpy detects faces asks want blur'\n 'q bert agents build knowledge graphs explore textual worlds asking questions'\n 'single stage semantic segmentation image labels attain competitive results training single network model segmentation self supervised fashion using image level annotations'\n 'deep learning videos 2018 guide action recognition post summarize literature action recognition videos'\n 'anomaly detection keras tensorflow deep learning perform anomaly detection image datasets using deep learning'\n 'comment classification using bert multi language fine tuning going use bert layer model applying keras'\n 'training image classifier pytorch torchvision data loaders common datasets imagenet cifar10 mnist etc data transformers images vizualization data loaders'\n 'text classification using bert tensorflow hub tutorial helps learn bert models classification task tweet dataset'\n 'stumpy powerful scalable python library time series stumpy powerful scalable python library computing matrix profile used variety time series data mining tasks'\n 'azure ml mlops using azure ml'\n 'building level 3 conversational ai assistants presentations panels fireside chats addressing topics related creation level 3 ai assistants'\n 'abstraction reasoning corpus arc computer learn complex abstract tasks examples arc used measure human like form general fluid intelligence'\n 'transfer learning t5 text text transfer transformer paper demonstrate achieve state art results multiple nlp tasks using text text transformer pre trained large text corpus'\n 'introduction adversarial examples deep learning report provides intuitive introduction adversarial examples discusses wide variety different adversarial attacks notably provides ad'\n 'pytorch geometric temporal temporal extension library pytorch geometric'\n 'diverse image generation via self conditioned gans simple effective unsupervised method generating realistic diverse images using class conditional gan model without using manually annotated class'\n 'flashtorch visualization toolkit neural networks pytorch'\n 'machine learning pipelines kubeflow kubeflow pipelines reusable end end ml workflows built using kubeflow pipelines sdk'\n 'part 2 deep representations way towards neural style transfer top approach conceiving neural style transfer'\n 'deepdream video style transfer deepdream video'\n 'parallelizing prophet cross validation dask applied example w code'\n 'nlp beyond english 7000 languages spoken around world nlp research mostly focused english post outlines work languages eng'\n 'face predicting web app interactive deep learning model utilizes computer webcam predict age gender seconds'\n 'simple transformers transformers classification ner qa language modeling language generation t5 multi modal conversational ai'\n 'capsule graph neural network pytorch implementation capsule graph neural network iclr 2019'\n 'need deep graph neural networks depth graph neural network architectures bring advantage'\n 'generate true false questions content automatically generate true false questions like ones see school textbooks using openai gpt2 sentence bert berkley parser'\n 'spaczz fuzzy matching spacy fuzzy matching functionality spacy'\n 'graphein protein graph library'\n 'v2v posenet pytorch pytorch implementation v2v posenet integralpose posefix loss'\n 'deepclas4bio deepclas4bio project aims facilitate interoperability bioimaging tools deep learning frameworks'\n 'unet implementation keras gpu vector map generation aerial imagery using deep learning geospatial unet'\n 'evolution representations transformer evolution representations individual tokens transformers trained different training objectives mt lm mlm bert style'\n 'replicating airbnb amenity detection documentary series airbnb engineering team shared article used computer vision detection amenities photos read like recipe replicated'\n 'unpopular opinion data scientists end end believe data scientists effective end end'\n 'ailight automatic highlighting using bert automatically highlight pdfs using bert embeddings clustering  anishthite github io ailight'\n 'pyimagesearch online platform blogs computer vision deep learning'\n 'tuned albert ensemble model top 6 squad 2 0'\n 'nerf neural radiance fields representing scenes neural radiance fields view synthesis'\n 'explore execute adapting without rewards via factorized meta reinforcement learning'\n 'accelerate nlp pipelines using hugging face onnx onnx runtime team hugging face working together address challenges training deployment transformer models'\n 'data quality key successful ml ops look ml ops highlight data quality key ml ops workflows'\n 'explainable ml monitoring video covers overview risks ai need explainable monitoring exactly mean talk'\n 'self supervised representation learning get labels free unlabelled data train unsupervised dataset supervised manner'\n 'back translation text augmentation google sheets learn augment existing labeled text data free using google sheets'\n 'tensorflow serving flexible high performance serving system machine learning models designed production environments'\n 'omega ml building deploying ml models easy way deploying ml hard omega ml makes breeze'\n 'visual survey data augmentation nlp extensive overview text data augmentation techniques natural language processing'\n 'comprehensive analysis important metrics ml work authors present comprehensive analysis important metrics practical applications'\n 'unsupervised toolbox unsupervised learning tool box micro framework state art methods models unsupervised learning nlu nlg'\n 'gotchas transfer learning image classification discover things care transfer learning image classification'\n 'deep love transfer learning nlp review nlp research'\n 'set python project automation collaboration set python repo unit tests code coverage lint checking type checking makefile wrapper automated build github actions'\n 'gpt 3 model simply knows brief introduction gigantic gpt 3 new leap ai natural language processing'\n 'awesome deep rl project built people learning researching latest deep reinforcement learning methods'\n 'remo python lib remo app annotations images management computer vision'\n 'survey long term context transformers past two years nlp community developed veritable zoo methods combat expensive multi head self attention'\n 'low dimensional hyperbolic knowledge graph embeddings low dimensional knowledge graph embeddings simultaneously capture hierarchical relations logical patterns'\n 'quick draw neural network learn recognize doodling'\n 'deep learning techniques nlp healthcare talk discussing recent advancements deep learning facilitate adaption nlp healthcare domain'\n 'dpod pose estimator pytorch recreation sota 6d pose estimation research paper'\n 'text summarization using tf idf algorithm article explains tf idf algorithm shows implemtnation scratch summarize text'\n 'reinforcement learning tic tac toe value function reinforcement learning algorithm agents learn tic tac toe using value function'\n 'linformer self attention linear complexity demonstrate self attention mechanism approximated low rank matrix'\n 'recipes building open domain chatbot python framework sharing training testing dialogue models open domain chitchat vqa visual question answering'\n 'python implementation reinforcement learning introduction plot replications exercise solutions anki flashcards entire book chapters'\n 'adapterhub framework adapting transformers huggingface transformers adapters'\n 'tempering expectations gpt 3 openai api closer look magic behind gpt 3 caveats aware'\n 'paraphrase question t5 text text transformer given question generate paraphrased versions question t5 transformer pretrained model training script provided'\n 'pruning bert accelerate inference previously discussing various ways accelerating models like bert blog post empirically evaluate pruning approach'\n 'divide hugging face transformers training time 2 reducing training time helps iterate fixed budget time thus achieve better results'\n 'adversarial latent autoencoders introducing adversarial latent autoencoder alae general architecture leverage recent improvements gan training procedures'\n 'biobert pre trained biomedical language representation model code fine tuning biobert biomedical text mining tasks biomedical ner relation extraction qa etc'\n 'reinforcement learning tutorial important reinforcement learning rl algorithms including policy iteration q learning neural fitted q'\n 'face alignment full pose range 3d total solution face alignment full pose range 3d total solution'\n 'cnn see first super clean notebook showcasing tensorflow 2 0 example end end dl interpretability'\n 'learning summarize human feedback human feedback models outperform much larger supervised models reference summaries tl dr'\n 'stylegan encoder encodes real images latent space stylegan model'\n 'u 2 net code newly accepted paper pattern recognition 2020 u 2 net going deeper nested u structure salient object detection'\n 'automatic translation squad dataset spanish machine translation used squad dataset produce equivalent dataset spanish word alignment applied produce synthetic spanisqa corpus'\n 'dark secrets bert much linguistically interpretable self attention patterns presumed strength actually used solve downstream tasks'\n 'gentle introduction text summarization machine learning text summarization technique generating concise precise summary voluminous texts focusing sections convey useful info'\n 'lazynlp library scrape clean web pages create massive datasets'\n 'pytest pytest framework makes easy write small tests yet scales support complex functional testing'\n 'great expectations always know expect data'\n 'building covid 19 project recommendation system create github open source repo recommendation system web app mlflow sagemaker booklet ai'\n 'electra electra pre training text encoders discriminators rather generators'\n 'machine learning tests production best practices testing ml based systems'\n 'interactive analysis sentence embeddings learn interactively explore sentence embedding labels tensorflow embedding projector'\n 'streamalert serverless realtime data analysis framework empowers ingest analyze alert data environment using datasources alerts'\n 'document search engine nlp based search engine single page pdf files'\n 'wikiart stylegan 2 model conditional stylegan 2 model trained images wikiart'\n 'gpt 3 language model technical overview technical details gpt 3 model training inference expect next'\n 'genomic ulmfit ulmfit genomic sequence data'\n 'evolution strategies evolutionary algorithms refer division population based optimization algorithms inspired natural selection'\n 'huggingtweets streamlit app built around huggingtweets project fine tune pre trained gpt2 model tweet like user given twitter handle'\n 'blink better entity linking entity linking python library uses wikipedia target knowledge base'\n 'torchcde differentiable controlled differential equation solvers pytorch gpu support memory efficient adjoint backpropagation'\n 'serverless bert huggingface aws lambda build serverless question answering api bert huggingface serverless framework aws lambda'\n 'coloring greyscale images coloring black white images neural networks'\n 'image smoothing via l0 gradient minimization edge aware image smoothing algorithm algorithm tries smoothen image preserving global structural information image'\n 'openai api api accessing new ai models developed openai'\n 'transformertts transformer tts implementation non autoregressive transformer based neural network text speech'\n 'openmmlab computer vision mmcv python library cv research supports many research projects object detection segmentation pose estimation action classification'\n 'extracting structured data templatic documents automatically extract data structured documents invoices receipts etc potential streamline many business workflows'\n 'structured self attention implementation paper structured self attentive sentence embedding  arxiv org abs 1703 03130 model interpretability explainability'\n 'open compound domain adaptation pytorch implementation open compound domain adaptation'\n 'font recognition using deep learning deepfont adobe deepfont paper technique created adobe inc detect font images using deep learning published work paper public'\n 'nlp developers shrinking transformers rasa video rasa senior developer advocate rachael talk different approaches make transformer models smaller'\n 'future transfer learning natural language processing transfer learning natural language processing nlp open questions current trends limits future directions'\n 'pix2pix tf js implementation web friendly ml models using tensorflow js pix2pix face segmentation fast style transfer many'\n 'almost everything need know time series understand moving average exponential smoothing stationarity autocorrelation sarima'\n 'practical guide building conversational chatbot building chatbot scratch using keras nltk library customer service company'\n 'doc2vec paragraph embeddings text classification text classification model uses gensim doc2vec generating paragraph embeddings scikit learn logistic regression classification'\n 'nlp evolved financial sentiment analysis still need humans read boring financial statements'\n 'sentiment analysis key milestones challenges new directions overview sentiment analysis progress ahead'\n 'image classifier browser using tensorflow js make prediction directly browser'\n 'show tell neural image caption generator tensorflow implementation image text model'\n 'python template projects template gives batteries required package code ci checks auto build deploy docs easy pypi publishing support docker files'\n 'text classification torchtext example shows train supervised learning algorithm classification using one textclassification datasets'\n 'wav2lip accurately lip syncing videos wild lip sync expert need speech lip generation wild'\n 'visual exploration deepcluster deepcluster self supervised method combine clustering representation learning'\n 'attribute2font creating fonts want attributes official pytorch implementation attribute2font creating fonts want attributes'\n 'leafy plant leaf classifier sequential model trained images leafsnap com'\n 'sentiment analysis sentiment analysis combining three dataset amazon yelp imdb reviews train model classify comment negative positive denoted 0 1'\n 'finetuning transformers jax haiku walking port roberta pre trained model jax haiku fine tuning model solve downstream task'\n 'steal modern nlp systems gibberish possible steal bert based models without real training data even using gibberish word sequences'\n 'illustrated guide transformers component component breakdown analysis'\n 'build robust embeddings visual similarity tasks repository package bunch tips tricks efficiently train deep learning models computer vision'\n 'super resolution variational auto encoders vae realnvp prior super resolution vae pytorch'\n 'neural style transfer gatys et al pytorch implementation original neural style transfer paper gatys et al pytorch'\n 'identifying brain tumor mri images using fastai dynamicunet use fastai unet learner identify tumours mri brain logging loss metrics neptune ai logger compare results hyperparameter tuning'\n 'limitations deep learning vision might fix opinion paper strengths weaknesses deep nets vision'\n 'deepkitai open source machine learning devtool training suite'\n 'pytorch faster rcnn fine tune faster rcnn pytorch task'\n 'understanding effectivity ensembles deep learning report explores ideas presented deep ensembles loss landscape perspective stanislav fort huiyi hu balaji lakshminarayanan'\n 'medicalzoo pytorch pytorch based deep learning framework multi modal 2d 3d medical image segmentation'\n 'genrl genrl pytorch first reinforcement learning library centered around reproducible generalizable algorithm implementations'\n 'transformers hugging face transformers state art natural language processing tensorflow 2 0 pytorch'\n 'rxnmapper unsupervised attention guided atom mapping atom mapping information learned albert model trained unsupervised fashion large dataset chemical reactions'\n 'convnet galaxy morphology classifier classify galaxies hubble tuning fork using convnet'\n 'tensorflow js gesture controlled 2048 gesture controlled 2048 built tensorflow js'\n 'building footprint extraction project retrieves satellite imagery google performs building footprint extraction using u net'\n 'autocoder finetuning gpt 2 auto code completion basic simple tool code auto completion built upon gpt 2'\n 'nlp model selection nlp model selection guide make easier select models prescriptive nature used caution'\n 'time series prediction lstm using pytorch time series applied forecasting airplane passengers dataset'\n 'nlp news category objective repository create nlp bot give robot headline news short description return genre'\n 'using jax improve separable image filters optimizing filters improve filtered images computer vision tasks'\n 'quantifying attention flow transformers explain two simple effective methods called attention rollout attention flow'\n 'top2vec top2vec learns jointly embedded topic document word vectors'\n 'bertviz tool visualizing attention transformer model bert gpt 2 albert xlnet roberta ctrl etc'\n 'tensorflow pytorch transformer fastai etc tutorials bert classification question answering seq2seq machine translation contextual topic modeling large scale multilabelclassification etc'\n 'attention mechanism main concepts behind attention including implementation sequence sequence attention model followed application attention transformers'\n 'neural topological slam visual navigation topological representations space effectively leverage semantics afford approximate geometric reasoning'\n 'large scale open domain mixed interface dialogue based korbit large scale open domain mixed interface dialogue based intelligent tutoring system'\n 'message passing query embedding mpqe model answering complex queries knowledge graphs learns embeddings entities knowledge graph embeddings variable types'\n 'intellicode compose code generation using transformer code completion tool capable predicting sequences code tokens arbitrary types generating entire lines syntactically correct code'\n 'set continuous integration machine learning set continuous integration machine learning github actions neptune step step guide'\n 'reverse image search ever wondered google image search works amazon retrieve products similar image upload app site achieve ta'\n 'illustrated gpt 2 visualizing transformer language models visuals explaining inner workings transformers'\n 'beginner guide machine learning model deployment beginner field machine learning wondering bring project live situation started learning ml'\n 'automatic face detection annotation preprocessing automatically detect annotate collect coordinates convert csv tfrecord'\n 'image image translation conditional adversarial networks tensorflow port image image translation conditional adversarial nets'\n 'pix2pix tensorflow 2 0 implementation paper image image translation using conditional gans philip isola jun yan zhu tinghui zhou alexei efros'\n 'landcover ai dataset automatic mapping buildings woodlands water aerial imagery'\n 'fast online object tracking segmentation unifying approach illustrate perform realtime object tracking semi supervised video object segmentation using fully convolutional siamese approach'\n 'intro autoencoders tutorial introduces autoencoders three examples basics image denoising anomaly detection'\n 'dgl deep graph library python package built ease deep learning graph top existing dl frameworks'\n 'cycle gan tensorflow 2 0 custom loops implementation unpaired image image translation using cycle consistent adversarial networks jun yan zhu et al'\n 'short notes model based offline reinforcement learning morel blog article model based offline reinforcement learning morel paper rahul kidambi aravind rajeswaran et al'\n 'huggingface nlp library nlp lightweight extensible library easily share load dataset evaluation metrics already providing access 100 datasets 10 evaluatio'\n 'ml foundations methods precision medicine healthcare tutorial discuss ideas machine learning enable personalization useful applications education retail medicine recsys'\n 'introduction image inpainting deep learning article going learn image inpainting e fill missing parts images precisely using deep learning'\n 'build textual similarity web app tensorflow js wondered search engines understand queries retrieve relevant results chatbots extract intent questions provide'\n 'gru transformer recurrent units self attention related'\n 'act github actions locally run github actions locally'\n 'ai basketball analysis ai web app api analyze basketball shots shooting pose'\n 'bert distillation catalyst distill bert catalyst'\n 'cs231n convolutional neural networks visual recognition deep dive details deep learning architectures focus learning end end models tasks particularly image classification'\n 'codequestion ask coding questions directly terminal'\n 'graph nets pytorch implementation explanation graph representation learning papers involving deepwalk gcn graphsage chebnet gat'\n 'vilbert mt multi task vision language representation learning single vilbert multi task model perform 8 different vision language tasks learnt 12 datasets'\n 'exploratory data analysis ms coco style datasets simple toolkit exploratory data analysis ms coco style formatted datasets'\n 'spinenet novel architecture object detection meta architecture called scale permuted model enables two major improvements backbone architecture design iscovered neural architecture search'\n 'efficient transformers survey characterizes large thoughtful selection recent efficiency flavored x former models'\n 'imagenette imagenette subset 10 easily classified classes imagenet'\n 'unsupervised reinforcement learning lecture unsupervised reinforcement learning sergey levine originally prepared aamas 2020'\n 'literate lamp answering question common sense study problem answering questions require common sense answered using transformer based models conceptnet knowledge base'\n 'bert loses patience fast robust inference early exit patience based early exit inference method used plug play technique simultaneously improve efficiency pretrained lm'\n 'cybert applying bert windows event logs blog shows interpreting cybersecurity logs natural language improving upon standard regex based parsing log data'\n 'fast neural style pytorch implementation algorithm artistic style transfer'\n 'keeping data pipelines healthy w great expectations gh actions show use github actions together open source project great expectations automatically test document profile data pipelines'\n 'fine tuning custom datasets tutorial take several examples using transformers models datasets'\n 'imaginaire nvidia pytorch gan library distributed mixed precision support'\n 'textaugment improving short text classification global augmentation methods'\n 'unsupervised learning probably symmetric deformable 3d objects method learn 3d deformable object categories raw single view images without external supervision'\n 'stackover flow data analysis analysing certain aspects stack overflow data creating tag predictor predicts tag based post posted'\n 'traffic sign recognition using deep learning training dataset contains around 39 000 images test dataset contains around 12 000 images containing 43 different classes using convolutio'\n 'safe space github action github action checks toxicity level comments pr reviews help make repos safe spaces'\n 'synthesizer rethinking self attention transformer models dot product self attention known central indispensable state art transformer models really required'\n 'pdftableextract build parser extract table pdf document retinanet'\n 'roberta meets tpus understanding applying roberta model current challenge'\n 'detectron2 fair next generation platform object detection segmentation'\n 'iyasai book recommendation system recommender system books stories could help loved ones lift mood whenever facing stress unpleasant situations'\n 'entity embedding lstm time series demonstration using lstm forecasting structured time series data containing categorical numerical features'\n 'biosyn biomedical entity representations synonym marginalization'\n 'implementing dcgans using pytorch c api libtorch blog discusses paper review dcgans implementation using pytorch c api detail loading models visualizing batch data c'\n 'object tracking 75 lines code object tracking straightforward conceptually good detector simple methods pretty effective'\n 'harry potter deep learning experiment rnn built tensorflow generate text based harry potter books'\n 'distributional rl using tensorflow2 implementation various distributional reinforcement learning algorithms using tensorflow2'\n 'smart picture editor tool automatically remove unwanted objects photos'\n 'lagrangian neural networks trying learn simulation try lagrangian neural networks explicitly conserve energy may generalize better'\n 'text preprocessing python using spacy library article explored text preprocessing python using spacy library detail fundamental step prepare data applications'\n 'top research papers ecml pkdd 2020 conference ecml pkdd selectionof best reaesch papers'\n 'pytest board continuous pytest runner awesome visualization'\n 'tracking objects points simultaneous object detection tracking using center points'\n 'spacy go spacy go golang interface accessing linguistic annotations provided spacy using google grpc module supports basic functionalities like lo'\n 'image gpt generative pretraining pixels transformers trained pixel sequences generate coherent image completions samples'\n 'neural cdes long time series via log ode method ncdes long time series via log ode method'\n 'learned looking 200 machine learning tools better understand landscape available tools machine learning production decided look every ai ml tool could find'\n 'bachgan high res image synthesis salient object layout propose new task towards practical application image generation high quality image synthesis salient object layout'\n 'arima modeling guide time series forecasting python arima models works train forecast using arima sarima sarimax find optimal model python'\n 'humour ai language model crack jokes language model make laugh humour ai model tries complete sentence humourous way given input words'\n 'graph convolutions dummies article explaining graph convolutional networks simply possible'\n 'guided uncertainty aware policy optimization combining learning model based strategies sample efficient policy learning'\n 'survey state explainable ai nlp overview operations explainability techniques currently available generating explanations nlp model predictions'\n 'table detection information extraction structuring using ml table extraction te task detecting decomposing table information document'\n 'live demo state art mcq generator content demo state art mcq multiple choice questions generator content built using t5 transformer huggingface sense2vec'\n 'movie recommendation system web app recommends movies based plots found imdb'\n 'pose animator takes 2d vector illustration animates containing curves real time based recognition result posenet facemesh'\n 'recurrent neural networks building gru cells vs lstm cells advantages rnn transformers use gru lstm equations gru really mean build gru cell pytorch'\n 'ttt fine tuning transformers tpus gpus acceleration ttt short package fine tuning transformers tpus written tensorflow2 0'\n 'text classification implemented article link given text classification cnn beside tried ml classification algorithm'\n 'temporal convolutional networks time series introduce several novels using tcn including improving traffic prediction sound event localization detection probabilistic forecasting'\n 'tsfresh automatic extraction relevant features time series'\n 'paragraph summarizer uses extractive way summarizing text finding score ranking'\n 'sktime python toolbox machine learning time series'\n 'upside reinforcement learning implementation udrl outlined juergen schmidhuber  arxiv org abs 1912 02875'\n 'neural networks nlp cmu cs 11 747 class start brief overview neural networks spend majority class demonstrating apply neural networks language'\n 'survey deep learning localization mapping towards age spatial machine intelligence'\n 'cvpr 2020 snapshot snapshot conference summarizing papers listing grabbed attention'\n 'bentoml bentoml open source framework high performance ml model serving'\n 'high fidelity generative image compression combine generative adversarial networks learned compression obtain state art generative lossy compression system'\n 'nsfw image classification rest api built tensorflow js ready use open source nsfw image classification rest api built tensorflow js nsfw js effortless content moderation'\n 'short notes batch constrained deep reinforcement learning blog article policy deep reinforcement learning without exploration paper fujimoto et al icml 2019'\n 'deepway autonomous navigation blind tried make something used blind people navigate around streets look video github repo details'\n 'softbot design wanns soft robots robots built highly compliant materials similar found living organisms project explored cppns wanns design'\n 'universal sentence encoder visually explained deep dive universal sentence encoder learns generate fixed length sentence embeddings'\n 'rasa nlu examples experimental components rasa nlu pipelines'\n 'image synthesis cvpr 2020 overview different approaches image synthesis cvpr 2020'\n 'superglue learning feature matching graph neural networks superglue neural network matches two sets local features jointly finding correspondences rejecting non matchable points'\n 'transfer learning fine tuning keras 100 date guide transfer learning fine tuning keras'\n 'snaked classifying snake species using images proof concept possible identify snake species whether poisonous photographs pytorch code model android app'\n 'efficient serverless deployment pytorch models azure tutorial serving models cost effectively scale using azure functions onnx runtime'\n 'exploring knowledge captured probability strings exploration simple knowledge captured language models code examples'\n 'using different decoding methods lm transformers look different decoding methods generate subsequent tokens language modeling'\n 'ccnet pytorch pytorch implementation ccnet criss cross attention semantic segmentation'\n 'neuralcook image2ingredients cooking recommendation deep learning application identify ingredients cooking dishes images recommend dishes cook given set ingredients'\n 'semantic segmentation background removal style transfer running multiple tf lite models perform semantic segmentation remove background apply style transfer'\n 'graph neural networks descriptive guide graph neural networks'\n 'neptune ai lightweight experiment management tool fits workflow'\n 'transfer learning nlp brief history transfer learning nlp'\n 'nlpaug data augmentation nlp'\n 'chakin simple downloader pre trained word vectors'\n 'self driving car project demonstration working model self driving car identifying following lanes using powerful computer vision algorithms'\n 'appnp ppnp pytorch implementation predict propagate graph neural networks meet personalized pagerank iclr 2019'\n 'frimcla framework image classification frimcla open source framework image classification using traditional deep learning techniques supports wide variety deep learning c'\n 'detr end end object detection transformers new method views object detection direct set prediction problem'\n 'autosweep recovering 3d editable objects single photo fully automatic framework extracting editable 3d objects directly single photograph'\n 'next word prediction using transformers predict next word predict mask word'\n 'overview early vision inceptionv1 guided tour first five layers inceptionv1 taxonomized neuron groups'\n 'better nlp project wrapper program library encapsulates couple nlp libraries popular among ai ml communities'\n 'real time text detection east tflite demonstrates conversion process original east model tflite use static images also real time video feeds'\n '2019 guide human pose estimation deep learning basics human pose estimation 2d review literature topic'\n 'shift ctrl f semantic search browser search information available webpage using natural language instead exact string match'\n 'hyperparameter optimization transformers guide basic grid search optimal fact hyperparameters choose significant impact final model performance'\n 'intuitive guide deep network architectures intuition behind base network architectures like mobilenets inception resnet'\n 'data analysis made easy text2code jupyter notebook jupyter notebook extension text2code basic pandas plotly commands'\n 'sparse sinkhorn attention new efficient sparse method learning attend based differentiable sorting internal representations'\n 'onceupon space nlp experiment story telling creates illustrations text sketch content text generation'\n 'high resolution image inpainting high resolution image inpainting iterative confidence feedback guided upsampling'\n 'real time object detection using cnn yolo project done real time object detection using deep learning object detection algorithm e yolo'\n 'machine learning deserves flavor continuous delivery traveling data science world homesick smooth continuous delivery flow thoughts approachable cd4ml'\n 'gans computer vision article review series article series review important research papers gans 2015 today 6 articles 20 papers 20000 words'\n 'graphnorm principled approach accelerating graph neural network training'\n 'building captcha ocr tf2 0 kaggle notebook showcasing use endpoint layer ctc loss function used building captcha reader tensorflow'\n 'gabornet modified network architecture focuses improving convergence reducing training complexity'\n 'biowordvec biosentvec pre trained embeddings biomedical words sentences'\n 'object detection dummies go several basic concepts algorithms popular deep learning models image processing object detection'\n 'token2index lightweight powerful library build token indices nlp tasks compatible major deep learning frameworks like pytorch tensorflow'\n 'paint machine learning web app allows create landscape painting style bob ross using deep learning model served using spell model server'\n 'norfair lightweight python library adding real time 2d object tracking detector'\n 'tensorboard dev easily host track share ml experiments free'\n 'atlass automl using transfer semi supervised learning repository includes code application notebooks work automl using transfer semi supervised learning tools presented'\n 'simplegan tensorflow based framework ease training generative models'\n 'pytorch forecasting time series forecasting pytorch'\n 'convnet playground interactive visualization exploring convolutional neural networks applied task semantic image search'\n 'illustrated guide transformers step step explanation post focus one paper started attention need'\n 'dialogpt toward human quality conversational response generation large scale pre training dialogue'\n 'pifuhd high resolution 3d human digitization repository contains pytorch implementation multi level pixel aligned implicit function high resolution 3d human digitization'\n 'small differences bleu meaningless big differences metric scores meaningful mt'\n 'social distance detection people close red bounding box displayed around indicating maintaining social distance'\n 'important monitor machine learning models importance monitoring monitoring ml different application performance management apm'\n 'semantic graphs generating deep questions deep question generation dqg aims generate complex questions require reasoning multiple pieces information input passage'\n 'docker help become effective data scientist look docker perspective data scientist'\n 'introduction nlp using fastai implementing decoding revolutionary ulmfit approach train language model downstream nlp task'\n 'attentron shot text speech exploiting attention based variable length embedding'\n 'scene classification using pytorch fast ai objective classify multi label images using deep learning used fast ai library implementing model'\n 'practical ai using nlp word embeddings solve localization using nlp word vectors word2vec glove etc novel way solve problem localization edtech'\n 'exploration strategies deep reinforcement learning exploitation versus exploration critical topic reinforcement learning post introduces several common approaches better exploration deep rl'\n 'effective testing machine learning systems testing machine learning systems different discuss strategies writing effective tests machine learning systems'\n 'optimizing mobiledet mobile deployments learn criticalities effectively optimizing mobiledet object detectors mobile deployments'\n 'implementation face net tensorflow 2 0 repository naive unofficial implementation face net paper 2015 implementation opts online mode semi hard triplet mining'\n 'bertology meets biology interpreting attention protein language models'\n 'vott visual object tagging tool electron app building end end object detection models images videos'\n 'goturn pytorch pytorch implementation learning track 100 fps deep regression networks'\n 'yolov4 tensorflow 2 0 implementation yolov4 optimal speed accuracy object detection'\n 'state transfer learning nlp post expands naacl 2019 tutorial transfer learning nlp highlights key insights takeaways provides updates based recent work'\n 'pokezoo deep learning based web app developed using mern stack tensorflow js'\n 'torchio medical image processing deep learning pytorch tools medical image processing deep learning pytorch'\n '15 best tools tracking machine learning experiments feature comparison open source commercial options experiment tracking'\n 'test time data augmentation tutorial properly implement test time image data augmentation production environment limited computational resources'\n 'elastictransformers making bert stretchy semantic elasticsearch sentence transformers'\n '12 factors reproducible machine learning production took experience deduce 12 factors nod 12 factor app build backbone successful ml production'\n 'latest advancements video streaming ai ai developments video streaming using super resolution per title encoding p2p'\n 'overview semantic image segmentation image segmentation computer vision task label specific regions image according shown'\n 'classify photos 600 classes using nine million open images looking build image classifier need training data look google open images'\n 'easy data augmentation eda easy data augmentation techniques boosting performance text classification tasks'\n 'ulmfit airline sentiment analysis transfer learning using pretrained ulmfit model'\n 'drifter ml machine learning testing framework sklearn pandas goal help folks assess whether things changed time'\n 'tensorflowtts real time sota speech synthesis tensorflow 2 0 tensorflowtts provides real time state art speech synthesis architectures tacotron2 melgan fastspeech'\n 'introduction machine learning problem framing course helps frame machine learning ml problems'\n 'ganspace discovering interpretable gan controls paper describes simple technique analyze generative adversarial networks gans create interpretable controls image synthesis'\n 'gnnexplainer generating explanations graph neural networks general tool explaining predictions made graph neural networks gnns'\n 'long form question answering eli5 model open domain long form question answering'\n 'awesome monte carlo tree search curated list monte carlo tree search papers implementations'\n 'self supervised learning computer vision pre trained models domain'\n 'question answering fine tuned bert mean bert achieve human level performance question answering'\n 'semantic cord19 paper explorer semantic research paper explorer search research papers covid coronavirus easily modified research paper database'\n 'eccv 2020 highlights sort snapshot conference summarizing papers listing grabbed attention'\n 'estorch estorch evolution strategy library build around pytorch'\n 'latent graph neural networks manifold learning 2 0 parallels recent works latent graph learning older techniques manifold learning'\n 'gan bert enhancing bert training semi supervised generative adversarial networks'\n 'building intelligent twitter bot volume information going twitter per day makes one best platforms get information subject interest'\n 'deepr training tensorflow models production deepr python library build complex pipelines easily possible top tensorflow'\n 'exploratory data analysis time series exploratory data analysis time series data python uses lot principles concepts discussed prof hyndman book focus understa'\n 'temporal graph networks post describe temporal graph network generic framework deep learning dynamic graphs'\n 'commit history bert forks commit history version controlled research papers could look like'\n 'proteingcn protein model quality assessment using gcns source code paper proteingcn protein model quality assessment using graph convolutional networks'\n 'monai ai toolkit healthcare imaging'\n 'scitldr extreme summarization scientific documents new automatic summarization task high source compression requiring expert background knowledge complex language understanding'\n 'bad passwords nist guidelines example project provided datacamp project write code automatically detects flags bad passwords'\n 'time series classification using deep learning article introduce new package called timeseries fastai2 lately developed'\n 'siamfc towards robust accurate visual tracking implementation series basic algorithms useful video understanding including single object tracking sot video object segmentation vos'\n 'message passing gnns c c implementation using eigen forward pass graph convolutional neural networks'\n 'nlp pandect nlp resources one place nlp pandect created help find almost anything related natural language processing available online'\n 'object goal navigation using goal oriented semantic exploration embodied interactive learning object detection using semantic curiosity learn exploration policy set training environments'\n 'deep learning image super resolution survey article aims provide comprehensive survey recent advances image super resolution using deep learning approaches'\n 'sentiment analysis news article used twitter api extract news related tweets preprocessing calculated tweets polarity'\n 'yolov3 implementation keras tensorflow 2 2 yolov3 real time object detector tensorflow 2 2'\n 'fastai2 vision module detailed guide using fastai2 datablock api common computer vision tasks'\n 'interpretable machine learning computer vision recent progress made visualization interpretation explanation methodologies analyzing data models computer vision'\n 'teachable machine image classifier teachable image classifier runs browser built using tensorflow js'\n 'distilling knowledge neural networks project demonstrates compelling model optimization technique knowledge distillation code walkthroughs tensorflow'\n 'vedaseg vedaseg open source semantic segmentation toolbox based pytorch'\n 'nlp viewer simple website browsing popular nlp datasets'\n 'using data science pipelines disaster response uses etl ml pipeline build nlp system classification messages appropriate disaster categories'\n 'guide natural language processing allennlp basics using allennlp'\n 'create cartoonizer tensorflow lite end end tutorial convert tensorflow lite tflite model deploy android app cartoonizing image captured camera'\n 'nsfw image moderation admin app reactjs fully functional nsfw admin application simplified image classification moderation built node js tensorflow js react'\n '3d ken burns effect single image implementation 3d ken burns effect single image using pytorch'\n 'medical zoo 3d multi modal medical image segmentation articles deep learning medical imaging'\n 'yolov4 optimal speed accuracy object detection minimal implementation yolov4'\n 'coreml model zoo collection unified converted pre trained models'\n 'neural style transfer tutorial uses deep learning compose one image style another image ever wish could paint like picasso van gogh'\n 'tao large scale benchmark tracking object diverse dataset tracking object tao consisting 2 907 high resolution videos captured diverse environments half minute long'\n 'onnx t5 summarization translation q text generation blazing speed using t5 version implemented onnx'\n 'comprehensive survey graph neural networks comprehensive survey graph neural networks'\n 'text feature selection causal inference identifying linguistic features cause people act certain way reading text regardless confounding variables something people'\n 'injecting inductive bias graph neural networks mit talk equivariant mesh neural networks neural augmented factor graph neural networks'\n 'finetune scikit learn style model finetuning nlp finetune library allows users leverage state art pretrained nlp models wide variety downstream tasks'\n 'zero shot neural retrieval via domain targeted synthetic queries zero shot learning ad hoc retrieval models relies synthetic query generation'\n 'machine learning deployment shadow mode test new model production one answer method often employ initially deploying models shadow mode'\n 'real python recommendation engine full stack data science project performs document similarity realpython com content content recommendations implemented via chrome extension'\n 'contextualized topic models python package run contextualized topic modeling'\n 'automated time series forecasting data app uses facebook open source prophet library automatically forecast values future'\n 'stellargraph machine learning graphs state art algorithms graph machine learning making easy discover patterns answer questions graph structured data'\n 'implementing graph neural networks jax talk experience build train graph neural networks gnns jax'\n 'training game agents supervised learning continuing research project trying find ways learn complex tasks games without using reinforcement learning'\n 'face verification implementation siamese neural network model used face verification dataset used task imdb wiki face images dataset'\n 'sized fill blank multi mask filling roberta sized fill blank conditional text filling idea filling missing words sentence probable choice words'\n 'attributed social network embedding sparsity aware memory efficient implementation attributed social network embedding tkde 2018'\n 'indian paper currency prediction trained model takes image indian paper currency input predict class image 10 20 50 100 200 500 2000 denomination'\n 'clinical bert repository publicly available clinical bert embeddings'\n 'hmtl hierarchical multi task learning state art neural network model several nlp tasks based pytorch allennlp'\n 'top 10 deep learning breakthroughs deep reinforcement learning article unravels journey behind reaching point reinforcement learning combined deep learning defeated go player world champion'\n 'discovering symbolic models deep learning w inductive bias general approach distill symbolic representations learned deep model introducing strong inductive biases'\n 'linear attention transformer fully featured transformer mixes qk v local attention q k v global attention scales linearly respect sequence length'\n 'designer gpt2 bot talks ux design twitter profile spits thoughts design development trained hundreds books ux design front end development opinions'\n 'albumentations fast image augmentation library easy use wrapper around libraries'\n 'dash detr detection app user interface detr built dash 100 python'\n 'basic ml algorithms scratch implement basic machine learning algorithms scratch python'\n 'neural machine translation attention notebook trains sequence sequence seq2seq model spanish english translation'\n 'dropout pytorch example example adding dropout pytorch model observe effect dropout model performance tracking models weights biases'\n 'build first data warehouse airflow gcp steps building data warehouse cloud technology use use airflow orchestrate pipeline'\n 'r u stoked nlp sentiment analysis project demonstrate pipeline data first stage data collection ml model deployment'\n 'pattern exploiting training pet repository contains code exploiting cloze questions shot text classification natural language inference'\n 'bingoset cli tool create image dataset cli toolkit quickly create image dataset using bing image search api'\n 'asap pooling graph neural network aaai 2020 asap sparse differentiable pooling method addresses limitations previous graph pooling layers'\n 'stochastic segmentation networks efficient probabilistic method modelling aleatoric uncertainty image segmentation network architecture'\n 'image super resolution project learn train super resolution model espcn div2k dataset upscale images using ai 3x'\n 'models checkpoints hugging face massive growing collection nlp models nearly nlp tasks especially involving use transformers'\n 'optimize ml models learn use optimize custom image classification models built tf keras using tensorflow lite gain 10x reduction model size'\n 'tudatasets collection benchmark datasets graph classification regression'\n 'bert summarization folder contains colab notebooks guide summarization bert gpt 2 play data'\n 'nature scene classification using fastai classifying nature scene images using deep learning fastai library'\n 'ai debate master created deployed bot made debate human given topic employed doc2vec model using gensim library python'\n 'pixellib pixellib library performing segmentation images'\n 'machine learning production pipeline project flow landscape'\n 'practical tips tricks successful transfer learning training models learn knowledge skills related tasks transfer boost performance tasks interest'\n 'tableqa ai tool querying natural language tabular data like csvs dataframes'\n 'wt5 training text text models explain predictions leverage text text framework proposed raffel et al 2019 train language models output natural text explanation alongside prediction'\n 'melanoma classification shubhamai 3 week project working new kaggle competition deploying web application predicting benign malignant based images'\n 'diffusion vector reference implementation diffusion2vec complenet 2018 built gensim networkx'\n 'tensorflow2 object detection tutorial tutorial going step step complete training process tensorflow2 object detection'\n 'mlflow machine learning lifecycle platform open source platform machine learning lifecycle'\n 'build sota conversational ai transfer learning train dialog agent leveraging transfer learning openai gpt gpt 2 transformer language model'\n 'big bad nlp database collection 400 nlp datasets papers included'\n 'author identification using doc2vec web app author identification model trained pan 2012 dataset kaggle spooky authorship dataset'\n 'teacheasy web app text summarization q generation intuitive streamlit based web app text summarization question answer generation reduce work school teachers'\n 'long peek reinforcement learning post gonna briefly go field reinforcement learning rl fundamental concepts classic algorithms'\n 'images radio boxes collected 15 k raw images radio boxes across 500 forms hand picked 200 images used determine radio box checked'\n 'visual guide self labelling images self supervised method generate labels via simultaneous clustering representation learning'\n 'dframcy dframcy light weight utility module integrate pandas dataframe spacy linguistic annotation training tasks'\n 'semixup manifold regularization semixup semi supervised learning method based manifold regularization'\n 'feature stores ml list production ml groups open source feature store architectures'\n 'intro facebook prophet everything need know starting facebook time series forecasting tool'\n 'machine learning methods explained examples common techniques used data science projects get know easy understand examples put practice ml projects'\n 'deep learning based super resolution without using gan techniques training deep learning model image improvement image restoration inpainting super resolution'\n 'topic modeling bert leveraging transformers class based tf idf create dense clusters allowing easily interpretable topics'\n 'axcell automatic extraction results machine learning papers'\n 'two step graph convolutional decoder molecule generation simple auto encoder framework molecule generation'\n 'fast nst videos person segmentation create nst videos pick separate styles person video background'\n 'allennlp open source nlp research library built pytorch'\n 'visual paper summary albert lite bert illustrated summary albert paper improves bert makes resource efficient'\n 'textattack python framework building adversarial attacks nlp models'\n 'stop worrying compositionality review tenets compositionality highlight theory evolved match particular theoretical positions nature language'\n 'shape viewpoint without keypoints recover 3d shape pose texture single image trained image collection without ground truth 3d shape multi view camera viewpoints'\n 'tslearn machine learning toolkit dedicated time series data'\n 'five cool python libraries data science python best friend majority data scientists libraries make life simpler come across five cool python libraries working'\n 'plant disease detection website help detect disease plant based plant leaf image'\n 'face mask detector simple streamlit frontend face mask detection images using pre trained keras cnn model opencv model interpretability'\n '3d face fast accurate stable reconstruction work extends previous work 3ddfa named 3ddfa v2 titled towards fast accurate stable 3d dense face alignment accepted eccv 2020'\n 'nearest celebrity face implementation facenet unified embedding face recognition clustering find celebrity whose face matches closest input face'\n 'make sense reinforcement learning agents log training debug'\n 'course review causal inference types understanding causal inference researchers value'\n 'computer vision pretrained models collection computer vision pre trained models'\n 't5 fine tuning colab notebook showcase fine tune t5 model various nlp tasks especially non text 2 text tasks text 2 text approach'\n 'benchmark models transformers huggingface transformer library allows users benchmark models tensorflow 2 pytorch using pytorchbenchmark tensorflowbenchmark classes'\n 'pytorch transformers tutorials set annotated jupyter notebooks give user template fine tune transformers model downstream nlp tasks classification ner etc'\n 'train albert nlp tensorflow amazon sagemaker train bert 1 hour efficiently scaled 2 048 nvidia v100 gpus improving underlying infrastructure network ml framework'\n 'simple transformers transformers made easy simple transformers removes complexity lets get matters model training experimenting transformer model architectures'\n 'natural language processing roadmap roadmap learning nlp topics'\n 'rules machine learning best practices ml engineering basic knowledge machine learning get benefit best practices machine learning around google'\n 'named entity recognition tagging post go example natural language processing learn load text data perform ner tagging token'\n 'ai economist improving equality productivity ai driven tax policies'\n 'twitter sentiment analysis project based natural language processing nlp sentiment analysis e much positive negative tweets account'\n 'image segmentation 2020 architectures losses datasets frameworks'\n 'research production deep semi supervised learning semi supervised learning ssl blossomed deep learning research community share lessons learned 15 months taking ssl production'\n 'finding similar documents transformers transformers help us distill text documents points n dimensional vector spaces'\n 'shakespeare meets google flax application rnns flax character level language model'\n 'fast api dockerization ml models github repo able know learn build fast api testing ml model test ml model ui dockerize ml'\n 'million ml predictions tip fingers announcement sashido breaking barrier machine learning introducing fully open sourced content moderation service'\n 'nlp developers multilingual nlp rasa video rasa developer advocate rachael talk common approaches handle language input one language'\n 'web mining information theory mining web playing natural language processing implementing information retrieval system tasks going towards nlp performing machine learning algorithms codes problems understood information retrieval process search engine useful problems towards sentiment analysis'\n 'extension block nsfw content using ai nsfw filter extension blocks nsfw content browser uses computer vision model detect nsfw content hides user'\n 'deep learning graph structured representations novel approaches based theme structuring representations computations neural network based models form graph'\n 'dakshina dataset collection text latin native scripts 12 south asian languages'\n 'visualizing neural machine translation model mechanics seq2seq models attention'\n 'jukebox generative model music introducing jukebox neural net generates music including rudimentary singing raw audio variety genres artist styles'\n 'paraphrase generation using t5 model simple application using t5 base model fine tuned quora question pairs generate paraphrased questions'\n 'sudoku game solver computer vision application solves 9x9 sudoku board game using deep learning backtracking algorithm'\n 'ufod unified framework object detection ufod open source framework enables training comparison object detection models custom datasets using different underlying frameworks'\n 'design patterns production nlp systems designs tips designing nlp production systems'\n 'cs224n natural language processing deep learning course students gain thorough introduction cutting edge research deep learning nlp'\n 'med7 clinical natural language processing ehr med7 transferable clinical natural language processing model electronic health records compatible spacy named entity recognition task'\n 'forex prediction using neural networks predict movement forex direction'\n 'solt data augmentation deep learning data augmentation library deep learning supports images segmentation masks labels key points'\n 'wheat detection project detecting creating bounding box wheat heads'\n 'deep learning object detection comprehensive review closer look tensorflow object detection models faster r cnn r fcn ssd'\n 'embedding projector visualization high dimensional data namely embeddings'\n 'practical text classification python keras get grasp current advancements deep neural networks applied text'\n 'layered neural rendering retiming people video manipulating editing time different motions individuals video occur'\n 'semi supervised learning computer vision comprehensive overview recent semi supervised learning methods computer vision'\n 'fairseq tagging fairseq fork sequence tagging labeling tasks'\n 'twitter turing test guess whether tweet written human generated neural network'\n 'learning see learning act visual pre training find pre training vision tasks significantly improves generalization sample efficiency learning manipulate objects'\n 'toward better storylines sentence level language models propose sentence level language model selects next sentence story finite set fluent alternatives'\n 'multimodal meme classification uniter given state art results various image text related problems project aims finetuning uniter solve hateful memes challenge'\n 'detectron 2 demo facebook project contains process getting started facebook fair detectron2 project windows 10 without nvidia gpu'\n 'illustrated self supervised learning visual introduction self supervised learning methods computer vision'\n 'drowsiness detection system using opencv flask python system provides overview system detects whether person drowsy driving alerts using voice messages real time'\n 'multi target albumentations many images many masks bounding boxes key points transform sync'\n 'yolov4 tensorflow yolov4 yolov4 tiny yolov3 yolov3 tiny implemented tensorflow 2 0 android convert yolo v4 weights tensorflow tensorrt tflite'\n 'tf lite semantic segmentation models faster lighter tf lite models perform semantic segmentation'\n 'transmomo invariance driven unsupervised motion retargeting lightweight video motion retargeting approach capable transferring motion person source video realistically another video target'\n 'summarize webapge flask application extracts summarizes webpage using natural language processing powered nlp akash'\n 'electra pre training text encoders discriminators pytorch implementation electra model paper electra pre training text encoders discriminators rather generators'\n 'super bpd fast image segmentation propose direction based super bpd alternative superpixel fast generic image segmentation achieving state art real time result'\n 'electra pytorch electra pytorch fastai huggingface unofficial reimplementation electra pre training text encoders discriminators rather generators'\n 'tf geometric efficient friendly graph neural network library tensorflow 1 x 2 x'\n 'farm framework adapting representation models fast easy transfer learning nlp harvesting language models industry'\n 'top introduction bert huggingface pytorch also provide intuition bert works top approach applications algorithm'\n 'building ai trading systems lessons learned building profitable algorithmic trading system using reinforcement learning techniques'\n 'medcat medical concept annotation tool tool used extract information electronic health records ehrs link biomedical ontologies like snomed ct umls'\n 'efficientdet scalable efficient object detection implementation efficientdet scalable efficient object detection pytorch'\n 'show infer tell contextual inference creative captioning beauty work lies way architects fundamental idea humans look overall image individual pieces'\n 'doccano open source text annotation tool machine learning practitioner'\n 'time series forecasting tensorflow js machine learning becoming increasingly popular days growing number world population see magic crystal ball predicting'\n 'deep q network space invaders pytorch implementation deep q network agent trained play atari 2600 game space invaders'\n 'computer vision recipes repository provides examples best practice guidelines building computer vision systems'\n 'age gender estimation using multi task cnn used multi task cnn predict age group gender person image'\n 'machine learning fastai fastai library based research deep learning best practices undertaken fast ai includes support vision text tabular collab'\n 'machine learning systems design designing machine learning system'\n 'close domain fine tuning table detection project show benefits using models trained close domain using tablebank dataset fine tuning table detection models additio'\n 'hidden technical debt machine learning systems using software engineering framework technical debt find common incur massive ongoing maintenance costs real world ml systems'\n 'pcdet 3d point cloud detection pcdet toolbox pytorch 3d object detection point cloud'\n 'pytorch cnn trainer simple package fine tune cnns torchvision pytorch image models ross wightman'\n 'trained machine learning model three often overlooked parts process occur model actually built model evaluation deployment monitoring'\n 'nsfw image moderation automation engine built tensorflow js open source nsfw image classifier including automation engine fast deletion moderation built node js tensorflow parse server'\n 'deploying ml model torchserve talk brad heintz walks use torchserve deploy trained models scale without writing custom code'\n 'common architectures convolutional neural networks post discuss commonly used architectures convolutional networks'\n 'marge pre training via paraphrasing retrieval model maps document set related documents reconstruction model paraphrases maximize likelihood original'\n 'tokenizers fast state art tokenizers optimized research production'\n 'lyrics based music genre classifier classify genre rock pop hip hop available metal country jazz electronic r b indie folk song lyrics'\n 'unsupervised keyphrase extraction learn unsupervised algorithms automatically extracting representative keyword phrases documents'\n 'understanding text bert building machine reading comprehension system using latest advances deep learning nlp'\n 'digital image processing python play around pixel values python programming language'\n 'driver identification based vehicle telematics data paper proposed deep learning model identify drivers driving behaviors based vehicle telematics data'\n 'rasa open source machine learning framework automate text voice based conversations'\n 'laplacian pyramid reconstruction refinement semantic seg pytorch implementation multi resolution reconstruction architecture based laplacian pyramid uses skip connections'\n 'pytorch3d fair library reusable components deep learning 3d data'\n 'torchvision object detection finetuning tutorial finetuning pre trained mask r cnn model penn fudan database pedestrian detection segmentation'\n 'comparison yolo rcnn real world videos bringing theory experiment cool easily train models colab find results minutes'\n 'easy ocr ready use ocr 40 languages supported including chinese japanese korean thai'\n 'training batch norm batch norm experiments ideas presented  arxiv org abs 2003 00152 frankle et al'\n '2020 guide semantic segmentation concept image segmentation discuss relevant use cases different neural network architectures involved achieving results metrics datasets'\n 'object detection multi template matching python package allows perform object detection using one template images provides simpler alternative deep learning methods'\n 'roberta longformer build long version pretrained models notebook replicates procedure descriped longformer paper train longformer model starting roberta checkpoint'\n 'hugging face achieved 2x performance boost qa question answering distilbert node js'\n 'network fusion content creation conditional inns present method repurpose powerful existing models new tasks even though never designed'\n 'gp gan towards realistic high resolution image blending blending composite images using generative model gaussian poisson equation laplacian pyramid'\n 'coco annotator web based image segmentation tool object detection localization key points'\n 'compressing bert faster prediction blog post discuss ways make huge models like bert smaller faster'\n 'continuous machine learning cml cml helps organize mlops infrastructure top traditional software engineering stack instead creating separate ai platforms'\n 'ecg arrhythmia classification using convolutional neural net implementation paper ecg arrhythmia classification  arxiv org pdf 1804 06812 pdf'\n 'sentiment classification utapass kkbox reviews text classification reviews utapass kkbox using different deep learning models'\n 'using selective attention reinforcement learning agents work establish self attention viewed form indirect encoding enables us construct highly parameter efficient agents'\n 's2igan speech image generation via adversarial learning speech image generation s2ig framework proposed translates speech descriptions photo realistic images without using text information'\n 'mini pokedex end end tutorial gotta classify em build pokemon image classifier classify awesome starters pikachu charmander squirtle bulbasaur'\n 'transformers scratch attempt explain directly modern transformers work without historical baggage'\n 'jepto digital marketing analytics kpi prediction anomaly detection digital marketing data technical non technical marketers business owners'\n 'behavioral testing nlp models checklist overview checklist framework fine grained evaluation nlp models'\n 'machine learning projects repo contains projects done learning basics familiar types regression classification clustering methods used'\n 'stefann scene text editor using font adaptive neural network generalized method realistic modification textual content present scene image accepted cvpr 2020'\n 'ensemble methods object detection repository provide code ensembling output object detection models applying test time augmentation object detection lib'\n 'evaluate longformer triviaqa using nlp evaluate pretrained longformerforquestionanswering model validation dataset triviaqa'\n 'differentiable adaptive computation time visual reasoning dact new algorithm achieving adaptive computation time unlike existing approaches fully differentiable'\n 'epipolar transformers differentiable epipolar transformer enables 2d detector leverage 3d aware features improve 2d pose estimation'\n 'nlp developers word embeddings rasa video rasa developer advocate rachael talk word embeddings work used common errors'\n 'illustrated self attention step step guide self attention illustrations code'\n 'leveraging temporal context object detection object detection architecture leveraging contextual clues across time camera deployment network improving recognition objects'\n 'qsvm quantum svm sentiment analysis'\n 'tensorflow 2 meets object detection api tf object detection api od api officially supports tensorflow 2'\n 'multi task nlp utility toolkit enabling nlp developers easily train infer single model multiple tasks'\n 'artifacts weights biases effortless pipeline tracking production model management'\n 'bridging pytorch tvm taking hugging face transformer bert pytorch running apachetvm inference reasonable timings training'\n 'fast neural style transfer feed forward method repo contains concise pytorch implementation original feed forward nst paper'\n 'jiant software toolkit research general purpose text understanding models'\n 'end end object detection tensorflow lite project shows train custom detection model tfod api optimize tflite perform inference optimized model'\n 'model agnostic meta learning reinforcement learning tf2 reimplementation model agnostic meta learning maml applied reinforcement learning problems tensorflow 2'\n 'optimal transport sinkhorn transformer understand optimal transport sinkhorn knopp algorithm diving sinkhorn transformer'\n 'pictranslate seamless live image text translator given image text app give new image text modified different language'\n 'simplest way serve nlp model production w python scikit learn hugging face pipelines learn simplest way deploy ml models using ray serve'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Oversample (training set)\n",
    "oversample = RandomOverSampler(sampling_strategy=\"all\")\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "36d2ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: [272 272 272 272],\n",
      "class weights: {0: 0.003676470588235294, 1: 0.003676470588235294, 2: 0.003676470588235294, 3: 0.003676470588235294}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_over)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aabdd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01aaa5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SGDClassifier(\n",
    "    loss=\"log\", penalty=\"l2\", alpha=1e-4, max_iter=1,\n",
    "    learning_rate=\"constant\", eta0=1e-1, power_t=0.1,\n",
    "    warm_start=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7b7b30a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00|train_loss: 1.168809,val_loss: 1.20216\n",
      "Epoch: 10|train_loss: 0.461614,val_loss: 0.62198\n",
      "Epoch: 20|train_loss: 0.315400,val_loss: 0.51541\n",
      "Epoch: 30|train_loss: 0.251478,val_loss: 0.47084\n",
      "Epoch: 40|train_loss: 0.216510,val_loss: 0.44734\n",
      "Epoch: 50|train_loss: 0.195472,val_loss: 0.43314\n",
      "Epoch: 60|train_loss: 0.181702,val_loss: 0.42407\n",
      "Epoch: 70|train_loss: 0.172406,val_loss: 0.41808\n",
      "Epoch: 80|train_loss: 0.165914,val_loss: 0.41399\n",
      "Epoch: 90|train_loss: 0.161182,val_loss: 0.41096\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.fit(X_over, y_over)\n",
    "    #Evaluation\n",
    "    train_loss = log_loss(y_train,model.predict_proba(X_train))\n",
    "    val_loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    \n",
    "    if not epoch%10:\n",
    "        print(\n",
    "            f\"Epoch: {epoch:02d}|\"\n",
    "            f\"train_loss: {train_loss:05f},\"\n",
    "            f\"val_loss: {val_loss:.5f}\"\n",
    "            \n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7e5ca070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8764647844565878,\n",
      "  \"recall\": 0.875,\n",
      "  \"f1\": 0.8737886461377173\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae65a0",
   "metadata": {},
   "source": [
    "### Limitations:\n",
    "\n",
    "representation: TF-IDF representations don't encapsulate much signal beyond frequency but we require more fine-grained token representations that can account for the significance of the token itself (embeddings).\n",
    "architecture: we want to develop models that can use better represented encodings in a more contextual manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "992fbcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference (with tokens similar to training data)\n",
    "text = \"Transfer learning with transformers for text classification.\"\n",
    "y_pred = model.predict(vectorizer.transform([text]))\n",
    "label_encoder.decode(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f52545a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer-vision': 0.031620508668047075,\n",
       " 'mlops': 0.003537301081046674,\n",
       " 'natural-language-processing': 0.9533040304105429,\n",
       " 'other': 0.01153815984036319}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities\n",
    "y_prob = model.predict_proba(vectorizer.transform([text]))\n",
    "{tag:y_prob[0][i] for i, tag in enumerate(label_encoder.classes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "751f54bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference (with tokens not similar to training data)\n",
    "text = \"Interpretability methods for explaining model behavior.\"\n",
    "y_pred = model.predict(vectorizer.transform([text]))\n",
    "label_encoder.decode(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "276f224d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer-vision': 0.14143425241550953,\n",
       " 'mlops': 0.10863564113169033,\n",
       " 'natural-language-processing': 0.6606401665967966,\n",
       " 'other': 0.08928993985600366}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities\n",
    "y_prob = model.predict_proba(vectorizer.transform([text]))\n",
    "{tag:y_prob[0][i] for i, tag in enumerate(label_encoder.classes)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f201bf",
   "metadata": {},
   "source": [
    "We're going to create a custom predict function where if the majority class is not above a certain softmax score, then we predict the other class. In our objectives, we decided that precision is really important for us and that we can leverage the labeling and QA workflows to improve the recall during subsequent manual inspection.\n",
    "\n",
    "Warning:\n",
    "\n",
    "Our models can suffer from overconfidence so applying this limitation may not be as effective as we'd imagine, especially for larger neural networks. See the confident learning section of the evaluation lesson for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3fd30f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'content style disentanglement artistic style transfer hi res style transfer interpolation styles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12368\\836101120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Determine first quantile softmax score for the correct class (on validation split)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Q1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlops\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'content style disentanglement artistic style transfer hi res style transfer interpolation styles'"
     ]
    }
   ],
   "source": [
    "# Determine first quantile softmax score for the correct class (on validation split)\n",
    "y_pred = model.predict(X_val)\n",
    "y_prob = model.predict_proba(X_val)\n",
    "threshold = np.quantile([y_prob[i][j] for i, j in enumerate(y_pred)], q=0.25)  # Q1\n",
    "threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b232d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom predict function\n",
    "def custom_predict(y_prob, threshold, index):\n",
    "    '''custom predict functions that defaults to \n",
    "    an index if conditions are not met'''\n",
    "    y_pred = [np.argmax(p) if max(p) > threshold else index for p in y_prob]\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d143971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tag(texts):\n",
    "    y_prob = model.predict_proba(vectorizer.transform(texts))\n",
    "    other_index = label_encoder.class_to_index[\"other\"]\n",
    "    y_pred = custom_predict(y_prob=y_prob,threshold=threshold, index=other_index)\n",
    "    return label_encoder.decode(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c4b06722",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12368\\397492479.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Inference (with tokens not similar to training data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Interpretability methods for explaining model behavior.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredict_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12368\\3309116470.py\u001b[0m in \u001b[0;36mpredict_tag\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mother_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"other\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'threshold' is not defined"
     ]
    }
   ],
   "source": [
    "# Inference (with tokens not similar to training data)\n",
    "text = \"Interpretability methods for explaining model behavior.\"\n",
    "predict_tag(texts=[text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b38561ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9107142857142857,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.7874872825628427\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_prob = model.predict_proba(X_test)\n",
    "y_pred = custom_predict(y_prob=y_prob, threshold=threshold, index=label_encoder.class_to_index[\"other\"])\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4e3c30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metrics = {\"overall\": {}, \"class\": {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8ccaa64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to evaluate\n",
    "other_index = label_encoder.class_to_index[\"other\"]\n",
    "y_prob = model.predict_proba(X_test)\n",
    "y_pred = custom_predict(y_prob=y_prob, threshold=threshold, index=other_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49c65d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7420a6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"precision\": 0.9107142857142857,\n",
      "    \"recall\": 0.75,\n",
      "    \"f1\": 0.7874872825628427,\n",
      "    \"num_samples\": 144.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Overall metrics\n",
    "overall_metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "metrics[\"overall\"][\"precision\"] = overall_metrics[0]\n",
    "metrics[\"overall\"][\"recall\"] = overall_metrics[1]\n",
    "metrics[\"overall\"][\"f1\"] = overall_metrics[2]\n",
    "metrics[\"overall\"][\"num_samples\"] = np.float64(len(y_test))\n",
    "print (json.dumps(metrics[\"overall\"], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a66aa0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cdcdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1826d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "for i, _class in enumerate(label_encoder.classes):\n",
    "    metrics[\"class\"][_class] = {\n",
    "        \"precision\": class_metrics[0][i],\n",
    "        \"recall\": class_metrics[1][i],\n",
    "        \"f1\": class_metrics[2][i],\n",
    "        \"num_samples\": np.float64(class_metrics[3][i]),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0fa185fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 1.0,\n",
      "  \"recall\": 0.7413793103448276,\n",
      "  \"f1\": 0.8514851485148515,\n",
      "  \"num_samples\": 58.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Metrics for a specific class\n",
    "tag = \"natural-language-processing\"\n",
    "print (json.dumps(metrics[\"class\"][tag], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117e5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b8d1b71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"mlops\",\n",
      "  {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.75,\n",
      "    \"f1\": 0.8571428571428571,\n",
      "    \"num_samples\": 12.0\n",
      "  }\n",
      "]\n",
      "[\n",
      "  \"natural-language-processing\",\n",
      "  {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.7413793103448276,\n",
      "    \"f1\": 0.8514851485148515,\n",
      "    \"num_samples\": 58.0\n",
      "  }\n",
      "]\n",
      "[\n",
      "  \"computer-vision\",\n",
      "  {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.6666666666666666,\n",
      "    \"f1\": 0.8,\n",
      "    \"num_samples\": 54.0\n",
      "  }\n",
      "]\n",
      "[\n",
      "  \"other\",\n",
      "  {\n",
      "    \"precision\": 0.35714285714285715,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1\": 0.5263157894736842,\n",
      "    \"num_samples\": 20.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#sorted tags\n",
    "sorted_tags_by_f1 = OrderedDict(sorted(\n",
    "                metrics[\"class\"].items(), key=lambda tag: tag[1][\"f1\"], reverse =True))\n",
    "for item in sorted_tags_by_f1.items():\n",
    "    print(json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "76ff880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP, FP, FN samples\n",
    "tag = \"mlops\"\n",
    "index = label_encoder.class_to_index[tag]\n",
    "tp, fp, fn = [], [], []\n",
    "for i, true in enumerate(y_test):\n",
    "    pred = y_pred[i]\n",
    "    if index==true==pred:\n",
    "        tp.append(i)\n",
    "    elif index!=true and index==pred:\n",
    "        fp.append(i)\n",
    "    elif index==true and index!=pred:\n",
    "        fn.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8f29bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 47, 52, 96, 111, 123, 129, 141]\n",
      "[]\n",
      "[38, 130, 136]\n"
     ]
    }
   ],
   "source": [
    "print (tp)\n",
    "print (fp)\n",
    "print (fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4fb72271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest pytest framework makes easy write small tests yet scales support complex functional testing\n",
      "true: mlops\n",
      "pred: mlops\n"
     ]
    }
   ],
   "source": [
    "index = tp[0]\n",
    "print (X_test_raw[index])\n",
    "print (f\"true: {label_encoder.decode([y_test[index]])[0]}\")\n",
    "print (f\"pred: {label_encoder.decode([y_pred[index]])[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b1f291b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest pytest framework makes easy write small tests yet scales support complex functional testing\n",
      "true: mlops\n",
      "pred: mlops\n"
     ]
    }
   ],
   "source": [
    "index = tp[0]\n",
    "print (X_test_raw[index])\n",
    "print (f\"true: {label_encoder.decode([y_test[index]])[0]}\")\n",
    "print (f\"pred: {label_encoder.decode([y_pred[index]])[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c3de5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== True positives ===\n",
      "  pytest pytest framework makes easy write small tests yet scales support complex functional testing\n",
      "    true: mlops\n",
      "    pred: mlops\n",
      "\n",
      "  test machine learning code systems minimal examples testing machine learning correct implementation expected learned behaviour model performance\n",
      "    true: mlops\n",
      "    pred: mlops\n",
      "\n",
      "  continuous machine learning cml cml helps organize mlops infrastructure top traditional software engineering stack instead creating separate ai platforms\n",
      "    true: mlops\n",
      "    pred: mlops\n",
      "\n",
      "\n",
      "=== False negatives ===\n",
      "  hidden technical debt machine learning systems using software engineering framework technical debt find common incur massive ongoing maintenance costs real world ml systems\n",
      "    true: mlops\n",
      "    pred: other\n",
      "\n",
      "  docker help become effective data scientist look docker perspective data scientist\n",
      "    true: mlops\n",
      "    pred: other\n",
      "\n",
      "  neptune ai lightweight experiment management tool fits workflow\n",
      "    true: mlops\n",
      "    pred: other\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Samples\n",
    "num_samples = 3\n",
    "cm = [(tp, \"True positives\"), (fp, \"False positives\"), (fn, \"False negatives\")]\n",
    "for item in cm:\n",
    "    if len(item[0]):\n",
    "        print (f\"\\n=== {item[1]} ===\")\n",
    "        for index in item[0][:num_samples]:\n",
    "            print (f\"  {X_test_raw[index]}\")\n",
    "            print (f\"    true: {label_encoder.decode([y_test[index]])[0]}\")\n",
    "            print (f\"    pred: {label_encoder.decode([y_pred[index]])[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a917ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n",
      "(144, 4)\n"
     ]
    }
   ],
   "source": [
    "# y\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print (np.shape(y_test))\n",
    "print (np.shape(y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b65fe8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to show raw text\n",
    "test_df = pd.DataFrame({\"text\": X_test_raw, \"tag\": label_encoder.decode(y_test)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e9fd2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag to inspect\n",
    "tag = \"mlops\"\n",
    "index = label_encoder.class_to_index[tag]\n",
    "indices = np.where(y_test==index)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a49cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "88cac831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence score for the correct class is below a threshold\n",
    "low_confidence = []\n",
    "min_threshold = 0.5\n",
    "for i in indices:\n",
    "    prob = y_prob[i][index]\n",
    "    if prob <= 0.5:\n",
    "        low_confidence.append({\"text\": test_df.text[i],\n",
    "                               \"true\": label_encoder.index_to_class[y_test[i]],\n",
    "                               \"pred\": label_encoder.index_to_class[y_pred[i]],\n",
    "                               \"prob\": prob})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "03f0a52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'neptune ai lightweight experiment management tool fits workflow',\n",
       "  'true': 'mlops',\n",
       "  'pred': 'other',\n",
       "  'prob': 0.42905506172083235}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "33327601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "from cleanlab.pruning import get_noise_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a82b2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine potential labeling errors\n",
    "label_error_indices = get_noise_indices(\n",
    "            s=y_test,\n",
    "            psx=y_prob,\n",
    "            sorted_index_method=\"self_confidence\",\n",
    "            verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "48089f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: module 2 convolutional neural networks cs231n lecture 5 move fully connected neural networks convolutional neural networks\n",
      "true: computer-vision\n",
      "pred: other\n",
      "\n",
      "text: forex prediction using neural networks predict movement forex direction\n",
      "true: natural-language-processing\n",
      "pred: other\n",
      "\n",
      "text: goturn pytorch pytorch implementation learning track 100 fps deep regression networks\n",
      "true: computer-vision\n",
      "pred: other\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5\n",
    "for index in label_error_indices[:num_samples]:\n",
    "    print (\"text:\", test_df.iloc[index].text)\n",
    "    print (\"true:\", test_df.iloc[index].tag)\n",
    "    print (\"pred:\", label_encoder.decode([y_pred[index]])[0])\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "69a2e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing import PandasSFApplier\n",
    "from snorkel.slicing import slice_dataframe\n",
    "from snorkel.slicing import slicing_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d2ded2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def nlp_cnn(x):\n",
    "    \"NLP projects that use convolution\"\n",
    "    nlp_projects = \"natural-language-processing\" in x.tag\n",
    "    convolution_projects = \"CNN\" in x.text or \"convolution\" in x.text\n",
    "    return (nlp_projects and convolution_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c37a5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def short_text(x):\n",
    "    \"\"\"Projects with short titles and descriptions.\"\"\"\n",
    "    return len(x.text.split()) < 8  # less than 8 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a409677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 10287.86it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_cnn_df = slice_dataframe(test_df, nlp_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "921f5f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>understanding convolutional neural networks nl...</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "110  understanding convolutional neural networks nl...   \n",
       "\n",
       "                             tag  \n",
       "110  natural-language-processing  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_cnn_df[[\"text\", \"tag\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dd3423e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 20565.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>chakin simple downloader pre trained word vectors</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tsaug python package time series augmentation</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>nlpaug data augmentation nlp</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>texthero text preprocessing representation vis...</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>machine learning production pipeline project f...</td>\n",
       "      <td>mlops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "33   chakin simple downloader pre trained word vectors   \n",
       "73       tsaug python package time series augmentation   \n",
       "76                        nlpaug data augmentation nlp   \n",
       "79   texthero text preprocessing representation vis...   \n",
       "111  machine learning production pipeline project f...   \n",
       "\n",
       "                             tag  \n",
       "33   natural-language-processing  \n",
       "73                         other  \n",
       "76   natural-language-processing  \n",
       "79   natural-language-processing  \n",
       "111                        mlops  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_text_df = slice_dataframe(test_df, short_text)\n",
    "short_text_df[[\"text\", \"tag\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "66c3f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 5332.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rec.array([(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 1), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 1),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "           (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)],\n",
       "          dtype=[('nlp_cnn', '<i8'), ('short_text', '<i8')])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slices\n",
    "slicing_functions = [nlp_cnn, short_text]\n",
    "applier = PandasSFApplier(slicing_functions)\n",
    "slices = applier.apply(test_df)\n",
    "slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fc667d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score slices\n",
    "metrics[\"slices\"] = {}\n",
    "for slice_name in slices.dtype.names:\n",
    "    mask = slices[slice_name].astype(bool)\n",
    "    if sum(mask):\n",
    "        slice_metrics = precision_recall_fscore_support(\n",
    "            y_test[mask], y_pred[mask], average=\"micro\"\n",
    "        )\n",
    "        metrics[\"slices\"][slice_name] = {}\n",
    "        metrics[\"slices\"][slice_name][\"precision\"] = slice_metrics[0]\n",
    "        metrics[\"slices\"][slice_name][\"recall\"] = slice_metrics[1]\n",
    "        metrics[\"slices\"][slice_name][\"f1\"] = slice_metrics[2]\n",
    "        metrics[\"slices\"][slice_name][\"num_samples\"] = len(y_test[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fc43b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nlp_cnn\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1\": 1.0,\n",
      "    \"num_samples\": 1\n",
      "  },\n",
      "  \"short_text\": {\n",
      "    \"precision\": 0.4,\n",
      "    \"recall\": 0.4,\n",
      "    \"f1\": 0.4000000000000001,\n",
      "    \"num_samples\": 5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(metrics[\"slices\"], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f4e46c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "780cc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipe = make_pipeline(vectorizer, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef78e9f",
   "metadata": {},
   "source": [
    "### invariance: Changes should not affect outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "07768005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing', 'natural-language-processing']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INVariance via verb injection (changes should not affect outputs)\n",
    "tokens = [\"revolutionized\", \"disrupted\"]\n",
    "texts = [f\"Transformers applied to NLP have {token} the ML field.\" for token in tokens]\n",
    "predict_tag(texts=texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77582029",
   "metadata": {},
   "source": [
    "### directional: Change should affect outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f165edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing', 'computer-vision']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIRectional expectations (changes with known outputs)\n",
    "tokens = [\"text classification\", \"image classification\"]\n",
    "texts = [f\"ML applied to {token}.\" for token in tokens]\n",
    "predict_tag(texts=texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf349575",
   "metadata": {},
   "source": [
    "### minimum functionality: Simple combination of inputs and expected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "545b7e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing', 'mlops']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimum Functionality Tests (simple input/output pairs)\n",
    "tokens = [\"natural language processing\", \"mlops\"]\n",
    "texts = [f\"{token} is the next big wave in machine learning.\" for token in tokens]\n",
    "predict_tag(texts=texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "111c0e15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19576\\924327647.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mprev_precision\u001b[0m  \u001b[1;31m# most important, cannot regress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mbest_prev_recall\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.03\u001b[0m  \u001b[1;31m# recall cannot regress > 3%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nlp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mprev_nlp_f1\u001b[0m  \u001b[1;31m# priority class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"slices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nlp_cnn\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mprev_nlp_cnn_f1\u001b[0m  \u001b[1;31m# priority slice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "assert precision > prev_precision  # most important, cannot regress\n",
    "assert recall >= best_prev_recall - 0.03  # recall cannot regress > 3%\n",
    "assert metrics[\"class\"][\"nlp\"][\"f1\"] > prev_nlp_f1  # priority class\n",
    "assert metrics[\"slices\"][\"class\"][\"nlp_cnn\"][\"f1\"] > prev_nlp_cnn_f1  # priority slice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5da0f7",
   "metadata": {},
   "source": [
    "# Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df22d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import mlflow\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cdbd3",
   "metadata": {},
   "source": [
    "The input argument argscontains all the parameters needed and it's nice to have it all organized under one variable so we can easily log it and tweak it for different experiments (we'll see this when we do hyperparameter optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8aad2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify arguments\n",
    "args = Namespace(\n",
    "    lower=True,\n",
    "    stem=False,\n",
    "    analyzer=\"char\",\n",
    "    ngram_max_range=7,\n",
    "    alpha=1e-4,\n",
    "    learning_rate=1e-1,\n",
    "    power_t=0.1,\n",
    "    num_epochs=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2c2ba",
   "metadata": {},
   "source": [
    "Next, we'll set up our model registry where all the experiments and their respective runs will be stored. We'll load trained models from this registry as well using specific run IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d85892a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tracking URI\n",
    "MODEL_REGISTRY = Path(\"experiments\")\n",
    "Path(MODEL_REGISTRY).mkdir(exist_ok=True) # create experiments dir\n",
    "mlflow.set_tracking_uri(\"file:///\" + str(MODEL_REGISTRY.absolute()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2430c23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive F has no label.\n",
      " Volume Serial Number is 760A-4EA9\n",
      "\n",
      " Directory of F:\\2023\\MLOps_Deployment\n",
      "\n",
      "10/22/2022  06:19 PM    <DIR>          .\n",
      "10/22/2022  06:19 PM    <DIR>          ..\n",
      "10/17/2022  07:42 PM    <DIR>          .ipynb_checkpoints\n",
      "10/22/2022  04:58 PM    <DIR>          experiments\n",
      "10/22/2022  06:19 PM           180,057 labeled_projects.csv\n",
      "10/20/2022  06:14 PM               233 requirements.txt\n",
      "10/22/2022  06:16 PM           218,512 Untitled.ipynb\n",
      "               3 File(s)        398,802 bytes\n",
      "               4 Dir(s)  115,896,827,904 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78cf77",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b573d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, df, trial=None):\n",
    "    \"\"\"Train model on data.\"\"\"\n",
    "\n",
    "    # Setup\n",
    "    set_seeds()\n",
    "    df = pd.read_csv(\"labeled_projects.csv\")\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "    label_encoder = LabelEncoder().fit(df.tag)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "        get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))\n",
    "\n",
    "    # Tf-idf\n",
    "    vectorizer = TfidfVectorizer(analyzer=args.analyzer, ngram_range=(2,args.ngram_max_range))  # char n-grams\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_val = vectorizer.transform(X_val)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # Oversample\n",
    "    oversample = RandomOverSampler(sampling_strategy=\"all\")\n",
    "    X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Model\n",
    "    model = SGDClassifier(\n",
    "        loss=\"log\", penalty=\"l2\", alpha=args.alpha, max_iter=1,\n",
    "        learning_rate=\"constant\", eta0=args.learning_rate, power_t=args.power_t,\n",
    "        warm_start=True)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(args.num_epochs):\n",
    "        model.fit(X_over, y_over)\n",
    "        train_loss = log_loss(y_train, model.predict_proba(X_train))\n",
    "        val_loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "        if not epoch%10:\n",
    "            print(\n",
    "                f\"Epoch: {epoch:02d} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}\"\n",
    "            )\n",
    "\n",
    "        # Log\n",
    "        if not trial:\n",
    "            mlflow.log_metrics({\"train_loss\": train_loss, \"val_loss\": val_loss}, step=epoch)\n",
    "\n",
    "        # Pruning (for optimization in next section)\n",
    "        if trial:\n",
    "            trial.report(val_loss, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    # Threshold\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_prob = model.predict_proba(X_val)\n",
    "    args.threshold = np.quantile(\n",
    "        [y_prob[i][j] for i, j in enumerate(y_pred)], q=0.25)  # Q1\n",
    "\n",
    "    # Evaluation\n",
    "    other_index = label_encoder.class_to_index[\"other\"]\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    y_pred = custom_predict(y_prob=y_prob, threshold=args.threshold, index=other_index)\n",
    "    metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "    performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "    print (json.dumps(performance, indent=2))\n",
    "\n",
    "    return {\n",
    "        \"args\": args,\n",
    "        \"label_encoder\": label_encoder,\n",
    "        \"vectorizer\": vectorizer,\n",
    "        \"model\": model,\n",
    "        \"performance\": performance\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68b24f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "383b9e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive F has no label.\n",
      " Volume Serial Number is 760A-4EA9\n",
      "\n",
      " Directory of F:\\2023\\MLOps_Deployment\n",
      "\n",
      "10/22/2022  06:19 PM    <DIR>          .\n",
      "10/22/2022  06:19 PM    <DIR>          ..\n",
      "10/17/2022  07:42 PM    <DIR>          .ipynb_checkpoints\n",
      "10/22/2022  04:58 PM    <DIR>          experiments\n",
      "10/22/2022  06:19 PM           180,057 labeled_projects.csv\n",
      "10/20/2022  06:14 PM               233 requirements.txt\n",
      "10/22/2022  06:16 PM           218,512 Untitled.ipynb\n",
      "               3 File(s)        398,802 bytes\n",
      "               4 Dir(s)  115,896,827,904 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1af9b978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///F:\\\\2023\\\\MLOps_Deployment\\\\experiments/1', experiment_id='1', lifecycle_stage='active', name='aisquare', tags={}>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=\"aisquare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d741c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(d, filepath):\n",
    "    \"\"\"Save dict to a json file.\"\"\"\n",
    "    with open(filepath, \"w\") as fp:\n",
    "        json.dump(d, indent=2, sort_keys=False, fp=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2ae6a9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 0.44174, val_loss: 0.58472\n",
      "Epoch: 10 | train_loss: 0.15143, val_loss: 0.38966\n",
      "Epoch: 20 | train_loss: 0.14183, val_loss: 0.38401\n",
      "Epoch: 30 | train_loss: 0.14068, val_loss: 0.38056\n",
      "Epoch: 40 | train_loss: 0.13832, val_loss: 0.37809\n",
      "Epoch: 50 | train_loss: 0.14231, val_loss: 0.38104\n",
      "Epoch: 60 | train_loss: 0.13535, val_loss: 0.38018\n",
      "Epoch: 70 | train_loss: 0.13749, val_loss: 0.37740\n",
      "Epoch: 80 | train_loss: 0.13731, val_loss: 0.37621\n",
      "Epoch: 90 | train_loss: 0.13454, val_loss: 0.37890\n",
      "{\n",
      "  \"precision\": 0.9121572104018912,\n",
      "  \"recall\": 0.8055555555555556,\n",
      "  \"f1\": 0.8296134588540314\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Tracking\n",
    "with mlflow.start_run(run_name=\"sgd\"):\n",
    "\n",
    "    # Train & evaluate\n",
    "    artifacts = train(args=args, df=df)\n",
    "\n",
    "    # Log key metrics\n",
    "    mlflow.log_metrics({\"precision\": artifacts[\"performance\"][\"precision\"]})\n",
    "    mlflow.log_metrics({\"recall\": artifacts[\"performance\"][\"recall\"]})\n",
    "    mlflow.log_metrics({\"f1\": artifacts[\"performance\"][\"f1\"]})\n",
    "\n",
    "    # Log artifacts\n",
    "    with tempfile.TemporaryDirectory() as dp:\n",
    "        artifacts[\"label_encoder\"].save(Path(dp, \"label_encoder.json\"))\n",
    "        joblib.dump(artifacts[\"vectorizer\"], Path(dp, \"vectorizer.pkl\"))\n",
    "        joblib.dump(artifacts[\"model\"], Path(dp, \"model.pkl\"))\n",
    "        save_dict(artifacts[\"performance\"], Path(dp, \"performance.json\"))\n",
    "        mlflow.log_artifacts(dp)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_params(vars(artifacts[\"args\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d88b42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(filepath):\n",
    "    \"\"\"Load a dict from a json file.\"\"\"\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        d = json.load(fp)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bf8cd4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              run_id experiment_id    status  \\\n",
      "0   2985d14b632d48ee94d9e725b45dc66c             1  FINISHED   \n",
      "1   7be3584c531a413f9073fc7173a2e532             1  FINISHED   \n",
      "2   359d01b48a4e45369bc59691e483d327             1  FINISHED   \n",
      "3   e4e47d1fb39f418c84fdc7b7c25dc28f             1  FINISHED   \n",
      "4   46ee85a97ea3472c9a3a60d0f2c3b50e             1  FINISHED   \n",
      "5   d1d71f32a9444503888ed7ffc2ee5ff4             1  FINISHED   \n",
      "6   500461f56d8c425bba6c5b2e924e6ab5             1    FAILED   \n",
      "7   e6cf06bbe0d047e6803541092e250e2b             1    FAILED   \n",
      "8   fcc4dcfd430145e18a6720df30ef097b             1    FAILED   \n",
      "9   d33ba18e4a1b4a0b9c45c64e9d3b7b2f             1    FAILED   \n",
      "10  0136aa0705a64e24b0ba01ee0d57dec5             1    FAILED   \n",
      "11  93cd620e54854e7390eb69508d146143             1    FAILED   \n",
      "12  5731929adbd84cdba9d2d4ca8ac97f7d             1    FAILED   \n",
      "\n",
      "                                         artifact_uri  \\\n",
      "0   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "1   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "2   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "3   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "4   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "5   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "6   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "7   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "8   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "9   file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "10  file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "11  file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "12  file:///F:\\2023\\MLOps Deployment\\experiments/1...   \n",
      "\n",
      "                         start_time                         end_time  \\\n",
      "0  2022-10-22 13:05:50.786000+00:00 2022-10-22 13:05:56.710000+00:00   \n",
      "1  2022-10-22 12:50:55.003000+00:00 2022-10-22 12:50:59.737000+00:00   \n",
      "2  2022-10-22 12:45:27.223000+00:00 2022-10-22 12:45:32.890000+00:00   \n",
      "3  2022-10-22 11:36:15.899000+00:00 2022-10-22 11:36:21.188000+00:00   \n",
      "4  2022-10-22 11:28:31.289000+00:00 2022-10-22 11:28:36.188000+00:00   \n",
      "5  2022-10-22 11:15:56.518000+00:00 2022-10-22 11:16:01.534000+00:00   \n",
      "6  2022-10-22 11:13:13.553000+00:00 2022-10-22 11:13:17.581000+00:00   \n",
      "7  2022-10-22 11:11:17.672000+00:00 2022-10-22 11:11:22.046000+00:00   \n",
      "8  2022-10-22 11:10:27.023000+00:00 2022-10-22 11:10:31.038000+00:00   \n",
      "9  2022-10-22 11:02:47.356000+00:00 2022-10-22 11:02:51.722000+00:00   \n",
      "10 2022-10-22 10:58:16.842000+00:00 2022-10-22 10:58:22.011000+00:00   \n",
      "11 2022-10-22 10:55:48.270000+00:00 2022-10-22 10:55:53.334000+00:00   \n",
      "12 2022-10-22 10:55:25.347000+00:00 2022-10-22 10:55:30.107000+00:00   \n",
      "\n",
      "    metrics.train_loss  metrics.val_loss  metrics.precision  metrics.f1  ...  \\\n",
      "0             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "1             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "2             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "3             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "4             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "5             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "6             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "7             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "8             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "9             0.158647          0.413484           0.911616    0.792997  ...   \n",
      "10            0.158647          0.413484           0.911616    0.792997  ...   \n",
      "11            0.158647          0.413484           0.911616    0.792997  ...   \n",
      "12            0.158647          0.413484           0.911616    0.792997  ...   \n",
      "\n",
      "      params.threshold params.analyzer params.learning_rate params.alpha  \\\n",
      "0   0.6742890218960005            char                  0.1       0.0001   \n",
      "1   0.6742890218960005            char                  0.1       0.0001   \n",
      "2   0.6742890218960005            char                  0.1       0.0001   \n",
      "3   0.6742890218960005            char                  0.1       0.0001   \n",
      "4   0.6742890218960005            char                  0.1       0.0001   \n",
      "5   0.6742890218960005            char                  0.1       0.0001   \n",
      "6                 None            None                 None         None   \n",
      "7                 None            None                 None         None   \n",
      "8                 None            None                 None         None   \n",
      "9                 None            None                 None         None   \n",
      "10                None            None                 None         None   \n",
      "11                None            None                 None         None   \n",
      "12                None            None                 None         None   \n",
      "\n",
      "   params.ngram_max_range params.num_epochs tags.mlflow.user  \\\n",
      "0                       7               100            hhome   \n",
      "1                       7               100            hhome   \n",
      "2                       7               100            hhome   \n",
      "3                       7               100            hhome   \n",
      "4                       7               100            hhome   \n",
      "5                       7               100            hhome   \n",
      "6                    None              None            hhome   \n",
      "7                    None              None            hhome   \n",
      "8                    None              None            hhome   \n",
      "9                    None              None            hhome   \n",
      "10                   None              None            hhome   \n",
      "11                   None              None            hhome   \n",
      "12                   None              None            hhome   \n",
      "\n",
      "   tags.mlflow.runName tags.mlflow.source.type  \\\n",
      "0                  sgd                   LOCAL   \n",
      "1                  sgd                   LOCAL   \n",
      "2                  sgd                   LOCAL   \n",
      "3                  sgd                   LOCAL   \n",
      "4                  sgd                   LOCAL   \n",
      "5                  sgd                   LOCAL   \n",
      "6                  sgd                   LOCAL   \n",
      "7                  sgd                   LOCAL   \n",
      "8                  sgd                   LOCAL   \n",
      "9                  sgd                   LOCAL   \n",
      "10                 sgd                   LOCAL   \n",
      "11                 sgd                   LOCAL   \n",
      "12                 sgd                   LOCAL   \n",
      "\n",
      "                              tags.mlflow.source.name  \n",
      "0   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "1   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "2   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "3   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "4   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "5   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "6   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "7   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "8   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "9   C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "10  C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "11  C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "12  C:\\Users\\hhome\\anaconda3\\envs\\mlops\\lib\\site-p...  \n",
      "\n",
      "[13 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load all runs from experiment\n",
    "experiment_id = mlflow.get_experiment_by_name(\"aisquare\").experiment_id\n",
    "all_runs = mlflow.search_runs(experiment_ids=experiment_id, order_by=[\"metrics.val_loss ASC\"])\n",
    "print (all_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ab6ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best run\n",
    "best_run_id = all_runs.iloc[0].run_id\n",
    "best_run = mlflow.get_run(run_id=best_run_id)\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "with tempfile.TemporaryDirectory() as dp:\n",
    "    client.download_artifacts(run_id=best_run_id, path=\"\", dst_path=dp)\n",
    "    vectorizer = joblib.load(Path(dp, \"vectorizer.pkl\"))\n",
    "    label_encoder = LabelEncoder.load(fp=Path(dp, \"label_encoder.json\"))\n",
    "    model = joblib.load(Path(dp, \"model.pkl\"))\n",
    "    performance = load_dict(filepath=Path(dp, \"performance.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6312e6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9116161616161617,\n",
      "  \"recall\": 0.7569444444444444,\n",
      "  \"f1\": 0.7929971988795519\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print (json.dumps(performance, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ab59793c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12368\\3633344998.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Q1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "threshold = np.quantile([y_prob[i][j] for i, j in enumerate(y_pred)], q=0.25)  # Q1\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2d48bc59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12368\\541929636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Transfer learning with transformers for text classification.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredict_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12368\\3309116470.py\u001b[0m in \u001b[0;36mpredict_tag\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mother_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"other\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'threshold' is not defined"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "text = \"Transfer learning with transformers for text classification.\"\n",
    "predict_tag(texts=[text])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ee92659",
   "metadata": {},
   "source": [
    "We can also load a specific run's model artifacts, by using it's run ID, directly from the model registry without having to save them to a temporary directory.\n",
    "\n",
    "\n",
    "artifact_uri = mlflow.get_run(run_id=run_id).info.artifact_uri.split(\"file://\")[-1]\n",
    "params = Namespace(**utils.load_dict(filepath=Path(artifact_uri, \"args.json\")))\n",
    "label_encoder = data.MultiLabelLabelEncoder.load(fp=Path(artifact_uri, \"label_encoder.json\"))\n",
    "tokenizer = data.Tokenizer.load(fp=Path(artifact_uri, \"tokenizer.json\"))\n",
    "model_state = torch.load(Path(artifact_uri, \"model.pt\"), map_location=device)\n",
    "performance = utils.load_dict(filepath=Path(artifact_uri, \"performance.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69690423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f19b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args, trial):\n",
    "    \"\"\"Objective function for optimization trials.\"\"\"\n",
    "    # Parameters to tune\n",
    "    args.analyzer = trial.suggest_categorical(\"analyzer\", [\"word\", \"char\", \"char_wb\"])\n",
    "    args.ngram_max_range = trial.suggest_int(\"ngram_max_range\", 3, 10)\n",
    "    args.learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-2, 1e0)\n",
    "    args.power_t = trial.suggest_uniform(\"power_t\", 0.1, 0.5)\n",
    "\n",
    "    # Train & evaluate\n",
    "    artifacts = train(args=args, df=df, trial=trial)\n",
    "\n",
    "    # Set additional attributes\n",
    "    performance = artifacts[\"performance\"]\n",
    "    print(json.dumps(performance, indent=2))\n",
    "    trial.set_user_attr(\"precision\", performance[\"precision\"])\n",
    "    trial.set_user_attr(\"recall\", performance[\"recall\"])\n",
    "    trial.set_user_attr(\"f1\", performance[\"f1\"])\n",
    "\n",
    "    return performance[\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4847d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyencoder import NumpyEncoder\n",
    "from optuna.integration.mlflow import MLflowCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8e7fdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 20  # small sample for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64e5da",
   "metadata": {},
   "source": [
    "Pruner using the median stopping rule.\n",
    "\n",
    "Prune if the trial’s best intermediate result is worse than median of intermediate results of previous trials at the same step.\n",
    "\n",
    "Example\n",
    "\n",
    "We minimize an objective function with the median stopping rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa827105",
   "metadata": {},
   "source": [
    "n_startup_trials (int) – Pruning is disabled until the given number of trials finish in the same study.\n",
    "\n",
    "n_warmup_steps (int) – Pruning is disabled until the trial exceeds the given number of step. Note that this feature assumes that step starts at zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d72685",
   "metadata": {},
   "source": [
    "### MLflowCallback\n",
    "Callback to track Optuna trials with MLflow.\n",
    "\n",
    "This callback adds relevant information that is tracked by Optuna to MLflow.\n",
    "\n",
    "Example\n",
    "\n",
    "Add MLflow callback to Optuna optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e39eb343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 18:59:40,883]\u001b[0m A new study created in memory with name: optimization\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 0.53206, val_loss: 0.67625\n",
      "Epoch: 10 | train_loss: 0.16046, val_loss: 0.41277\n",
      "Epoch: 20 | train_loss: 0.14505, val_loss: 0.40302\n",
      "Epoch: 30 | train_loss: 0.14197, val_loss: 0.39985\n",
      "Epoch: 40 | train_loss: 0.14032, val_loss: 0.39852\n",
      "Epoch: 50 | train_loss: 0.14013, val_loss: 0.39837\n",
      "Epoch: 60 | train_loss: 0.13684, val_loss: 0.39872\n",
      "Epoch: 70 | train_loss: 0.13726, val_loss: 0.39761\n",
      "Epoch: 80 | train_loss: 0.13675, val_loss: 0.39557\n",
      "Epoch: 90 | train_loss: 0.13485, val_loss: 0.39689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 18:59:45,234]\u001b[0m Trial 0 finished with value: 0.8038354909930252 and parameters: {'analyzer': 'char', 'ngram_max_range': 6, 'learning_rate': 0.7418393866731047, 'power_t': 0.4307013665676761}. Best is trial 0 with value: 0.8038354909930252.\u001b[0m\n",
      "2022/10/22 18:59:45 INFO mlflow.tracking.fluent: Experiment with name 'optimization' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9135220125786163,\n",
      "  \"recall\": 0.7708333333333334,\n",
      "  \"f1\": 0.8038354909930252\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9135220125786163,\n",
      "  \"recall\": 0.7708333333333334,\n",
      "  \"f1\": 0.8038354909930252\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.17746, val_loss: 1.23578\n",
      "Epoch: 10 | train_loss: 0.42980, val_loss: 0.80338\n",
      "Epoch: 20 | train_loss: 0.29481, val_loss: 0.73013\n",
      "Epoch: 30 | train_loss: 0.24596, val_loss: 0.70248\n",
      "Epoch: 40 | train_loss: 0.22359, val_loss: 0.68912\n",
      "Epoch: 50 | train_loss: 0.21212, val_loss: 0.68182\n",
      "Epoch: 60 | train_loss: 0.20569, val_loss: 0.67743\n",
      "Epoch: 70 | train_loss: 0.20202, val_loss: 0.67465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 18:59:46,818]\u001b[0m Trial 1 finished with value: 0.7315701102066794 and parameters: {'analyzer': 'word', 'ngram_max_range': 3, 'learning_rate': 0.23136280811530835, 'power_t': 0.10330370967615599}. Best is trial 0 with value: 0.8038354909930252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | train_loss: 0.19975, val_loss: 0.67275\n",
      "Epoch: 90 | train_loss: 0.19819, val_loss: 0.67145\n",
      "{\n",
      "  \"precision\": 0.7973326276897706,\n",
      "  \"recall\": 0.7083333333333334,\n",
      "  \"f1\": 0.7315701102066794\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.7973326276897706,\n",
      "  \"recall\": 0.7083333333333334,\n",
      "  \"f1\": 0.7315701102066794\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.35629, val_loss: 1.36102\n",
      "Epoch: 10 | train_loss: 1.06028, val_loss: 1.10689\n",
      "Epoch: 20 | train_loss: 0.87012, val_loss: 0.94378\n",
      "Epoch: 30 | train_loss: 0.74729, val_loss: 0.83997\n",
      "Epoch: 40 | train_loss: 0.66135, val_loss: 0.76883\n",
      "Epoch: 50 | train_loss: 0.59718, val_loss: 0.71684\n",
      "Epoch: 60 | train_loss: 0.54687, val_loss: 0.67689\n",
      "Epoch: 70 | train_loss: 0.50618, val_loss: 0.64516\n",
      "Epoch: 80 | train_loss: 0.47242, val_loss: 0.61926\n",
      "Epoch: 90 | train_loss: 0.44384, val_loss: 0.59768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 18:59:50,491]\u001b[0m Trial 2 finished with value: 0.782917088588174 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 9, 'learning_rate': 0.011649559576706275, 'power_t': 0.27536157939503975}. Best is trial 0 with value: 0.8038354909930252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.886893539467069,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.782917088588174\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.886893539467069,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.782917088588174\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.25651, val_loss: 1.27822\n",
      "Epoch: 10 | train_loss: 0.61836, val_loss: 0.74719\n",
      "Epoch: 20 | train_loss: 0.43764, val_loss: 0.60684\n",
      "Epoch: 30 | train_loss: 0.34899, val_loss: 0.54147\n",
      "Epoch: 40 | train_loss: 0.29604, val_loss: 0.50357\n",
      "Epoch: 50 | train_loss: 0.26099, val_loss: 0.47912\n",
      "Epoch: 60 | train_loss: 0.23616, val_loss: 0.46203\n",
      "Epoch: 70 | train_loss: 0.21805, val_loss: 0.44964\n",
      "Epoch: 80 | train_loss: 0.20441, val_loss: 0.44033\n",
      "Epoch: 90 | train_loss: 0.19374, val_loss: 0.43323\n",
      "{\n",
      "  \"precision\": 0.9042181069958848,\n",
      "  \"recall\": 0.7569444444444444,\n",
      "  \"f1\": 0.7901424610544279\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9042181069958848,\n",
      "  \"recall\": 0.7569444444444444,\n",
      "  \"f1\": 0.7901424610544279\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 18:59:53,980]\u001b[0m Trial 3 finished with value: 0.7901424610544279 and parameters: {'analyzer': 'char', 'ngram_max_range': 6, 'learning_rate': 0.05477241819401939, 'power_t': 0.2818923756143509}. Best is trial 0 with value: 0.8038354909930252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 0.92844, val_loss: 0.99255\n",
      "Epoch: 10 | train_loss: 0.30854, val_loss: 0.48985\n",
      "Epoch: 20 | train_loss: 0.21816, val_loss: 0.42838\n",
      "Epoch: 30 | train_loss: 0.18366, val_loss: 0.40622\n",
      "Epoch: 40 | train_loss: 0.16753, val_loss: 0.39637\n",
      "Epoch: 50 | train_loss: 0.15847, val_loss: 0.39140\n",
      "Epoch: 60 | train_loss: 0.15239, val_loss: 0.38887\n",
      "Epoch: 70 | train_loss: 0.14909, val_loss: 0.38644\n",
      "Epoch: 80 | train_loss: 0.14719, val_loss: 0.38495\n",
      "Epoch: 90 | train_loss: 0.14523, val_loss: 0.38492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 18:59:55,868]\u001b[0m Trial 4 finished with value: 0.8265063522446623 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 4, 'learning_rate': 0.17078916921037807, 'power_t': 0.48797541761210816}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9178004535147392,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.8265063522446623\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9178004535147392,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.8265063522446623\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.30527, val_loss: 1.31873\n",
      "Epoch: 10 | train_loss: 0.79293, val_loss: 0.88361\n",
      "Epoch: 20 | train_loss: 0.60672, val_loss: 0.72936\n",
      "Epoch: 30 | train_loss: 0.50564, val_loss: 0.64902\n",
      "Epoch: 40 | train_loss: 0.44055, val_loss: 0.59912\n",
      "Epoch: 50 | train_loss: 0.39411, val_loss: 0.56493\n",
      "Epoch: 60 | train_loss: 0.35860, val_loss: 0.53961\n",
      "Epoch: 70 | train_loss: 0.33099, val_loss: 0.52029\n",
      "Epoch: 80 | train_loss: 0.30883, val_loss: 0.50510\n",
      "Epoch: 90 | train_loss: 0.29034, val_loss: 0.49293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 18:59:57,556]\u001b[0m Trial 5 finished with value: 0.7818115536539413 and parameters: {'analyzer': 'char', 'ngram_max_range': 3, 'learning_rate': 0.025296829741801207, 'power_t': 0.3298939986362448}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.889019468186135,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.7818115536539413\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.889019468186135,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.7818115536539413\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.29512, val_loss: 1.31117\n",
      "Epoch: 10 | train_loss: 0.72998, val_loss: 0.83859\n",
      "Epoch: 20 | train_loss: 0.53525, val_loss: 0.68110\n",
      "Epoch: 30 | train_loss: 0.43371, val_loss: 0.60239\n",
      "Epoch: 40 | train_loss: 0.37011, val_loss: 0.55463\n",
      "Epoch: 50 | train_loss: 0.32618, val_loss: 0.52258\n",
      "Epoch: 60 | train_loss: 0.29382, val_loss: 0.49943\n",
      "Epoch: 70 | train_loss: 0.26927, val_loss: 0.48210\n",
      "Epoch: 80 | train_loss: 0.25007, val_loss: 0.46866\n",
      "Epoch: 90 | train_loss: 0.23458, val_loss: 0.45804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:00,821]\u001b[0m Trial 6 finished with value: 0.7839703671014351 and parameters: {'analyzer': 'char', 'ngram_max_range': 5, 'learning_rate': 0.03569286250419072, 'power_t': 0.23052963364477327}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9032828282828282,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.7839703671014351\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9032828282828282,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.7839703671014351\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.01768, val_loss: 1.06991\n",
      "Epoch: 10 | train_loss: 0.35079, val_loss: 0.53007\n",
      "Epoch: 20 | train_loss: 0.24388, val_loss: 0.45659\n",
      "Epoch: 30 | train_loss: 0.20098, val_loss: 0.42838\n",
      "Epoch: 40 | train_loss: 0.17960, val_loss: 0.41470\n",
      "Epoch: 50 | train_loss: 0.16735, val_loss: 0.40739\n",
      "Epoch: 60 | train_loss: 0.15949, val_loss: 0.40283\n",
      "Epoch: 70 | train_loss: 0.15468, val_loss: 0.39975\n",
      "Epoch: 80 | train_loss: 0.15157, val_loss: 0.39761\n",
      "Epoch: 90 | train_loss: 0.14910, val_loss: 0.39658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:04,855]\u001b[0m Trial 7 finished with value: 0.8048092342621649 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 9, 'learning_rate': 0.14585708976363254, 'power_t': 0.18039581315398945}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9135220125786163,\n",
      "  \"recall\": 0.7708333333333334,\n",
      "  \"f1\": 0.8048092342621649\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9135220125786163,\n",
      "  \"recall\": 0.7708333333333334,\n",
      "  \"f1\": 0.8048092342621649\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.13284, val_loss: 1.16871\n",
      "Epoch: 10 | train_loss: 0.48612, val_loss: 0.62363\n",
      "Epoch: 20 | train_loss: 0.34972, val_loss: 0.52353\n",
      "Epoch: 30 | train_loss: 0.28589, val_loss: 0.48096\n",
      "Epoch: 40 | train_loss: 0.24923, val_loss: 0.45787\n",
      "Epoch: 50 | train_loss: 0.22511, val_loss: 0.44376\n",
      "Epoch: 60 | train_loss: 0.20777, val_loss: 0.43448\n",
      "Epoch: 70 | train_loss: 0.19563, val_loss: 0.42739\n",
      "Epoch: 80 | train_loss: 0.18686, val_loss: 0.42246\n",
      "Epoch: 90 | train_loss: 0.17971, val_loss: 0.41942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:07,123]\u001b[0m Trial 8 finished with value: 0.7958645411885326 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 3, 'learning_rate': 0.07569388935183549, 'power_t': 0.10595059446419737}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8963276556413811,\n",
      "  \"recall\": 0.7638888888888888,\n",
      "  \"f1\": 0.7958645411885326\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8963276556413811,\n",
      "  \"recall\": 0.7638888888888888,\n",
      "  \"f1\": 0.7958645411885326\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.98824, val_loss: 1.04945\n",
      "Epoch: 10 | train_loss: 0.30735, val_loss: 0.51419\n",
      "Epoch: 20 | train_loss: 0.21390, val_loss: 0.44994\n",
      "Epoch: 30 | train_loss: 0.18065, val_loss: 0.42749\n",
      "Epoch: 40 | train_loss: 0.16569, val_loss: 0.41757\n",
      "Epoch: 50 | train_loss: 0.15788, val_loss: 0.41283\n",
      "Epoch: 60 | train_loss: 0.15310, val_loss: 0.41028\n",
      "Epoch: 70 | train_loss: 0.15040, val_loss: 0.40868\n",
      "Epoch: 80 | train_loss: 0.14872, val_loss: 0.40753\n",
      "Epoch: 90 | train_loss: 0.14720, val_loss: 0.40719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:13,436]\u001b[0m Trial 9 finished with value: 0.7874872825628427 and parameters: {'analyzer': 'char', 'ngram_max_range': 7, 'learning_rate': 0.1990728893295957, 'power_t': 0.4775558733747993}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9107142857142857,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.7874872825628427\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9107142857142857,\n",
      "  \"recall\": 0.75,\n",
      "  \"f1\": 0.7874872825628427\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.92537, val_loss: 1.10578\n",
      "Epoch: 10 | train_loss: 0.26225, val_loss: 0.73534\n",
      "Epoch: 20 | train_loss: 0.21726, val_loss: 0.70750\n",
      "Epoch: 30 | train_loss: 0.20827, val_loss: 0.70022\n",
      "Epoch: 40 | train_loss: 0.20560, val_loss: 0.69773\n",
      "Epoch: 50 | train_loss: 0.20457, val_loss: 0.69661\n",
      "Epoch: 60 | train_loss: 0.20394, val_loss: 0.69583\n",
      "Epoch: 70 | train_loss: 0.20380, val_loss: 0.69550\n",
      "Epoch: 80 | train_loss: 0.20368, val_loss: 0.69518\n",
      "Epoch: 90 | train_loss: 0.20318, val_loss: 0.69502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:15,060]\u001b[0m Trial 10 finished with value: 0.7275066428573402 and parameters: {'analyzer': 'word', 'ngram_max_range': 5, 'learning_rate': 0.6082347964940635, 'power_t': 0.37608470435684715}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8016595686075091,\n",
      "  \"recall\": 0.7013888888888888,\n",
      "  \"f1\": 0.7275066428573402\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.8016595686075091,\n",
      "  \"recall\": 0.7013888888888888,\n",
      "  \"f1\": 0.7275066428573402\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.01445, val_loss: 1.06726\n",
      "Epoch: 10 | train_loss: 0.34874, val_loss: 0.52948\n",
      "Epoch: 20 | train_loss: 0.24266, val_loss: 0.45703\n",
      "Epoch: 30 | train_loss: 0.20029, val_loss: 0.42938\n",
      "Epoch: 40 | train_loss: 0.17925, val_loss: 0.41604\n",
      "Epoch: 50 | train_loss: 0.16724, val_loss: 0.40896\n",
      "Epoch: 60 | train_loss: 0.15955, val_loss: 0.40455\n",
      "Epoch: 70 | train_loss: 0.15486, val_loss: 0.40156\n",
      "Epoch: 80 | train_loss: 0.15184, val_loss: 0.39949\n",
      "Epoch: 90 | train_loss: 0.14943, val_loss: 0.39849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:18,764]\u001b[0m Trial 11 finished with value: 0.8048092342621649 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 10, 'learning_rate': 0.14866773497223648, 'power_t': 0.1839126746199084}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9135220125786163,\n",
      "  \"recall\": 0.7708333333333334,\n",
      "  \"f1\": 0.8048092342621649\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9135220125786163,\n",
      "  \"recall\": 0.7708333333333334,\n",
      "  \"f1\": 0.8048092342621649\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.72043, val_loss: 0.81676\n",
      "Epoch: 10 | train_loss: 0.20885, val_loss: 0.43236\n",
      "Epoch: 20 | train_loss: 0.16272, val_loss: 0.40274\n",
      "Epoch: 30 | train_loss: 0.15021, val_loss: 0.39398\n",
      "Epoch: 40 | train_loss: 0.14612, val_loss: 0.39146\n",
      "Epoch: 50 | train_loss: 0.14426, val_loss: 0.39078\n",
      "Epoch: 60 | train_loss: 0.14175, val_loss: 0.39033\n",
      "Epoch: 70 | train_loss: 0.14116, val_loss: 0.38896\n",
      "Epoch: 80 | train_loss: 0.14065, val_loss: 0.38753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:21,965]\u001b[0m Trial 12 finished with value: 0.8211582700713135 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 8, 'learning_rate': 0.3677771939195187, 'power_t': 0.17790491422882526}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.13922, val_loss: 0.38806\n",
      "{\n",
      "  \"precision\": 0.9166666666666666,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8211582700713135\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9166666666666666,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8211582700713135\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.71229, val_loss: 0.80995\n",
      "Epoch: 10 | train_loss: 0.20628, val_loss: 0.43071\n",
      "Epoch: 20 | train_loss: 0.16158, val_loss: 0.40205\n",
      "Epoch: 30 | train_loss: 0.14963, val_loss: 0.39361\n",
      "Epoch: 40 | train_loss: 0.14579, val_loss: 0.39124\n",
      "Epoch: 50 | train_loss: 0.14404, val_loss: 0.39063\n",
      "Epoch: 60 | train_loss: 0.14153, val_loss: 0.39021\n",
      "Epoch: 70 | train_loss: 0.14099, val_loss: 0.38884\n",
      "Epoch: 80 | train_loss: 0.14048, val_loss: 0.38738\n",
      "Epoch: 90 | train_loss: 0.13904, val_loss: 0.38793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:25,717]\u001b[0m Trial 13 finished with value: 0.8211582700713135 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 8, 'learning_rate': 0.3772385677195726, 'power_t': 0.4914429875605559}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9166666666666666,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8211582700713135\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9166666666666666,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8211582700713135\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.68821, val_loss: 0.78719\n",
      "Epoch: 10 | train_loss: 0.20090, val_loss: 0.41689\n",
      "Epoch: 20 | train_loss: 0.15808, val_loss: 0.38928\n",
      "Epoch: 30 | train_loss: 0.14686, val_loss: 0.38143\n",
      "Epoch: 40 | train_loss: 0.14346, val_loss: 0.37945\n",
      "Epoch: 50 | train_loss: 0.14216, val_loss: 0.37903\n",
      "Epoch: 60 | train_loss: 0.13944, val_loss: 0.37915\n",
      "Epoch: 70 | train_loss: 0.13924, val_loss: 0.37755\n",
      "Epoch: 80 | train_loss: 0.13890, val_loss: 0.37606\n",
      "Epoch: 90 | train_loss: 0.13735, val_loss: 0.37705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:29,114]\u001b[0m Trial 14 finished with value: 0.8265063522446623 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 5, 'learning_rate': 0.37893468603209085, 'power_t': 0.3778839747250494}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9178004535147392,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.8265063522446623\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9178004535147392,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.8265063522446623\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.76222, val_loss: 0.84925\n",
      "Epoch: 10 | train_loss: 0.23125, val_loss: 0.43789\n",
      "Epoch: 20 | train_loss: 0.17355, val_loss: 0.40091\n",
      "Epoch: 30 | train_loss: 0.15593, val_loss: 0.38973\n",
      "Epoch: 40 | train_loss: 0.14962, val_loss: 0.38619\n",
      "Epoch: 50 | train_loss: 0.14677, val_loss: 0.38495\n",
      "Epoch: 60 | train_loss: 0.14360, val_loss: 0.38493\n",
      "Epoch: 70 | train_loss: 0.14293, val_loss: 0.38320\n",
      "Epoch: 80 | train_loss: 0.14255, val_loss: 0.38194\n",
      "Epoch: 90 | train_loss: 0.14105, val_loss: 0.38291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:31,075]\u001b[0m Trial 15 finished with value: 0.8265063522446623 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 4, 'learning_rate': 0.29063971102668124, 'power_t': 0.4021015969033501}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9178004535147392,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.8265063522446623\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9178004535147392,\n",
      "  \"recall\": 0.7986111111111112,\n",
      "  \"f1\": 0.8265063522446623\n",
      "}\n",
      "Epoch: 00 | train_loss: 1.12017, val_loss: 1.15873\n",
      "Epoch: 10 | train_loss: 0.44091, val_loss: 0.58796\n",
      "Epoch: 20 | train_loss: 0.30789, val_loss: 0.48877\n",
      "Epoch: 30 | train_loss: 0.24824, val_loss: 0.44702\n",
      "Epoch: 40 | train_loss: 0.21519, val_loss: 0.42464\n",
      "Epoch: 50 | train_loss: 0.19444, val_loss: 0.41128\n",
      "Epoch: 60 | train_loss: 0.18027, val_loss: 0.40241\n",
      "Epoch: 70 | train_loss: 0.17061, val_loss: 0.39618\n",
      "Epoch: 80 | train_loss: 0.16382, val_loss: 0.39179\n",
      "Epoch: 90 | train_loss: 0.15856, val_loss: 0.38893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:32,980]\u001b[0m Trial 16 finished with value: 0.8211582700713135 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 5, 'learning_rate': 0.08964035334751444, 'power_t': 0.3532121019293545}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9166666666666666,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8211582700713135\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9166666666666666,\n",
      "  \"recall\": 0.7916666666666666,\n",
      "  \"f1\": 0.8211582700713135\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.93894, val_loss: 1.10282\n",
      "Epoch: 10 | train_loss: 0.26524, val_loss: 0.72744\n",
      "Epoch: 20 | train_loss: 0.21603, val_loss: 0.69773\n",
      "Epoch: 30 | train_loss: 0.20553, val_loss: 0.68968\n",
      "Epoch: 40 | train_loss: 0.20232, val_loss: 0.68680\n",
      "Epoch: 50 | train_loss: 0.20105, val_loss: 0.68549\n",
      "Epoch: 60 | train_loss: 0.20030, val_loss: 0.68462\n",
      "Epoch: 70 | train_loss: 0.20006, val_loss: 0.68421\n",
      "Epoch: 80 | train_loss: 0.19990, val_loss: 0.68384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:34,156]\u001b[0m Trial 17 finished with value: 0.7213056761599426 and parameters: {'analyzer': 'word', 'ngram_max_range': 4, 'learning_rate': 0.5687627497503405, 'power_t': 0.4420102293479031}. Best is trial 4 with value: 0.8265063522446623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | train_loss: 0.19941, val_loss: 0.68365\n",
      "{\n",
      "  \"precision\": 0.799564857410602,\n",
      "  \"recall\": 0.6944444444444444,\n",
      "  \"f1\": 0.7213056761599426\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.799564857410602,\n",
      "  \"recall\": 0.6944444444444444,\n",
      "  \"f1\": 0.7213056761599426\n",
      "}\n",
      "Epoch: 00 | train_loss: 0.70259, val_loss: 0.79848\n",
      "Epoch: 10 | train_loss: 0.20994, val_loss: 0.42433\n",
      "Epoch: 20 | train_loss: 0.16321, val_loss: 0.39495\n",
      "Epoch: 30 | train_loss: 0.15044, val_loss: 0.38662\n",
      "Epoch: 40 | train_loss: 0.14642, val_loss: 0.38443\n",
      "Epoch: 50 | train_loss: 0.14500, val_loss: 0.38393\n",
      "Epoch: 60 | train_loss: 0.14194, val_loss: 0.38428\n",
      "Epoch: 70 | train_loss: 0.14181, val_loss: 0.38242\n",
      "Epoch: 80 | train_loss: 0.14159, val_loss: 0.38099\n",
      "Epoch: 90 | train_loss: 0.13997, val_loss: 0.38227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:35,828]\u001b[0m Trial 18 finished with value: 0.8324239210798947 and parameters: {'analyzer': 'char_wb', 'ngram_max_range': 4, 'learning_rate': 0.352294350509354, 'power_t': 0.3995577695620203}. Best is trial 18 with value: 0.8324239210798947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9189814814814815,\n",
      "  \"recall\": 0.8055555555555556,\n",
      "  \"f1\": 0.8324239210798947\n",
      "}\n",
      "{\n",
      "  \"precision\": 0.9189814814814815,\n",
      "  \"recall\": 0.8055555555555556,\n",
      "  \"f1\": 0.8324239210798947\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 19:00:36,268]\u001b[0m Trial 19 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 0.44174, val_loss: 0.58472\n"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "study = optuna.create_study(study_name=\"optimization\", direction=\"maximize\", pruner=pruner)\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=mlflow.get_tracking_uri(), metric_name=\"f1\")\n",
    "study.optimize(lambda trial: objective(args, trial), n_trials=NUM_TRIALS, callbacks=[mlflow_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "63a4a752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_analyzer</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_ngram_max_range</th>\n",
       "      <th>params_power_t</th>\n",
       "      <th>user_attrs_f1</th>\n",
       "      <th>user_attrs_precision</th>\n",
       "      <th>user_attrs_recall</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>2022-10-22 19:00:34.212136</td>\n",
       "      <td>2022-10-22 19:00:35.828281</td>\n",
       "      <td>00:00:01.616145</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.352294</td>\n",
       "      <td>4</td>\n",
       "      <td>0.399558</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>0.918981</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>2022-10-22 19:00:29.275776</td>\n",
       "      <td>2022-10-22 19:00:31.075847</td>\n",
       "      <td>00:00:01.800071</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.290640</td>\n",
       "      <td>4</td>\n",
       "      <td>0.402102</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>0.917800</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>2022-10-22 18:59:54.236062</td>\n",
       "      <td>2022-10-22 18:59:55.868207</td>\n",
       "      <td>00:00:01.632145</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.170789</td>\n",
       "      <td>4</td>\n",
       "      <td>0.487975</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>0.917800</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>2022-10-22 19:00:27.130332</td>\n",
       "      <td>2022-10-22 19:00:29.114622</td>\n",
       "      <td>00:00:01.984290</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.378935</td>\n",
       "      <td>5</td>\n",
       "      <td>0.377884</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>0.917800</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.821158</td>\n",
       "      <td>2022-10-22 19:00:31.139794</td>\n",
       "      <td>2022-10-22 19:00:32.980035</td>\n",
       "      <td>00:00:01.840241</td>\n",
       "      <td>char_wb</td>\n",
       "      <td>0.089640</td>\n",
       "      <td>5</td>\n",
       "      <td>0.353212</td>\n",
       "      <td>0.821158</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "18      18  0.832424 2022-10-22 19:00:34.212136 2022-10-22 19:00:35.828281   \n",
       "15      15  0.826506 2022-10-22 19:00:29.275776 2022-10-22 19:00:31.075847   \n",
       "4        4  0.826506 2022-10-22 18:59:54.236062 2022-10-22 18:59:55.868207   \n",
       "14      14  0.826506 2022-10-22 19:00:27.130332 2022-10-22 19:00:29.114622   \n",
       "16      16  0.821158 2022-10-22 19:00:31.139794 2022-10-22 19:00:32.980035   \n",
       "\n",
       "          duration params_analyzer  params_learning_rate  \\\n",
       "18 00:00:01.616145         char_wb              0.352294   \n",
       "15 00:00:01.800071         char_wb              0.290640   \n",
       "4  00:00:01.632145         char_wb              0.170789   \n",
       "14 00:00:01.984290         char_wb              0.378935   \n",
       "16 00:00:01.840241         char_wb              0.089640   \n",
       "\n",
       "    params_ngram_max_range  params_power_t  user_attrs_f1  \\\n",
       "18                       4        0.399558       0.832424   \n",
       "15                       4        0.402102       0.826506   \n",
       "4                        4        0.487975       0.826506   \n",
       "14                       5        0.377884       0.826506   \n",
       "16                       5        0.353212       0.821158   \n",
       "\n",
       "    user_attrs_precision  user_attrs_recall     state  \n",
       "18              0.918981           0.805556  COMPLETE  \n",
       "15              0.917800           0.798611  COMPLETE  \n",
       "4               0.917800           0.798611  COMPLETE  \n",
       "14              0.917800           0.798611  COMPLETE  \n",
       "16              0.916667           0.791667  COMPLETE  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All trials\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df = trials_df.sort_values([\"user_attrs_f1\"], ascending=False)  # sort by metric\n",
    "trials_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ef80287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value (f1): 0.8324239210798947\n",
      "Best hyperparameters: {\n",
      "  \"analyzer\": \"char_wb\",\n",
      "  \"ngram_max_range\": 4,\n",
      "  \"learning_rate\": 0.352294350509354,\n",
      "  \"power_t\": 0.3995577695620203\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Best trial\n",
    "print (f\"Best value (f1): {study.best_trial.value}\")\n",
    "print (f\"Best hyperparameters: {json.dumps(study.best_trial.params, indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19980d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"lower\": true,\n",
      "  \"stem\": false,\n",
      "  \"analyzer\": \"char_wb\",\n",
      "  \"ngram_max_range\": 4,\n",
      "  \"alpha\": 0.0001,\n",
      "  \"learning_rate\": 0.352294350509354,\n",
      "  \"power_t\": 0.3995577695620203,\n",
      "  \"num_epochs\": 100,\n",
      "  \"threshold\": 0.6920968072304011\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save best parameter values\n",
    "args = {**args.__dict__, **study.best_trial.params}\n",
    "print (json.dumps(args, indent=2, cls=NumpyEncoder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82bbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
